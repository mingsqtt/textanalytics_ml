{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: If you're using a Mac/Linux, you can check your environment with these commands:\n",
    "\n",
    "```\n",
    "!which pip3\n",
    "!which python3\n",
    "!ls -lah /usr/local/bin/python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: torch==1.3.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torch==1.3.0) (1.17.2)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.17.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install torch==1.3.0\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=====\n",
    "\n",
    "**Perceptron** algorithm is a:\n",
    "\n",
    "> \"*system that depends on **probabilistic** rather than deterministic principles for its operation, gains its reliability from the **properties of statistical measurements obtain from a large population of elements***\"\n",
    "> \\- Frank Rosenblatt (1957)\n",
    "\n",
    "Then the news:\n",
    "\n",
    "> \"*[Perceptron is an] **embryo of an electronic computer** that [the Navy] expects will be **able to walk, talk, see, write, reproduce itself and be conscious of its existence.***\"\n",
    "> \\- The New York Times (1958)\n",
    "\n",
    "News quote cite from Olazaran (1996) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron in Bullets\n",
    "----\n",
    "\n",
    " - Perceptron learns to classify any linearly separable set of inputs. \n",
    " - Some nice graphics for perceptron with Go https://appliedgo.net/perceptron/  \n",
    "\n",
    "If you've got some spare time: \n",
    "\n",
    " - There's a whole book just on perceptron: https://mitpress.mit.edu/books/perceptrons\n",
    " - For watercooler gossips on perceptron in the early days, read [Olazaran (1996)](https://pdfs.semanticscholar.org/f3b6/e5ef511b471ff508959f660c94036b434277.pdf?_ga=2.57343906.929185581.1517539221-1505787125.1517539221)\n",
    " \n",
    " \n",
    "Perceptron in Math\n",
    "----\n",
    "\n",
    "Given a set of inputs $x$, the perceptron \n",
    "\n",
    " - learns $w$ vector to map the inputs to a real-value output between $[0,1]$\n",
    " - through the summation of the dot product of the $wÂ·x$ with a transformation function\n",
    " \n",
    " \n",
    "Perceptron in Picture\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ibin.co/4TyMU8AdpV4J.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron.png\", width=500)\n",
    "Image(url=\"https://ibin.co/4TyMU8AdpV4J.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note:** Usually, we use $x_1$ as the bias and fix the input to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron as a Workflow Diagram\n",
    "----\n",
    "\n",
    "If you're familiar with [mermaid flowchart](https://mermaidjs.github.io)\n",
    "\n",
    "```\n",
    ".. mermaid::\n",
    "\n",
    "    graph LR\n",
    "       subgraph Input\n",
    "          x_1\n",
    "          x_i \n",
    "          x_n\n",
    "       end\n",
    "       subgraph Perceptron\n",
    "            n1((s)) --> n2((\"f(s)\"))\n",
    "        end\n",
    "        x_1 --> |w_1| n1\n",
    "        x_i --> |w_i| n1\n",
    "        x_n --> |w_n| n1\n",
    "        n2 --> y[\"[0,1]\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://svgshare.com/i/AbJ.svg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron-mermaid.svg\", width=500)\n",
    "Image(url=\"https://svgshare.com/i/AbJ.svg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Process\n",
    "====\n",
    "\n",
    "To learn the weights, $w$, we use an **optimizer** to find the best-fit (optimal) values for $w$ such that the inputs correct maps to the outputs.\n",
    "\n",
    "Typically, process performs the following 4 steps iteratively.\n",
    "\n",
    "### **Initialization**\n",
    "\n",
    " - **Step 1**: Initialize weights vector\n",
    " \n",
    "### **Forward Propagation**\n",
    "\n",
    " \n",
    " - **Step 2a**: Multiply the weights vector with the inputs, sum the products, i.e. `s`\n",
    " - **Step 2b**: Put the sum through the sigmoid, i.e. `f()`\n",
    " \n",
    "### **Back Propagation**\n",
    " \n",
    " \n",
    " - **Step 3a**: Compute the errors, i.e. difference between expected output and predictions\n",
    " - **Step 3b**: Multiply the error with the **derivatives** to get the delta\n",
    " - **Step 3c**: Multiply the delta vector with the inputs, sum the product\n",
    " \n",
    "### **Optimizer takes a step**\n",
    "\n",
    " - **Step 4**: Multiply the learning rate with the output of Step 3c.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx): \n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    # Hint: let sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92414182, 0.57932425, 0.19466158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2.5, 0.32, -1.42]))             # [out]: array([0.92414182, 0.57932425, 0.19466158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75  ,  0.2176, -3.4364])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([2.5, 0.32, -1.42]))  # [out]: array([0.07010372, 0.24370766, 0.15676845])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predicted, truth):\n",
    "    return np.abs(truth - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([0.6, 1.0, 10.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8,  2.8, 89.2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([9.3, 4.0, 99.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing OR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = or_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = or_output = np.array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = or_input.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(or_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "======\n",
      "no. of rows = 4\n",
      "no. of cols = 2\n",
      "\n",
      "\n",
      "Outputs\n",
      "=======\n",
      "no. of cols = 1\n"
     ]
    }
   ],
   "source": [
    "print('Inputs\\n======')\n",
    "print('no. of rows =', num_data) \n",
    "print('no. of cols =', input_dim)\n",
    "print('\\n')\n",
    "print('Outputs\\n=======')\n",
    "print('no. of cols =', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Multiply the weights vector with the inputs, sum the products\n",
    "====\n",
    "\n",
    "To get the output of step 2a, \n",
    "\n",
    " - Itrate through each row of the data, `X`\n",
    " - For each column in each row, find the product of the value and the respective weights\n",
    " - For each row, compute the sum of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.71518937]\n",
      " [0.5488135 ]\n",
      " [1.26400287]]\n"
     ]
    }
   ],
   "source": [
    "# If we write it imperatively:\n",
    "summation = []\n",
    "for row in X:\n",
    "    sum_wx = 0\n",
    "    for feature, weight in zip(row, W):\n",
    "        sum_wx += feature * weight\n",
    "    summation.append(sum_wx)\n",
    "print(np.array(summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.71518937],\n",
       "       [0.5488135 ],\n",
       "       [1.26400287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we vectorize the process and use numpy.\n",
    "np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Single-Layer Model\n",
    "====\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.03 # How large a step to take per iteration.\n",
    "\n",
    "# Lets standardize and call our inputs X and outputs Y\n",
    "X = or_input\n",
    "Y = or_output\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "\n",
    "    # Step 2a: Multiply the weights vector with the inputs, sum the products, i.e. s\n",
    "    # Step 2b: Put the sum through the sigmoid, i.e. f()\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # Back propagation.\n",
    "    # Step 3a: Compute the errors, i.e. difference between expected output and predictions\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Step 3b: Multiply the error with the derivatives to get the delta\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "\n",
    "    # Step 3c: Multiply the delta vector with the inputs, sum the product (use np.dot)\n",
    "    # Step 4: Multiply the learning rate with the output of Step 3c.\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.95643415],\n",
       "       [0.95623017],\n",
       "       [0.99791935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[[int(prediction > 0.5)] for prediction in layer1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the XOR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = xor_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.003 # How large a step to take per iteration.\n",
    "\n",
    "# Lets drop the last row of data and use that as unseen test.\n",
    "X = xor_input\n",
    "Y = xor_output\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Back propagation.\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = sigmoid_derivative(layer1) * layer1_error\n",
    "\n",
    "    # update weights\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer1] # All correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't represent XOR with simple perceptron !!!\n",
    "====\n",
    "\n",
    "No matter how you change the hyperparameters or data, the XOR function can't be represented by a single perceptron layer.\n",
    " \n",
    "There's no way you can get all four data points to get the correct outputs for the XOR boolean operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving XOR (Add more layers)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "hidden_dim = 5\n",
    "# Initialize weights between the input layers and the hidden layer.\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the hidden layers and the output layer.\n",
    "W2 = np.random.random((hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.03\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    \n",
    "    # How much did we miss in the predictions?\n",
    "    layer2_error = cost(layer2, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
    "\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
    "    ##print(epoch_n, list((layer2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training input.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31284349],\n",
       "       [0.6213127 ],\n",
       "       [0.62323891],\n",
       "       [0.46427804]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 # Our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding another layer\n",
    "====\n",
    "\n",
    "Use the same process:\n",
    "    \n",
    "  1. Initialize\n",
    "  2. Forward Propagate\n",
    "  3. Back Propagate \n",
    "  4. Update (aka step)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "layer0to1_hidden_dim = 5\n",
    "layer1to2_hidden_dim = 5\n",
    "\n",
    "# Initialize weights between the input layers 0 ->  layer 1\n",
    "W1 = np.random.random((input_dim, layer0to1_hidden_dim))\n",
    "\n",
    "# Initialize weights between the layer 1 -> layer 2\n",
    "W2 = np.random.random((layer0to1_hidden_dim, layer1to2_hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the layer 2 -> layer 3\n",
    "W3 = np.random.random((layer1to2_hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "    layer3 = sigmoid(np.dot(layer2, W3))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    # How much did we miss in the predictions?\n",
    "    layer3_error = cost(layer3, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer3_delta = layer3_error * sigmoid_derivative(layer3)\n",
    "\n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer3 error (according to the weights)?\n",
    "    layer2_error = np.dot(layer3_delta, W3.T)\n",
    "    layer2_delta = layer3_error * sigmoid_derivative(layer2)\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W3 +=  learning_rate * np.dot(layer2.T, layer3_delta)\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50039537],\n",
       "       [0.50000003],\n",
       "       [0.9929507 ],\n",
       "       [0.50001378]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets do it with PyTorch \n",
    "\n",
    "First lets try a single perceptron and see that we can't train a model that can represent XOR. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Original XOR X input in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # Original XOR Y output in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu' if torch.cuda.is_available()  else 'cpu'\n",
    "# Converting the X to PyTorch-able data structure.\n",
    "X_pt = torch.tensor(X).float()\n",
    "X_pt = X_pt.to(device)\n",
    "# Converting the Y to PyTorch-able data structure.\n",
    "Y_pt = torch.tensor(Y, requires_grad=False).float()\n",
    "Y_pt = Y_pt.to(device)\n",
    "print(X_pt)\n",
    "print(Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Dim: 2\n",
      "Output Dim: 1\n"
     ]
    }
   ],
   "source": [
    "# Use tensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, input_dim = X_pt.shape\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, output_dim = Y_pt.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Sequential to define a simple feed-forward network.\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Use nn.Linear to get our simple perceptron\n",
    "            nn.Sigmoid()                      # Use nn.Sigmoid to get our sigmoid non-linearity\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we define as: cost = truth - predicted\n",
    "# If we take the absolute of cost, i.e.: cost = |truth - predicted|\n",
    "# we get the L1 loss function. \n",
    "criterion = nn.L1Loss() \n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simple weights/parameters update processes we did before\n",
    "# is call the gradient descent. SGD is the sochastic variant of\n",
    "# gradient descent. \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note**: Personally, I strongely encourage you to go through the [University of Washington course of machine learning regression](https://www.coursera.org/learn/ml-regression) to better understand the fundamentals of (i) ***gradient***, (ii) ***loss*** and (iii) ***optimizer***. But given that you know how to code it, the process of more complex variants of gradient/loss computation and optimizer's step is easy to grasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch model\n",
    "\n",
    "To train a model using PyTorch, we simply iterate through the no. of epochs and imperatively state the computations we want to perform. \n",
    "\n",
    "## Remember the steps?\n",
    "\n",
    " 1. Initialize \n",
    " 2. Forward Propagation\n",
    " 3. Backward Propagation\n",
    " 4. Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10000/10000 [00:03<00:00, 2559.55it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Initialization. \n",
    "# Note: When using PyTorch a lot of the manual weights\n",
    "#       initialization is done automatically when we define\n",
    "#       the model (aka architecture)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), \n",
    "            nn.Sigmoid())\n",
    "criterion = nn.MSELoss() \n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Reset the gradient after every epoch. \n",
    "    optimizer.zero_grad() \n",
    "    # Step 2: Foward Propagation\n",
    "    predictions = model(X_pt)\n",
    "    \n",
    "    # Step 3: Back Propagation \n",
    "    # Calculate the cost between the predictions and the truth.\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    # Note: The neat thing about PyTorch is it does the \n",
    "    #       auto-gradient computation, no more manually defining\n",
    "    #       derivative of functions and manually propagating\n",
    "    #       the errors layer by layer.\n",
    "    loss_this_epoch.backward()\n",
    "    \n",
    "    # Step 4: Optimizer take a step. \n",
    "    # Note: Previously, we have to manually update the \n",
    "    #       weights of each layer individually according to the\n",
    "    #       learning rate and the layer delta. \n",
    "    #       PyTorch does that automatically =)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log the loss value as we proceed through the epochs.\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again with 2 layers using PyTorch\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5000/5000 [00:03<00:00, 1640.25it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 177 ms, total: 3.19 s\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_dim = 5\n",
    "num_data, input_dim = X_pt.shape\n",
    "num_data, output_dim = Y_pt.shape\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                      nn.Sigmoid(), \n",
    "                      nn.Linear(hidden_dim, output_dim),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_pt)\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction > 0.5))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST: The \"Hello World\" of Neural Nets\n",
    "====\n",
    "\n",
    "Like any deep learning class, we ***must*** do the MNIST. \n",
    "\n",
    "The MNIST dataset is \n",
    "\n",
    " - is made up of handwritten digits \n",
    " - 60,000 examples training set\n",
    " - 10,000 examples test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.2.2.post3)\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (5.2.0)\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.17.2)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# We're going to install tensorflow here because their dataset access is simpler =)\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|ââââââââââ| 9707520/9912422 [00:12<00:00, 2903157.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:00, 41668.36it/s]                           \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:33, 49414.30it/s]\u001b[A\n",
      "  2%|â         | 40960/1648877 [00:01<00:28, 56215.37it/s]\u001b[A\n",
      "  6%|â         | 98304/1648877 [00:01<00:21, 71024.78it/s]\u001b[A\n",
      "  9%|â         | 155648/1648877 [00:01<00:16, 90365.64it/s]\u001b[A\n",
      " 13%|ââ        | 212992/1648877 [00:01<00:13, 108375.77it/s]\u001b[A\n",
      " 16%|ââ        | 270336/1648877 [00:02<00:11, 124291.92it/s]\u001b[A\n",
      " 20%|ââ        | 335872/1648877 [00:02<00:09, 142330.06it/s]\u001b[A\n",
      " 24%|âââ       | 401408/1648877 [00:02<00:07, 158049.80it/s]\u001b[A\n",
      " 28%|âââ       | 466944/1648877 [00:03<00:06, 181416.54it/s]\u001b[A\n",
      " 33%|ââââ      | 540672/1648877 [00:03<00:05, 203520.36it/s]\u001b[A\n",
      " 37%|ââââ      | 614400/1648877 [00:03<00:04, 228894.90it/s]\u001b[A\n",
      " 42%|âââââ     | 696320/1648877 [00:03<00:03, 256685.07it/s]\u001b[A\n",
      " 47%|âââââ     | 778240/1648877 [00:03<00:02, 291311.88it/s]\u001b[A\n",
      " 52%|ââââââ    | 860160/1648877 [00:04<00:02, 357543.91it/s]\u001b[A\n",
      " 55%|ââââââ    | 909312/1648877 [00:04<00:02, 319770.20it/s]\u001b[A\n",
      " 58%|ââââââ    | 958464/1648877 [00:04<00:02, 327221.45it/s]\u001b[A\n",
      " 62%|âââââââ   | 1015808/1648877 [00:04<00:01, 369551.48it/s]\u001b[A\n",
      " 65%|âââââââ   | 1064960/1648877 [00:04<00:01, 320486.59it/s]\u001b[A\n",
      " 70%|âââââââ   | 1155072/1648877 [00:04<00:01, 363001.11it/s]\u001b[A\n",
      " 75%|ââââââââ  | 1228800/1648877 [00:05<00:00, 422411.24it/s]\u001b[A\n",
      " 78%|ââââââââ  | 1286144/1648877 [00:05<00:00, 377737.47it/s]\u001b[A\n",
      " 82%|âââââââââ | 1359872/1648877 [00:05<00:00, 412489.28it/s]\u001b[A\n",
      " 85%|âââââââââ | 1409024/1648877 [00:05<00:00, 431840.00it/s]\u001b[A\n",
      " 90%|âââââââââ | 1482752/1648877 [00:05<00:00, 462082.00it/s]\u001b[A\n",
      " 93%|ââââââââââ| 1540096/1648877 [00:05<00:00, 487104.89it/s]\u001b[A\n",
      "1654784it [00:05, 279634.77it/s]                             \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8192it [00:00, 17364.24it/s]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST('../data', train=True, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Candies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(mnist_x_vector, mnist_y_vector):\n",
    "    pixels = mnist_x_vector.reshape((28, 28))\n",
    "    label = np.where(mnist_y_vector == 1)[0]\n",
    "    plt.title('Label is {}'.format(label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fifth image and label.\n",
    "show_image(mnist_train.data[5], mnist_train.targets[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets apply what we learn about multi-layered perceptron with PyTorch and apply it to the MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist_train.data.float()\n",
    "Y_mnist = mnist_train.targets.float()\n",
    "\n",
    "X_mnist_test = mnist_test.data.float()\n",
    "Y_mnist_test = mnist_test.targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [28, 28]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dimensions of the images.\n",
    "X_mnist = mnist_train.data.float().view(num_data, -1)\n",
    "Y_mnist = mnist_train.targets.float().unsqueeze(1)\n",
    "\n",
    "X_mnist_test = mnist_test.data.float().view(num_test_data, -1)\n",
    "Y_mnist_test = mnist_test.targets.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [784]\n",
      "Output Dim: [1]\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_dim = 500\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "losses = []\n",
    "plt.ion()\n",
    "\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_mnist)\n",
    "    loss_this_epoch = criterion(predictions, Y_mnist)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(losses)\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(X_mnist_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([np.argmax(_p) for _p in predictions.data.numpy()])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([np.argmax(_p) for _p in Y_mnist_test.data.numpy()])\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred == truth).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: lazyme in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (0.0.23)\n",
      "Requirement already satisfied: nltk in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: gensim in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from torch) (1.17.4)\n",
      "Requirement already satisfied: six in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from nltk) (1.13.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim) (1.3.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: requests in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.10.30)\n",
      "Requirement already satisfied: boto>=2.32 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.30 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.30)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda3\\envs\\torch-nlp\\lib\\runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Z370\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install torch tqdm lazyme nltk gensim\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Toxic Comments\n",
    "\n",
    "Lets apply what we learnt in a realistic task and **fight cyber-abuse with NLP**!\n",
    "\n",
    "From https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/\n",
    "\n",
    "> *The threat of abuse and harassment online means that many people stop <br>*\n",
    "> *expressing themselves and give up on seeking different opinions. <br>*\n",
    "> *Platforms struggle to effectively facilitate conversations, leading many <br>*\n",
    "> *communities to limit or completely shut down user comments.*\n",
    "\n",
    "\n",
    "The goal of the task is to build a model to detect different types of of toxicity:\n",
    "\n",
    " - toxic\n",
    " - severe toxic\n",
    " - threats\n",
    " - obscenity\n",
    " - insults\n",
    " - identity-based hate\n",
    " \n",
    "In this part, you'll be munging the data as how I would be doing it at work. \n",
    "\n",
    "Your task is to train a feed-forward network on the toxic comments given the skills we have accomplished thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging into the data...\n",
    "\n",
    "If you're using linux/Mac you can use these bang commands in the notebook:\n",
    "\n",
    "```\n",
    "!pip3 install kaggle\n",
    "!mkdir -p /content/.kaggle/\n",
    "!echo '{\"username\":\"natgillin\",\"key\":\"54ae95ab760b52c3307ed4645c6c9b5d\"}' > /content/.kaggle/kaggle.json\n",
    "!chmod 600 /content/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
    "!unzip /content/.kaggle/competitions/jigsaw-toxic-comment-classification-challenge/*\n",
    "```\n",
    "\n",
    "Otherwise, download the data from https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('D:/projects/tsundoku-master/data/toxic/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79        Hi! I am back again!\\nLast warning!\\nStop undo...\n",
       "176       I think that your a Fagget get a oife and burn...\n",
       "600       I'm also a sock puppet of this account...SUPRI...\n",
       "802       Fuck you, Smith. Please have me notified when ...\n",
       "1017      WOULDN'T BE THE FIRST TIME BITCH. FUCK YOU I'L...\n",
       "                                ...                        \n",
       "157718    bitch \\nyou are a fucking hore. you suck dick ...\n",
       "158717    stupid head \\n\\nYOur dumb and you are stupid d...\n",
       "158856    Hey \\n\\nhey faggot, are you dead yet? or are y...\n",
       "159029                                  Death to Musulmans!\n",
       "159400    Shalom \\n\\nSemite, get the fuck out of here. I...\n",
       "Name: comment_text, Length: 478, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['threat'] == 1]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please stop. If you continue to ignore our policies by introducing inappropriate pages to Wikipedia, you will be blocked.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[3712]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['comment_text_tokenzied'] = df_train['comment_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just in case your Jupyter kernel dies, save the tokenized text =)\n",
    "\n",
    "# To save your tokenized text you can do this:\n",
    "import pickle\n",
    "with open('train_tokenized_text.pkl', 'wb') as fout:\n",
    "    pickle.dump(df_train['comment_text_tokenzied'], fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load it back:\n",
    "import pickle\n",
    "with open('train_tokenized_text.pkl', 'rb') as fin:\n",
    "    df_train['comment_text_tokenzied'] = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get a one-hot?\n",
    "\n",
    "There are many variants of how to get your one-hot embeddings from the individual columns.\n",
    "\n",
    "This is one way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_column_names = \"toxic\tsevere_toxic\tobscene\tthreat\tinsult\tidentity_hate\".split()\n",
    "df_train[label_column_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df_train[label_column_names].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot to indices of the column.\n",
    "\n",
    "print(np.argmax(df_train[label_column_names].values, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.vocab = Dictionary(texts)\n",
    "        special_tokens = {'<pad>': 0, '<unk>':1}\n",
    "        self.vocab = Dictionary(texts)\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Vectorize labels\n",
    "        self.labels = torch.tensor(labels)\n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts)\n",
    "        \n",
    "        self.num_labels = len(labels[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent, \n",
    "                'y':self.labels[index], \n",
    "                'x_len':len(vectorized_sent)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(self.vocab.doc2idx(tokens))\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_column_names = \"toxic\tsevere_toxic\tobscene\tthreat\tinsult\tidentity_hate\".split()\n",
    "toxic_data = ToxicDataset(df_train['comment_text_tokenzied'],\n",
    "                          df_train[label_column_names].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([2554, 1465,  586,  ...,    0,    0,    0]),\n",
       " 'y': tensor([0, 0, 0, 0, 0, 0]),\n",
       " 'x_len': 4948}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_data[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "dataloader = DataLoader(dataset=toxic_data, \n",
    "                        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(nn.Module):\n",
    "    def __init__(self, max_len, num_labels, vocab_size, embedding_size, hidden_dim):\n",
    "        super(FFNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embedding_size, \n",
    "                                       padding_idx=0)\n",
    "        # The no. of inputs to the linear layer is the \n",
    "        # no. of tokens in each input * embedding_size\n",
    "        self.linear1 = nn.Linear(embedding_size*max_len, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_labels)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # We want to flatten the inputs so that we get the matrix of shape.\n",
    "        # batch_size x no. of tokens in each input * embedding_size\n",
    "        batch_size, max_len = inputs.shape\n",
    "        embedded = self.embeddings(inputs).view(batch_size, -1)\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        return F.sigmoid(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/7979 [00:00<?, ?it/s]D:\\apps\\Anaconda3\\envs\\torch-nlp\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▏| 7893/7979 [03:47<00:02, 35.36it/s]"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embedding_size = 100\n",
    "learning_rate = 0.003\n",
    "hidden_size = 100\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# Hint: the CBOW model object you've created.\n",
    "model = FFNet(toxic_data.max_len, \n",
    "              len(label_column_names),\n",
    "              toxic_data.vocab_size, \n",
    "              embedding_size=embedding_size, \n",
    "              hidden_dim=hidden_size).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "losses = []\n",
    "num_epochs = 50\n",
    "for _e in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        x = batch['x'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        # Zero gradient.\n",
    "        optimizer.zero_grad()\n",
    "        # Feed forward.\n",
    "        predictions = model(x)\n",
    "        loss = criterion(predictions, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(float(loss))\n",
    "        \n",
    "    print(sum(epoch_loss)/len(epoch_loss))\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(text):\n",
    "    # Vectorize and Pad.\n",
    "    vectorized_sent = toxic_data.vectorize(word_tokenize(text))\n",
    "    pad_dim = (0, toxic_data.max_len - len(vectorized_sent))\n",
    "    vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "    # Forward Propagation.\n",
    "    # Unsqueeze because model is expecting `batch_size` x `sequence_len` shape.\n",
    "    outputs = model(vectorized_sent.unsqueeze(0).to(device)).squeeze()\n",
    "    # To get the boolean output, we check if outputs are > 0.5\n",
    "    return [int(l > 0.5) for l in outputs]\n",
    "    # What happens if you use torch.max instead? =)\n",
    "    ##return label_column_names[int(torch.max(outputs, dim=1).indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a nice message.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_column_names)\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

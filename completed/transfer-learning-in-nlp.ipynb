{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Candies \n",
    "\n",
    "# Run the notebook readable w/o wanrings.\n",
    "# P/S: Not a good habit to do this, but squelching warnings \n",
    "#      so that the notebook is easier to demo.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\r\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-zs95_n96\r\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-zs95_n96\r\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (1.16.4)\r\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (1.9.237)\r\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (2.22.0)\r\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (4.36.1)\r\n",
      "Requirement already satisfied, skipping upgrade: regex in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (2019.8.19)\r\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.1) (0.1.83)\r\n",
      "Collecting sacremoses (from transformers==2.2.1)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\r\n",
      "\u001b[K     |████████████████████████████████| 860kB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.1) (0.9.4)\r\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.1) (0.2.1)\r\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.237 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.1) (1.12.237)\r\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.1) (3.0.4)\r\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.1) (2019.9.11)\r\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.1) (2.8)\r\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.1) (1.24.2)\r\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.1) (1.12.0)\r\n",
      "Requirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.1) (7.0)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.1) (0.13.2)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.237->boto3->transformers==2.2.1) (2.8.0)\r\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.237->boto3->transformers==2.2.1) (0.15.2)\r\n",
      "Building wheels for collected packages: transformers, sacremoses\r\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-2.2.1-cp36-none-any.whl size=368468 sha256=d6ea99a53034467df6903ef897d09d0618a2ca784c6b25538988e1567e84a48d\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-woe02_w3/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=1a8ce2a8c31ec7163c737be1874c421d707cd00bc5c134c4c5ee6b42e40f2c8d\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\r\n",
      "Successfully built transformers sacremoses\r\n",
      "Installing collected packages: sacremoses, transformers\r\n",
      "Successfully installed sacremoses-0.0.35 transformers-2.2.1\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch) (1.16.4)\r\n"
     ]
    }
   ],
   "source": [
    "# Install the additional libaries.\n",
    "! pip install -U git+https://github.com/huggingface/transformers\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The first section of this notebook will first ***very*** briefly introduce some background concepts that's good to know about \n",
    "\n",
    "- The ImageNet Moment in NLP\n",
    "- A Zoo of Pre-trained Models\n",
    "- BERT (Bidirectional Encoder Representation from Transformers) Basics, one of the more popular transfer learning models for NLP and \n",
    "\n",
    "\n",
    "The second section** demonstrates how you can the BERT model from `pytorch_transformer` library to: \n",
    "\n",
    "1. **Convert text to array/list of floats** \n",
    "2. **Fill in the blanks** \n",
    "\n",
    "<!--\n",
    "3. **Fine-tune the pre-trained model** based on the data you want to use for a specific task\n",
    "4. **Apply the fine-tuned model** to a couple of downstream tasks\n",
    "-->\n",
    "\n",
    "### References\n",
    "\n",
    "I'll strongly recommend these readings to better understand/appreciate the first part of the notebook =)\n",
    "\n",
    " - [Rush (2018) blogpost](https://nlp.seas.harvard.edu/2018/04/03/attention.html) on \"The Annotated Transformer\" that explains the explaining the Transformer architecture \n",
    " - [Ruder et al. (2019) tutorial](http://ruder.io/state-of-transfer-learning-in-nlp/index.html) on \"Transfer Learning in NLP\" @ NAACL\n",
    " - [Weng (2019) blogpost](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html) on \"Generalized Language Models\"\n",
    " - https://github.com/huggingface/transformers\n",
    " - https://github.com/explosion/spacy-transformers\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: The ImageNet Moment for NLP \n",
    "\n",
    "\n",
    "Transfer learning gained traction in Computer Vision, made popular by the [ImageNet](http://www.image-net.org) and [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) image classification task. Similarly, transfer learning gained popularity when a wave of Transformer based models, with the BERT model being the more popular one from the zoo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: A Zoo of Pre-trained Models\n",
    "\n",
    "There's a whole variety of transfer learning pre-trained models in the wild. [Sanh et al. (2019)](https://arxiv.org/abs/1910.01108) puts them nicely into a chart of the no. of parameters* of the model with respect to the dates the models were released: \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/4140/1*IFVX74cEe8U5D1GveL1uZA.png\" alt=\"DistilBERT\" style=\"width:700px;\"/>\n",
    "\n",
    "***Note:** \"*Parameters*\" approximates to how much \"*memory*\"/\"*information*\" the model is storing after pre-training.\n",
    "\n",
    "\n",
    "<!-- \n",
    "Here's a summary inspired by [Weng's (2019) blogpost](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html):\n",
    "\n",
    "| Name | Architecture | Autoregressive | No. of Parameters | Release Date | Pre-training | Downstream tasks | Downstream Model | \n",
    "|:-|:-|:-:|:-:|:-:|:-:|:-:|:-|\n",
    "| [ELMo](https://allennlp.org/elmo) | 2-layers BiLSTM | Yes | 94M | Apr 2018 | Unsupervised | Feature-based | Task-agnostic | None | \n",
    "| [ULMFit](http://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html) | AWD-LSTM | Yes | ?? | Apr 2018 | Unsupervised | Feature-based | Task-agnostic | None | \n",
    "| [GPT](https://openai.com/blog/language-unsupervised/) | Transformer Decoder | Yes | 110M | Jul 2018 | Unsupervised | Model-baed | Task-agnostic | Pre-trained layers + Task layers | \n",
    "| [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) | Transformer Encoder | No | 340M | Oct 2018 | Unsupervised | Model-based | Task-agnostic | Pre-trained layers + Task layers | \n",
    "| [Transfomer ElMo](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/training_transformer_elmo.md) | Transformer Decoder | Yes | 465M | Jan 2019 | Unsupervised | Task-agnostic | Pre-trained layers + Task layers | \n",
    "| [GPT-2](https://openai.com/blog/better-language-models/) | Transformer Decoder | Yes | 1500M | Feb 2019 | Unsupervised | Model-baed | Task-agnostic | Pre-trained layers + Task layers | \n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: BERT Basics\n",
    "\n",
    "Lets start with the elephant in the zoo!\n",
    "\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/BERT-input-embedding.png\" alt=\"BERTInputs\" style=\"width:700px;\"/>\n",
    "\n",
    "First the input string needs to prepended with the `[CLS]` token, this special token is used to allocate some placeholder than can be used to produce the labels for classification task. \n",
    "\n",
    "Then, for each sentence that's inside the text string, explicit `[SEP]` tokens need to be added to indicate on of a sentence. \n",
    "\n",
    "\n",
    "Then string input needs to be converted to three components before passing them to Transformer model:\n",
    "\n",
    " - **WordPiece tokenization**: The text (string) input would be split into tokens segmented using the WordPiece model that may split natural words further into sub-words units to handle rare/unknown words. \n",
    " \n",
    " - **Segment Indices**: This part indicates the start and end of the sentences in the string inputs, delimited by the special `[SEP]` token.\n",
    " \n",
    " - **Position Indices**: This part simply enumerates the index of WordPiece tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 5552210.16B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'my', 'dog', 'is', 'cute', '[SEP]', 'he', 'likes', 'playing', '[SEP]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "# A tokenizer will split the text into the appropriate sub-parts (aka. tokens).\n",
    "# Depending on how the pre-trained model is trained, the tokenizers defers.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Example of a tokenized input after WordPiece Tokenization.\n",
    "text = \"[CLS] my dog is cute [SEP] he likes playing [SEP]\"\n",
    "print(tokenizer.wordpiece_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha! The output is differen from texample in the image above!!\n",
    "\n",
    "That's because the full word `playing` is inside the `BertTokenizer`'s WordPiece vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"playing\" in tokenizer.wordpiece_tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"slacking\" in tokenizer.wordpiece_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try another verb that's not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'my', 'dog', 'is', 'cute', '[SEP]', 'he', 'likes', 'slack', '##ing', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] my dog is cute [SEP] he likes slacking [SEP]\"\n",
    "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text) # There, we see the ##ing token!\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We fetch the index of these words from the model's vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2026, 3899, 2003, 10140, 102, 2002, 7777, 19840, 2075, 102]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "token_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corresponding to the text input, we need to create the \"segment indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11]) <class 'list'> <class 'torch.Tensor'>\n",
      "torch.Size([1, 11]) <class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We need to create an array that indicates the end of sentences, delimited by [SEP]\n",
    "text = \"[CLS] my dog is cute [SEP] he likes slacking [SEP]\"\n",
    "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)  # There, we see the ##ing token!\n",
    "\n",
    "# First we find the indices of `[SEP]`, and incrementally adds it up. \n",
    "# Here's some Numpy gymnastics... \n",
    "# Thanks to @divakar https://stackoverflow.com/a/58316889/610569\n",
    "m = np.asarray(tokenized_text) == \"[SEP]\"\n",
    "segments_ids = m.cumsum()-m\n",
    "\n",
    "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
    "\n",
    "# See the type change?\n",
    "print(tokens_tensor.shape, type(token_indices), type(tokens_tensor))\n",
    "print(segments_tensors.shape, type(segments_ids), type(segments_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we convert the list and numpy arrays to PyTorch's Tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11]) <class 'list'> <class 'torch.Tensor'>\n",
      "torch.Size([1, 11]) <class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
    "\n",
    "# See the type change?\n",
    "print(tokens_tensor.shape, type(token_indices), type(tokens_tensor))\n",
    "print(segments_tensors.shape, type(segments_ids), type(segments_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets convert our input text to an array of number!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 189631.25B/s]\n",
      "100%|██████████| 440473133/440473133 [00:14<00:00, 31447058.23B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# When using the BERT model for \"encoding\", i.e. convert string to array of floats, \n",
    "# we use the `BertModel` object from pytorch transformer library.\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval(); model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0737,  0.1229, -0.1612,  ...,  0.1235,  0.2381,  0.0880],\n",
      "         [ 0.5442,  0.6884, -0.0744,  ..., -0.0346,  0.1388, -0.4474],\n",
      "         [ 0.7117,  0.6298, -0.0084,  ...,  0.1541,  0.1260, -0.1969],\n",
      "         ...,\n",
      "         [ 0.6583,  0.4991, -0.1022,  ...,  0.2715, -0.2863, -0.4839],\n",
      "         [-0.1440, -0.3067, -0.3331,  ...,  0.4313,  0.1080,  0.0214],\n",
      "         [ 0.9325,  0.2506,  0.0805,  ...,  0.1434, -0.8708, -0.4659]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
    "    \n",
    "print(encoded_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the shape is 3-Dimension, i.e. (`batch_size`, `sequence_length`, `hidden_dimension`), where\n",
    "\n",
    " - `batch_size` corresponds to \"no. of sentences\"\n",
    " - `sequence_length` corresponds to \"no. of tokens\"\n",
    " - `hidden_dimensions` refers to the \"information for each word provided by the pre-trained model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The BERT model is very good at fill-in-the-blank task\n",
    "\n",
    "The BERT model is trained using a \"cloze\" task where words are randomly replaced with the `[MASK]` symbols and the model learns to adjust its parameters such that it learns which words are most probable to fit into the `[MASK]` symbols.\n",
    "\n",
    "When using the BERT model for \"guessing missing words\", we use the `BertForMaskedLM` object from pytorch transformer library. Here's an example if we blank out words in the sentence, BERT is able to find the appropriate word to fill it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval(); model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to create an array that indicates the end of sentences, delimited by [SEP]\n",
    "text = \"[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\"\n",
    "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)\n",
    "token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Create the segment indices.\n",
    "m = np.asarray(tokenized_text) == \"[SEP]\"\n",
    "segments_ids = m.cumsum()-m\n",
    "\n",
    "# Convert them to the arrays to pytorch tensors.\n",
    "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
    "\n",
    "# Apply the model to the inputs.\n",
    "with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
    "    outputs, *_ = model(tokens_tensor.to(device), \n",
    "                        token_type_ids=segments_tensors.to(device))\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the inputs.\n",
    "with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
    "    outputs, *_ = model(tokens_tensor.to(device), token_type_ids=segments_tensors.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the output tensor shape is different. The dimensions now refers to the (`batch_size`, `sequence_length`, `vocab_size`), where: \n",
    "\n",
    " - `batch_size` corresponds to \"no. of sentences\"\n",
    " - `sequence_length` corresponds to \"no. of tokens\"\n",
    " - `vocab_size` is the no. of wordpiece tokens in the tokenizer's vocabulary, we'll use this to fetch the correct word that we want to use to fill in the `[MASK]` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'please', 'don', \"##'\", '##t', 'let', 'the', '[MASK]', 'out', 'of', 'the', '[MASK]', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'please', 'don', \"##'\", '##t', 'let', 'the', '[MASK]', 'out', 'of', 'the', '[MASK]', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Lets remember our original masked sentence.\n",
    "print(tokenized_text)\n",
    "# We have to check where the masked token is from the original text. \n",
    "mask_index = tokenized_text.index('[MASK]') \n",
    "assert mask_index == 7 # The 7th token.\n",
    "\n",
    "# Then we fetch the vector for the 7th value, \n",
    "# The [0, mask_index] refers to accessing vector of vocab_size for\n",
    "# the 0th sentence, mask_index-th token.\n",
    "output_value = outputs[0, mask_index]\n",
    "\n",
    "# As a sanity check we can see that the shape of the output_value\n",
    "# is the same as the `vocab_size` from the outputs' shape.\n",
    "assert int(output_value.shape[0]) == len(tokenizer.wordpiece_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\n",
      "['cat']\n"
     ]
    }
   ],
   "source": [
    "# Lets recap the original sentence with the masked word.\n",
    "print(text)\n",
    "\n",
    "# We have to check where the first masked token is from the original text. \n",
    "mask_index = tokenized_text.index('[MASK]') \n",
    "output_value = outputs[0, mask_index]\n",
    "\n",
    "## We use torch.argmax to get the index with the highest value.\n",
    "mask_word_in_vocab = int(torch.argmax(output_value))\n",
    "print(tokenizer.convert_ids_to_tokens([mask_word_in_vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\n",
      "['cat']\n",
      "['way']\n"
     ]
    }
   ],
   "source": [
    "# Lets recap the original sentence with the masked word.\n",
    "print(text)\n",
    "\n",
    "# We have to check where the masked tokens are from the original text. \n",
    "for mask_index, token in enumerate(tokenized_text):\n",
    "    if token == '[MASK]':\n",
    "        output_value = outputs[0, mask_index]\n",
    "        mask_word_in_vocab = int(torch.argmax(output_value))\n",
    "        print(tokenizer.convert_ids_to_tokens([mask_word_in_vocab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets make the fill-in-the-blank feature into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_the_blanks(text, model, tokenizer, return_str=False):\n",
    "    tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)\n",
    "    token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Create the segment indices.\n",
    "    m = np.asarray(tokenized_text) == \"[SEP]\"\n",
    "    segments_ids = m.cumsum()-m\n",
    "    # Convert them to the arrays to pytorch tensors.\n",
    "    tokens_tensor = torch.tensor([token_indices]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "    \n",
    "    # Apply the model to the inputs.\n",
    "    with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
    "        outputs, *_ = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    \n",
    "    output_tokens = []\n",
    "    for mask_index, token_id in enumerate(token_indices):\n",
    "        token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "        if token == '[MASK]':\n",
    "            output_value = outputs[0, mask_index]\n",
    "            # The masked word index in the vocab.\n",
    "            mask_word_in_vocab = int(torch.argmax(output_value))\n",
    "            token = tokenizer.convert_ids_to_tokens([mask_word_in_vocab])[0]\n",
    "        output_tokens.append(token)\n",
    "        \n",
    "    return \" \".join(output_tokens).replace(\" ##\", \"\").replace(\" ' t \", \"'t \") if return_str else output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] please don't let the cat out of the way . [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval(); model.to(device)\n",
    "\n",
    "text = \"[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\"\n",
    "print(fill_in_the_blanks(text, model, tokenizer, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] i like to drink beer and eat meat . [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] i like to drink beer and eat [MASK] . [SEP]\"\n",
    "print(fill_in_the_blanks(text, model,tokenizer, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] i like to drink coffee and eat it . [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] i like to drink coffee and eat [MASK] . [SEP]\"\n",
    "print(fill_in_the_blanks(text, model, tokenizer, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT models. \n",
    "\n",
    "By default, the pre-trained model is trained on the\n",
    "\n",
    " - BookCorpus, ~800M words\n",
    " - English Wikipedia, ~2500M words\n",
    " \n",
    "If we want the model to adapt to a specific domain, we need to ***fine-tune*** the model. This section demonstrate how this can be done with the same PyTorch Transformer Library.\n",
    "\n",
    "### Lets use some Shakespeare poems...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenix_turtle = \"\"\"Truth may seem but cannot be;\\nBeauty brag but ’tis not she;\\nTruth and beauty buried be.\"\"\"\n",
    "sonnet20 = \"\"\"A woman’s face with Nature’s own hand painted\\nHast thou, the master-mistress of my passion;\\nA woman’s gentle heart, but not acquainte\\nWith shifting change, as is false women’s fashion;\"\"\"\n",
    "sonnet1 = \"\"\"From fairest creatures we desire increase,\\nThat thereby beauty’s rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\"\"\"\n",
    "sonnet73 = \"\"\"In me thou see’st the glowing of such fire,\\nThat on the ashes of his youth doth lie,\\nAs the death-bed whereon it must expire,\\nConsum’d with that which it was nourish’d by.\"\"\"\n",
    "venus_adonis = \"\"\"It shall be cause of war and dire events,\\nAnd set dissension ‘twixt the son and sire;\\nSubject and servile to all discontents,\\nAs dry combustious matter is to fire:\\nSith in his prime Death doth my love destroy,\\nThey that love best their loves shall not enjoy\\n\"\"\"\n",
    "sonnet29 = \"\"\"When, in disgrace with fortune and men’s eyes,\\nI all alone beweep my outcast state,\\nAnd trouble deaf heaven with my bootless cries,\\nAnd look upon myself and curse my fate,\"\"\"\n",
    "sonnet130 = \"\"\"I have seen roses damask’d, red and white,\\nBut no such roses see I in her cheeks;\\nAnd in some perfumes is there more delight\\nThan in the breath that from my mistress reeks.\"\"\"\n",
    "sonnet116 = \"\"\"Love’s not Time’s fool, though rosy lips and cheeks\\nWithin his bending sickle’s compass come;\\nLove alters not with his brief hours and weeks,\\nBut bears it out even to the edge of doom.\"\"\"\n",
    "sonnet18 = \"\"\"But thy eternal summer shall not fade\\nNor lose possession of that fair thou ow’st;\\nNor shall Death brag thou wander’st in his shade,\\nWhen in eternal lines to time thou grow’st;\\nSo long as men can breathe or eyes can see,\\nSo long lives this, and this gives life to thee.\"\"\"\n",
    "anthony_cleo = \"\"\"She made great Caesar lay his sword to bed;\\nHe plowed her, and she cropped.\"\"\"\n",
    "\n",
    "shakespeare = [phoenix_turtle, sonnet20, sonnet1, sonnet73, venus_adonis,\n",
    "              sonnet29, sonnet130, sonnet116, sonnet18, anthony_cleo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [00:00<00:00, 105911.66B/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM, BertTokenizer\n",
    "\n",
    "# Load the BERT model.\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Load the BERT Tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "# Load the BERT Config.\n",
    "config = BertConfig.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And if we try \"fill-in-the-blanks\" on Shakepearian text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] that on the ashes of his youth , lie\n"
     ]
    }
   ],
   "source": [
    "truth = \"that on the ashes of his youth doth lie\"\n",
    "masked_text = \"[CLS] that on the ashes of his youth [MASK] lie\"\n",
    "print(fill_in_the_blanks(masked_text, model, tokenizer, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmmmm, thou hast not read Shakespeare enough.\n",
    "\n",
    "Lets try to fine-tuned our model to shakespearian text. \n",
    "\n",
    "To do so, here's some boilerplates to munge data into an object use by the model training routine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        \"\"\"\n",
    "        :param texts: A list of documents, each document is a list of strings.\n",
    "        :rtype texts: list(string)\n",
    "        \"\"\"\n",
    "        tokenization_process = lambda s: tokenizer.build_inputs_with_special_tokens(\n",
    "                                             tokenizer.convert_tokens_to_ids(\n",
    "                                                 tokenizer.tokenize(s.lower())))\n",
    "        pad_sent = lambda x: np.pad(x, (0,tokenizer.max_len_single_sentence - len(x)), 'constant', \n",
    "                                    constant_values=tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
    "        self.examples = torch.tensor([pad_sent(tokenization_process(doc)) for doc in texts])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.examples[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Dataset object.\n",
    "train_dataset = TextDataset(shakespeare, tokenizer)\n",
    "# Initalize the DataLoader object, `batch_size=2` means reads 2 poems at a time.\n",
    "dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 510])\n"
     ]
    }
   ],
   "source": [
    "# 10 poems with 510 tokens per poems, \n",
    "# if poem has <510, pad with the 0th index.\n",
    "train_dataset.examples.shape\n",
    "\n",
    "# For each batch, we read 2 poems at a time.\n",
    "print(next(iter(dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1037, 2450,  ...,    0,    0,    0],\n",
       "        [ 101, 2009, 4618,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of a batch.\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It'll take some time to digest this `mask_tokens` function. \n",
    "\n",
    "But all it does is that 80% of the time, it'll mask the tokens, 10% of the time it'll random replace the masked word with another word, and 10% of the time it'll keep the original. You can read more in the original implementation at https://github.com/huggingface/transformers/blob/master/examples/run_lm_finetuning.py#L143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(inputs, tokenizer, mlm_probability=0.8):\n",
    "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
    "    labels = inputs.clone()\n",
    "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -1  # We only compute loss on masked tokens\n",
    "\n",
    "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    # 10% of the time, we replace masked input tokens with random word\n",
    "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "    inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers.optimization import get_linear_schedule_with_warmup as WarmupLinearSchedule\n",
    "\n",
    "Arguments = namedtuple('Arguments', ['learning_rate', 'weight_decay', 'adam_epsilon', 'num_warmup_steps', \n",
    "                                     'max_steps', 'num_train_epochs'])\n",
    "\n",
    "args = Arguments(learning_rate=5e-3, weight_decay=0.0, adam_epsilon=1e-8, num_warmup_steps=0, # Optimizer arguments\n",
    "                 max_steps=20, num_train_epochs=50  # Training routine arugments\n",
    "                )  \n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "scheduler = WarmupLinearSchedule(optimizer, num_warmup_steps=args.num_warmup_steps, num_training_steps=args.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t0, 1, 2, 3, 4, \n",
      "Epoch: 1 \t0, 1, 2, 3, 4, \n",
      "Epoch: 2 \t0, 1, 2, 3, 4, \n",
      "Epoch: 3 \t0, 1, 2, 3, 4, \n",
      "Epoch: 4 \t0, 1, 2, 3, 4, \n",
      "Epoch: 5 \t0, 1, 2, 3, 4, \n",
      "Epoch: 6 \t0, 1, 2, 3, 4, \n",
      "Epoch: 7 \t0, 1, 2, 3, 4, \n",
      "Epoch: 8 \t0, 1, 2, 3, 4, \n",
      "Epoch: 9 \t0, 1, 2, 3, 4, \n",
      "Epoch: 10 \t0, 1, 2, 3, 4, \n",
      "Epoch: 11 \t0, 1, 2, 3, 4, \n",
      "Epoch: 12 \t0, 1, 2, 3, 4, \n",
      "Epoch: 13 \t0, 1, 2, 3, 4, \n",
      "Epoch: 14 \t0, 1, 2, 3, 4, \n",
      "Epoch: 15 \t0, 1, 2, 3, 4, \n",
      "Epoch: 16 \t0, 1, 2, 3, 4, \n",
      "Epoch: 17 \t0, 1, 2, 3, 4, \n",
      "Epoch: 18 \t0, 1, 2, 3, 4, \n",
      "Epoch: 19 \t0, 1, 2, 3, 4, \n",
      "Epoch: 20 \t0, 1, 2, 3, 4, \n",
      "Epoch: 21 \t0, 1, 2, 3, 4, \n",
      "Epoch: 22 \t0, 1, 2, 3, 4, \n",
      "Epoch: 23 \t0, 1, 2, 3, 4, \n",
      "Epoch: 24 \t0, 1, 2, 3, 4, \n",
      "Epoch: 25 \t0, 1, 2, 3, 4, \n",
      "Epoch: 26 \t0, 1, 2, 3, 4, \n",
      "Epoch: 27 \t0, 1, 2, 3, 4, \n",
      "Epoch: 28 \t0, 1, 2, 3, 4, \n",
      "Epoch: 29 \t0, 1, 2, 3, 4, \n",
      "Epoch: 30 \t0, 1, 2, 3, 4, \n",
      "Epoch: 31 \t0, 1, 2, 3, 4, \n",
      "Epoch: 32 \t0, 1, 2, 3, 4, \n",
      "Epoch: 33 \t0, 1, 2, 3, 4, \n",
      "Epoch: 34 \t0, 1, 2, 3, 4, \n",
      "Epoch: 35 \t0, 1, 2, 3, 4, \n",
      "Epoch: 36 \t0, 1, 2, 3, 4, \n",
      "Epoch: 37 \t0, 1, 2, 3, 4, \n",
      "Epoch: 38 \t0, 1, 2, 3, 4, \n",
      "Epoch: 39 \t0, 1, 2, 3, 4, \n",
      "Epoch: 40 \t0, 1, 2, 3, 4, \n",
      "Epoch: 41 \t0, 1, 2, 3, 4, \n",
      "Epoch: 42 \t0, 1, 2, 3, 4, \n",
      "Epoch: 43 \t0, 1, 2, 3, 4, \n",
      "Epoch: 44 \t0, 1, 2, 3, 4, \n",
      "Epoch: 45 \t0, 1, 2, 3, 4, \n",
      "Epoch: 46 \t0, 1, 2, 3, 4, \n",
      "Epoch: 47 \t0, 1, 2, 3, 4, \n",
      "Epoch: 48 \t0, 1, 2, 3, 4, \n",
      "Epoch: 49 \t0, 1, 2, 3, 4, \n"
     ]
    }
   ],
   "source": [
    "for _e in range(args.num_train_epochs):\n",
    "    print('Epoch:', _e, '\\t' ,end='')\n",
    "    for step, batch in enumerate(iter(dataloader)):\n",
    "        print(step, end=', ')\n",
    "        optimizer.zero_grad()\n",
    "        # Randomly mask the tokens 80% of the time. \n",
    "        inputs, labels = mask_tokens(batch, tokenizer)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Initialize the model to train mode.\n",
    "        model.train()\n",
    "        # Feed forward the inputs through the models.\n",
    "        loss, _ = model(inputs, masked_lm_labels=labels)\n",
    "        # Backpropagate the loss.\n",
    "        loss.backward()\n",
    "        # Step through the optimizer.\n",
    "        optimizer.step()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [UNK] on the ashes of his youth [PAD] lie [SEP]\n"
     ]
    }
   ],
   "source": [
    "truth = \"That on the ashes of his youth doth lie\"\n",
    "masked_text = \"[CLS] That on the ashes of his youth [MASK] lie [SEP]\"\n",
    "print(fill_in_the_blanks(masked_text, model, tokenizer, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

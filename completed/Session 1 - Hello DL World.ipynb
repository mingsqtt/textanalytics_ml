{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: If you're using a Mac/Linux, you can check your environment with these commands:\n",
    "\n",
    "```\n",
    "!which pip3\n",
    "!which python3\n",
    "!ls -lah /usr/local/bin/python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: torch==1.3.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torch==1.3.0) (1.17.2)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.17.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: setuptools in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install torch==1.3.0\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=====\n",
    "\n",
    "**Perceptron** algorithm is a:\n",
    "\n",
    "> \"*system that depends on **probabilistic** rather than deterministic principles for its operation, gains its reliability from the **properties of statistical measurements obtain from a large population of elements***\"\n",
    "> \\- Frank Rosenblatt (1957)\n",
    "\n",
    "Then the news:\n",
    "\n",
    "> \"*[Perceptron is an] **embryo of an electronic computer** that [the Navy] expects will be **able to walk, talk, see, write, reproduce itself and be conscious of its existence.***\"\n",
    "> \\- The New York Times (1958)\n",
    "\n",
    "News quote cite from Olazaran (1996) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron in Bullets\n",
    "----\n",
    "\n",
    " - Perceptron learns to classify any linearly separable set of inputs. \n",
    " - Some nice graphics for perceptron with Go https://appliedgo.net/perceptron/  \n",
    "\n",
    "If you've got some spare time: \n",
    "\n",
    " - There's a whole book just on perceptron: https://mitpress.mit.edu/books/perceptrons\n",
    " - For watercooler gossips on perceptron in the early days, read [Olazaran (1996)](https://pdfs.semanticscholar.org/f3b6/e5ef511b471ff508959f660c94036b434277.pdf?_ga=2.57343906.929185581.1517539221-1505787125.1517539221)\n",
    " \n",
    " \n",
    "Perceptron in Math\n",
    "----\n",
    "\n",
    "Given a set of inputs $x$, the perceptron \n",
    "\n",
    " - learns $w$ vector to map the inputs to a real-value output between $[0,1]$\n",
    " - through the summation of the dot product of the $wÂ·x$ with a transformation function\n",
    " \n",
    " \n",
    "Perceptron in Picture\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ibin.co/4TyMU8AdpV4J.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron.png\", width=500)\n",
    "Image(url=\"https://ibin.co/4TyMU8AdpV4J.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note:** Usually, we use $x_1$ as the bias and fix the input to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron as a Workflow Diagram\n",
    "----\n",
    "\n",
    "If you're familiar with [mermaid flowchart](https://mermaidjs.github.io)\n",
    "\n",
    "```\n",
    ".. mermaid::\n",
    "\n",
    "    graph LR\n",
    "       subgraph Input\n",
    "          x_1\n",
    "          x_i \n",
    "          x_n\n",
    "       end\n",
    "       subgraph Perceptron\n",
    "            n1((s)) --> n2((\"f(s)\"))\n",
    "        end\n",
    "        x_1 --> |w_1| n1\n",
    "        x_i --> |w_i| n1\n",
    "        x_n --> |w_n| n1\n",
    "        n2 --> y[\"[0,1]\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://svgshare.com/i/AbJ.svg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron-mermaid.svg\", width=500)\n",
    "Image(url=\"https://svgshare.com/i/AbJ.svg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Process\n",
    "====\n",
    "\n",
    "To learn the weights, $w$, we use an **optimizer** to find the best-fit (optimal) values for $w$ such that the inputs correct maps to the outputs.\n",
    "\n",
    "Typically, process performs the following 4 steps iteratively.\n",
    "\n",
    "### **Initialization**\n",
    "\n",
    " - **Step 1**: Initialize weights vector\n",
    " \n",
    "### **Forward Propagation**\n",
    "\n",
    " \n",
    " - **Step 2a**: Multiply the weights vector with the inputs, sum the products, i.e. `s`\n",
    " - **Step 2b**: Put the sum through the sigmoid, i.e. `f()`\n",
    " \n",
    "### **Back Propagation**\n",
    " \n",
    " \n",
    " - **Step 3a**: Compute the errors, i.e. difference between expected output and predictions\n",
    " - **Step 3b**: Multiply the error with the **derivatives** to get the delta\n",
    " - **Step 3c**: Multiply the delta vector with the inputs, sum the product\n",
    " \n",
    "### **Optimizer takes a step**\n",
    "\n",
    " - **Step 4**: Multiply the learning rate with the output of Step 3c.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx): \n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    # Hint: let sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92414182, 0.57932425, 0.19466158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2.5, 0.32, -1.42]))             # [out]: array([0.92414182, 0.57932425, 0.19466158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75  ,  0.2176, -3.4364])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([2.5, 0.32, -1.42]))  # [out]: array([0.07010372, 0.24370766, 0.15676845])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predicted, truth):\n",
    "    return np.abs(truth - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([0.6, 1.0, 10.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8,  2.8, 89.2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([9.3, 4.0, 99.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing OR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = or_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = or_output = np.array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = or_input.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(or_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "======\n",
      "no. of rows = 4\n",
      "no. of cols = 2\n",
      "\n",
      "\n",
      "Outputs\n",
      "=======\n",
      "no. of cols = 1\n"
     ]
    }
   ],
   "source": [
    "print('Inputs\\n======')\n",
    "print('no. of rows =', num_data) \n",
    "print('no. of cols =', input_dim)\n",
    "print('\\n')\n",
    "print('Outputs\\n=======')\n",
    "print('no. of cols =', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Multiply the weights vector with the inputs, sum the products\n",
    "====\n",
    "\n",
    "To get the output of step 2a, \n",
    "\n",
    " - Itrate through each row of the data, `X`\n",
    " - For each column in each row, find the product of the value and the respective weights\n",
    " - For each row, compute the sum of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.71518937]\n",
      " [0.5488135 ]\n",
      " [1.26400287]]\n"
     ]
    }
   ],
   "source": [
    "# If we write it imperatively:\n",
    "summation = []\n",
    "for row in X:\n",
    "    sum_wx = 0\n",
    "    for feature, weight in zip(row, W):\n",
    "        sum_wx += feature * weight\n",
    "    summation.append(sum_wx)\n",
    "print(np.array(summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.71518937],\n",
       "       [0.5488135 ],\n",
       "       [1.26400287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we vectorize the process and use numpy.\n",
    "np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Single-Layer Model\n",
    "====\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.03 # How large a step to take per iteration.\n",
    "\n",
    "# Lets standardize and call our inputs X and outputs Y\n",
    "X = or_input\n",
    "Y = or_output\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "\n",
    "    # Step 2a: Multiply the weights vector with the inputs, sum the products, i.e. s\n",
    "    # Step 2b: Put the sum through the sigmoid, i.e. f()\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # Back propagation.\n",
    "    # Step 3a: Compute the errors, i.e. difference between expected output and predictions\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Step 3b: Multiply the error with the derivatives to get the delta\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "\n",
    "    # Step 3c: Multiply the delta vector with the inputs, sum the product (use np.dot)\n",
    "    # Step 4: Multiply the learning rate with the output of Step 3c.\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.95643415],\n",
       "       [0.95623017],\n",
       "       [0.99791935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[[int(prediction > 0.5)] for prediction in layer1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the XOR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = xor_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.003 # How large a step to take per iteration.\n",
    "\n",
    "# Lets drop the last row of data and use that as unseen test.\n",
    "X = xor_input\n",
    "Y = xor_output\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Back propagation.\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = sigmoid_derivative(layer1) * layer1_error\n",
    "\n",
    "    # update weights\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer1] # All correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't represent XOR with simple perceptron !!!\n",
    "====\n",
    "\n",
    "No matter how you change the hyperparameters or data, the XOR function can't be represented by a single perceptron layer.\n",
    " \n",
    "There's no way you can get all four data points to get the correct outputs for the XOR boolean operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving XOR (Add more layers)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "hidden_dim = 5\n",
    "# Initialize weights between the input layers and the hidden layer.\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the hidden layers and the output layer.\n",
    "W2 = np.random.random((hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.03\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    \n",
    "    # How much did we miss in the predictions?\n",
    "    layer2_error = cost(layer2, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
    "\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
    "    ##print(epoch_n, list((layer2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training input.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31284349],\n",
       "       [0.6213127 ],\n",
       "       [0.62323891],\n",
       "       [0.46427804]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 # Our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding another layer\n",
    "====\n",
    "\n",
    "Use the same process:\n",
    "    \n",
    "  1. Initialize\n",
    "  2. Forward Propagate\n",
    "  3. Back Propagate \n",
    "  4. Update (aka step)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "layer0to1_hidden_dim = 5\n",
    "layer1to2_hidden_dim = 5\n",
    "\n",
    "# Initialize weights between the input layers 0 ->  layer 1\n",
    "W1 = np.random.random((input_dim, layer0to1_hidden_dim))\n",
    "\n",
    "# Initialize weights between the layer 1 -> layer 2\n",
    "W2 = np.random.random((layer0to1_hidden_dim, layer1to2_hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the layer 2 -> layer 3\n",
    "W3 = np.random.random((layer1to2_hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "    layer3 = sigmoid(np.dot(layer2, W3))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    # How much did we miss in the predictions?\n",
    "    layer3_error = cost(layer3, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer3_delta = layer3_error * sigmoid_derivative(layer3)\n",
    "\n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer3 error (according to the weights)?\n",
    "    layer2_error = np.dot(layer3_delta, W3.T)\n",
    "    layer2_delta = layer3_error * sigmoid_derivative(layer2)\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W3 +=  learning_rate * np.dot(layer2.T, layer3_delta)\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50039537],\n",
       "       [0.50000003],\n",
       "       [0.9929507 ],\n",
       "       [0.50001378]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets do it with PyTorch \n",
    "\n",
    "First lets try a single perceptron and see that we can't train a model that can represent XOR. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Original XOR X input in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # Original XOR Y output in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu' if torch.cuda.is_available()  else 'cpu'\n",
    "# Converting the X to PyTorch-able data structure.\n",
    "X_pt = torch.tensor(X).float()\n",
    "X_pt = X_pt.to(device)\n",
    "# Converting the Y to PyTorch-able data structure.\n",
    "Y_pt = torch.tensor(Y, requires_grad=False).float()\n",
    "Y_pt = Y_pt.to(device)\n",
    "print(X_pt)\n",
    "print(Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Dim: 2\n",
      "Output Dim: 1\n"
     ]
    }
   ],
   "source": [
    "# Use tensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, input_dim = X_pt.shape\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, output_dim = Y_pt.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Sequential to define a simple feed-forward network.\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Use nn.Linear to get our simple perceptron\n",
    "            nn.Sigmoid()                      # Use nn.Sigmoid to get our sigmoid non-linearity\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we define as: cost = truth - predicted\n",
    "# If we take the absolute of cost, i.e.: cost = |truth - predicted|\n",
    "# we get the L1 loss function. \n",
    "criterion = nn.L1Loss() \n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simple weights/parameters update processes we did before\n",
    "# is call the gradient descent. SGD is the sochastic variant of\n",
    "# gradient descent. \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note**: Personally, I strongely encourage you to go through the [University of Washington course of machine learning regression](https://www.coursera.org/learn/ml-regression) to better understand the fundamentals of (i) ***gradient***, (ii) ***loss*** and (iii) ***optimizer***. But given that you know how to code it, the process of more complex variants of gradient/loss computation and optimizer's step is easy to grasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch model\n",
    "\n",
    "To train a model using PyTorch, we simply iterate through the no. of epochs and imperatively state the computations we want to perform. \n",
    "\n",
    "## Remember the steps?\n",
    "\n",
    " 1. Initialize \n",
    " 2. Forward Propagation\n",
    " 3. Backward Propagation\n",
    " 4. Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10000/10000 [00:03<00:00, 2676.56it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Initialization. \n",
    "# Note: When using PyTorch a lot of the manual weights\n",
    "#       initialization is done automatically when we define\n",
    "#       the model (aka architecture)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), \n",
    "            nn.Sigmoid())\n",
    "criterion = nn.MSELoss() \n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Reset the gradient after every epoch. \n",
    "    optimizer.zero_grad() \n",
    "    # Step 2: Foward Propagation\n",
    "    predictions = model(X_pt)\n",
    "    \n",
    "    # Step 3: Back Propagation \n",
    "    # Calculate the cost between the predictions and the truth.\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    # Note: The neat thing about PyTorch is it does the \n",
    "    #       auto-gradient computation, no more manually defining\n",
    "    #       derivative of functions and manually propagating\n",
    "    #       the errors layer by layer.\n",
    "    loss_this_epoch.backward()\n",
    "    \n",
    "    # Step 4: Optimizer take a step. \n",
    "    # Note: Previously, we have to manually update the \n",
    "    #       weights of each layer individually according to the\n",
    "    #       learning rate and the layer delta. \n",
    "    #       PyTorch does that automatically =)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log the loss value as we proceed through the epochs.\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again with 2 layers using PyTorch\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5000/5000 [00:02<00:00, 1851.74it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 158 ms, total: 2.83 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_dim = 5\n",
    "num_data, input_dim = X_pt.shape\n",
    "num_data, output_dim = Y_pt.shape\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                      nn.Sigmoid(), \n",
    "                      nn.Linear(hidden_dim, output_dim),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_pt)\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction > 0.5))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST: The \"Hello World\" of Neural Nets\n",
    "====\n",
    "\n",
    "Like any deep learning class, we ***must*** do the MNIST. \n",
    "\n",
    "The MNIST dataset is \n",
    "\n",
    " - is made up of handwritten digits \n",
    " - 60,000 examples training set\n",
    " - 10,000 examples test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.2.2.post3)\r\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.12.0)\r\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.17.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (5.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# We're going to install tensorflow here because their dataset access is simpler =)\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('../data', train=True, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Candies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(mnist_x_vector, mnist_y_vector):\n",
    "    pixels = mnist_x_vector.reshape((28, 28))\n",
    "    label = np.where(mnist_y_vector == 1)[0]\n",
    "    plt.title('Label is {}'.format(label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fifth image and label.\n",
    "show_image(mnist_train.data[5], mnist_train.targets[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets apply what we learn about multi-layered perceptron with PyTorch and apply it to the MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist_train.data.float()\n",
    "Y_mnist = mnist_train.targets.float()\n",
    "\n",
    "X_mnist_test = mnist_test.data.float()\n",
    "Y_mnist_test = mnist_test.targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [28, 28]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dimensions of the images.\n",
    "X_mnist = mnist_train.data.float().view(num_data, -1)\n",
    "Y_mnist = mnist_train.targets.float().unsqueeze(1)\n",
    "\n",
    "X_mnist_test = mnist_test.data.float().view(num_test_data, -1)\n",
    "Y_mnist_test = mnist_test.targets.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [784]\n",
      "Output Dim: [1]\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10/10 [00:04<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 500\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "losses = []\n",
    "plt.ion()\n",
    "\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_mnist)\n",
    "    loss_this_epoch = criterion(predictions, Y_mnist)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(losses)\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(X_mnist_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([np.argmax(_p) for _p in predictions.data.numpy()])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = np.array([np.argmax(_p) for _p in Y_mnist_test.data.numpy()])\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == truth).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

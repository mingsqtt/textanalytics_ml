{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YSRJr6FMHAIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsundoku in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: IPython in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (7.9.0)\n",
      "Requirement already satisfied: gensim in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (3.8.1)\n",
      "Requirement already satisfied: tqdm in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (4.40.0)\n",
      "Requirement already satisfied: numpy in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (1.17.4)\n",
      "Requirement already satisfied: nltk in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (3.4.5)\n",
      "Requirement already satisfied: torch in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from tsundoku) (1.3.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (4.3.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (42.0.1.post20191125)\n",
      "Requirement already satisfied: pygments in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (2.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (0.15.1)\n",
      "Requirement already satisfied: pickleshare in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (0.7.5)\n",
      "Requirement already satisfied: backcall in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (0.1.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (0.4.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (2.0.10)\n",
      "Requirement already satisfied: decorator in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from IPython->tsundoku) (4.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim->tsundoku) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim->tsundoku) (1.13.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim->tsundoku) (1.3.3)\n",
      "Requirement already satisfied: ipython-genutils in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from traitlets>=4.2->IPython->tsundoku) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from jedi>=0.10->IPython->tsundoku) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->tsundoku) (0.1.7)\n",
      "Requirement already satisfied: boto3 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim->tsundoku) (1.10.30)\n",
      "Requirement already satisfied: requests in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim->tsundoku) (2.22.0)\n",
      "Requirement already satisfied: boto>=2.32 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim->tsundoku) (2.49.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.30 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim->tsundoku) (1.13.30)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim->tsundoku) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim->tsundoku) (0.2.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim->tsundoku) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim->tsundoku) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim->tsundoku) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim->tsundoku) (2019.9.11)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim->tsundoku) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim->tsundoku) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tsundoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3sFD_Q-HAIE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: torch in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: nltk in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: lazyme in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (0.0.23)\n",
      "Requirement already satisfied: ansi in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: requests in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: gensim in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from sklearn) (0.22)\n",
      "Requirement already satisfied: numpy in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from torch) (1.17.4)\n",
      "Requirement already satisfied: six in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from nltk) (1.13.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim) (1.3.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from scikit-learn->sklearn) (0.14.0)\n",
      "Requirement already satisfied: boto3 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.10.30)\n",
      "Requirement already satisfied: boto>=2.32 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.30 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.30)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (from botocore<1.14.0,>=1.13.30->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn torch tqdm nltk lazyme ansi requests gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda3\\envs\\torch-nlp\\lib\\runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     e:/dataset/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to e:/dataset/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     e:/dataset/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "# before start the kernel, change the environment variable $NLTK_DATA (linux) or %NLTK_DATA% (windows) to the desired data path\n",
    "!python -m nltk.downloader -d %NLTK_DATA% movie_reviews punkt popular\n",
    "\n",
    "import nltk\n",
    "# or\n",
    "# nltk.download(\"popular\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMfIhsm9HAIH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "from tsundoku.word2vec_hints import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcNxTyz-HAII"
   },
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "- <a href=\"#section-3-0\">**3.0. Data Preparation**</a>\n",
    "  - <a href=\"#section-3-0-1\">3.0.1. *Vocabulary*</a>\n",
    "    - <a href=\"#section-3-0-1-a\"> Pet Peeve: using `gensim`</a>\n",
    "  - <a href=\"#section-3-0-2\">3.0.2. *Dataset*</a>  (<a href=\"#section-3-0-2-hints\">Hints</a>)\n",
    "    - <a href=\"#section-3-0-2-return-dict\">Return `dict` in `__getitem__()`</a>\n",
    "    - <a href=\"#section-3-0-2-labeleddata\">Try `LabeledDataset`</a>\n",
    "<br><br>\n",
    "- <a href=\"#section-3-1\">**3.1. Word2Vec from Scratch**</a>\n",
    "  - <a href=\"#section-3-1-1\">3.1.1. *CBOW*</a>\n",
    "  - <a href=\"#section-3-1-2\">3.1.2. *Skipgram*</a>\n",
    "  - <a href=\"#section-3-1-3\">3.1.3. *Word2Vec Dataset*</a> (<a href=\"#section-3-1-3-hint\">Hints</a>)\n",
    "  - <a href=\"#section-3-1-4-hint\">3.1.4. *Train a CBOW model*</a>\n",
    "    - <a href=\"#section-3-1-4-fill-cbow\">The CBOW model</a>\n",
    "    - <a href=\"#section-3-1-4-train-cbow\">Train the model (*for real*)</a>\n",
    "    - <a href=\"#section-3-1-4-evaluate-cbow\">Evaluate the model</a>\n",
    "    - <a href=\"#section-3-1-4-load-model\">Load model at specific epoch</a>\n",
    "  - <a href=\"#section-3-1-5\">3.1.5. *Train a Skipgram model*</a>\n",
    "    - <a href=\"#section-3-1-5-forward\">Take a closer look at `forward()`</a>\n",
    "    - <a href=\"#section-3-1-5-train\">Train the model (*for real*)</a>\n",
    "    - <a href=\"section-3-1-5-evaluate\">Evaluate the model</a>\n",
    "  - <a href=\"#section-3-1-6\">3.1.6. *Loading Pre-trained Embeddings*</a>\n",
    "    - <a href=\"#section-3-1-6-vocab\">Override the Embedding vocabulary</a>\n",
    "    - <a href=\"#section-3-1-6-pretrained\">Override the Embedding weights</a>\n",
    "    - <a href=\"#section-3-1-6-eval-skipgram\">Evaluate on the Skipgram task</a>\n",
    "    - <a href=\"#section-3-1-6-eval-cbow\">Evaluate on the CBOW task</a>\n",
    "    - <a href=\"#section-3-1-6-unfreeze-finetune\">Unfreeeze and finetune</a>\n",
    "    - <a href=\"#section-3-1-6-reval-cbow\">Re-evaluate on the CBOW task</a>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgogNA_4HAIK"
   },
   "source": [
    "<a id=\"section-3-0\"></a>\n",
    "# 3.0. Data Preparation\n",
    "\n",
    "Before we train our own embeddings, lets first understand how to read text data into pytorch.\n",
    "The native pytorch way to load datasets is to use the `torch.utils.data.Dataset` object.\n",
    "\n",
    "There are already several other libraries that help with loading text datasets, e.g. \n",
    "\n",
    " - FastAI https://docs.fast.ai/text.data.html\n",
    " - AllenNLP https://allenai.github.io/allennlp-docs/api/allennlp.data.dataset.html\n",
    " - Torch Text https://github.com/pytorch/text#data\n",
    " - Texar https://texar.readthedocs.io/en/latest/code/data.html#id4 \n",
    " - SpaCy https://github.com/explosion/thinc\n",
    " \n",
    "\n",
    "But to truly understand and use it for the custom datasets you'll see at work, lets learn it the native way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBuDtrsfHAIK"
   },
   "source": [
    "<a id=\"section-3-0-1\"></a>\n",
    "## 3.0.1  Vocabulary\n",
    "\n",
    "Given a text, the first thing to do is to build a vocabulary (i.e. a dictionary of unique words) and assign an index to each unique word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRRKjvgdHAIL"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import chain\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdW-wU64HAIM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's working: ['This', 'is', 'a', 'foobar', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    print(\"It's working: {}\".format(word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])))\n",
    "except Exception as ex: # Use a naive sentence tokenizer and toktok.\n",
    "    print(ex)\n",
    "    print(\"something is wrong...\")\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtDJBSPNHAIO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_text.len: 7\n",
      "sentense[0].len: 13\n",
      "sentense[1].len: 12\n",
      "sentense[2].len: 19\n",
      "sentense[3].len: 24\n",
      "sentense[4].len: 35\n",
      "sentense[5].len: 17\n",
      "sentense[6].len: 24\n",
      "uniq_tokens.len: 87\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"Language users never choose words randomly, and language is essentially\n",
    "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
    "posits randomness. Hence, when we look at linguistic phenomena in corpora, \n",
    "the null hypothesis will never be true. Moreover, where there is enough\n",
    "data, we shall (almost) always be able to establish that it is not true. In\n",
    "corpus studies, we frequently do have enough data, so the fact that a relation \n",
    "between two phenomena is demonstrably non-random, does not support the inference \n",
    "that it is not arbitrary. We present experimental evidence\n",
    "of how arbitrary associations between word frequencies and corpora are\n",
    "systematically non-random. We review literature in which hypothesis testing \n",
    "has been used, and show how it has often led to unhelpful or misleading results.\"\"\".lower()\n",
    "\n",
    "tokenized_text = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "print(\"tokenized_text.len: {}\".format(len(tokenized_text)))\n",
    "for i, each in enumerate(tokenized_text):\n",
    "    print(\"sentense[{}].len: {}\".format(i, len(each)))\n",
    "\n",
    "    \n",
    "uniq_tokens = set(chain(*tokenized_text))\n",
    "print(\"uniq_tokens.len: {}\".format(len(uniq_tokens)))\n",
    "\n",
    "vocab = {}   # Assign indices to every word.\n",
    "idx2tok = {} # Also keep an dict of index to words.\n",
    "for i, token in enumerate(uniq_tokens):\n",
    "    vocab[token] = i\n",
    "    idx2tok[i] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_QntiwpHAIR",
    "outputId": "c15a5a33-21e9-46f3-e782-2028bc0e3de0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unhelpful': 0,\n",
       " 'when': 1,\n",
       " 'which': 2,\n",
       " 'relation': 3,\n",
       " ',': 4,\n",
       " 'will': 5,\n",
       " 'word': 6,\n",
       " 'studies': 7,\n",
       " 'systematically': 8,\n",
       " 'where': 9,\n",
       " 'arbitrary': 10,\n",
       " 'moreover': 11,\n",
       " 'always': 12,\n",
       " 'users': 13,\n",
       " '(': 14,\n",
       " 'non-random': 15,\n",
       " 'phenomena': 16,\n",
       " 'so': 17,\n",
       " 'inference': 18,\n",
       " 'the': 19,\n",
       " 'fact': 20,\n",
       " 'essentially': 21,\n",
       " 'demonstrably': 22,\n",
       " 'statistical': 23,\n",
       " 'has': 24,\n",
       " 'not': 25,\n",
       " 'able': 26,\n",
       " 'randomly': 27,\n",
       " ')': 28,\n",
       " 'at': 29,\n",
       " 'does': 30,\n",
       " 'and': 31,\n",
       " 'shall': 32,\n",
       " 'hypothesis': 33,\n",
       " 'corpus': 34,\n",
       " 'look': 35,\n",
       " 'how': 36,\n",
       " 'do': 37,\n",
       " '.': 38,\n",
       " 'been': 39,\n",
       " 'review': 40,\n",
       " 'is': 41,\n",
       " 'establish': 42,\n",
       " 'linguistic': 43,\n",
       " 'have': 44,\n",
       " 'language': 45,\n",
       " 'support': 46,\n",
       " 'literature': 47,\n",
       " 'frequently': 48,\n",
       " 'null': 49,\n",
       " 'associations': 50,\n",
       " 'uses': 51,\n",
       " 'randomness': 52,\n",
       " 'there': 53,\n",
       " 'present': 54,\n",
       " 'true': 55,\n",
       " 'choose': 56,\n",
       " 'frequencies': 57,\n",
       " 'show': 58,\n",
       " 'often': 59,\n",
       " 'be': 60,\n",
       " 'evidence': 61,\n",
       " 'almost': 62,\n",
       " 'used': 63,\n",
       " 'experimental': 64,\n",
       " 'we': 65,\n",
       " 'testing': 66,\n",
       " 'in': 67,\n",
       " 'never': 68,\n",
       " 'it': 69,\n",
       " 'are': 70,\n",
       " 'results': 71,\n",
       " 'led': 72,\n",
       " 'hence': 73,\n",
       " 'posits': 74,\n",
       " 'data': 75,\n",
       " 'a': 76,\n",
       " 'or': 77,\n",
       " 'two': 78,\n",
       " 'words': 79,\n",
       " 'of': 80,\n",
       " 'enough': 81,\n",
       " 'that': 82,\n",
       " 'between': 83,\n",
       " 'to': 84,\n",
       " 'misleading': 85,\n",
       " 'corpora': 86}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saDeNLfqHAIV",
    "outputId": "d2ee5161-86bf-4b1c-c3a5-6cd3939d9e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the index of the word 'corpora'\n",
    "vocab['corpora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kY7UzMSRHAIX",
    "outputId": "4d2e48cf-2ed7-496a-e301-699d75db9680"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 13, 68, 56, 79, 27, 4, 31, 45, 41, 21, 15, 38]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The indexed representation of the first sentence.\n",
    "\n",
    "sent0 = tokenized_text[0]\n",
    "\n",
    "[vocab[token] for token in sent0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZOa3f3RHAIa"
   },
   "source": [
    "<a id=\"section-3-0-1-a\"></a>\n",
    "\n",
    "### Pet Peeve (Gensim)\n",
    "\n",
    "I (Liling) don't really like to write my own vectorizer the `gensim` has functions that are optimized for such operations. In fact, I've written a [whole preprocessing pipeline library for me to use for language modelling and machine translation purposes](https://github.com/alvations/komorebi/blob/master/komorebi/text.py) =)\n",
    "\n",
    "Using `gensim`, I would have written the above as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL36b-azHAId"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0fc82d449148>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_text' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = Dictionary(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uegCsbqqHAIg",
    "outputId": "e5e72187-af67-4cbf-9f1e-05ade01cf946",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ',',\n",
       " 1: '.',\n",
       " 2: 'and',\n",
       " 3: 'choose',\n",
       " 4: 'essentially',\n",
       " 5: 'is',\n",
       " 6: 'language',\n",
       " 7: 'never',\n",
       " 8: 'non-random',\n",
       " 9: 'randomly',\n",
       " 10: 'users',\n",
       " 11: 'words',\n",
       " 12: 'a',\n",
       " 13: 'hypothesis',\n",
       " 14: 'null',\n",
       " 15: 'posits',\n",
       " 16: 'randomness',\n",
       " 17: 'statistical',\n",
       " 18: 'testing',\n",
       " 19: 'uses',\n",
       " 20: 'which',\n",
       " 21: 'at',\n",
       " 22: 'be',\n",
       " 23: 'corpora',\n",
       " 24: 'hence',\n",
       " 25: 'in',\n",
       " 26: 'linguistic',\n",
       " 27: 'look',\n",
       " 28: 'phenomena',\n",
       " 29: 'the',\n",
       " 30: 'true',\n",
       " 31: 'we',\n",
       " 32: 'when',\n",
       " 33: 'will',\n",
       " 34: '(',\n",
       " 35: ')',\n",
       " 36: 'able',\n",
       " 37: 'almost',\n",
       " 38: 'always',\n",
       " 39: 'data',\n",
       " 40: 'enough',\n",
       " 41: 'establish',\n",
       " 42: 'it',\n",
       " 43: 'moreover',\n",
       " 44: 'not',\n",
       " 45: 'shall',\n",
       " 46: 'that',\n",
       " 47: 'there',\n",
       " 48: 'to',\n",
       " 49: 'where',\n",
       " 50: 'arbitrary',\n",
       " 51: 'between',\n",
       " 52: 'corpus',\n",
       " 53: 'demonstrably',\n",
       " 54: 'do',\n",
       " 55: 'does',\n",
       " 56: 'fact',\n",
       " 57: 'frequently',\n",
       " 58: 'have',\n",
       " 59: 'inference',\n",
       " 60: 'relation',\n",
       " 61: 'so',\n",
       " 62: 'studies',\n",
       " 63: 'support',\n",
       " 64: 'two',\n",
       " 65: 'are',\n",
       " 66: 'associations',\n",
       " 67: 'evidence',\n",
       " 68: 'experimental',\n",
       " 69: 'frequencies',\n",
       " 70: 'how',\n",
       " 71: 'of',\n",
       " 72: 'present',\n",
       " 73: 'systematically',\n",
       " 74: 'word',\n",
       " 75: 'been',\n",
       " 76: 'has',\n",
       " 77: 'led',\n",
       " 78: 'literature',\n",
       " 79: 'misleading',\n",
       " 80: 'often',\n",
       " 81: 'or',\n",
       " 82: 'results',\n",
       " 83: 'review',\n",
       " 84: 'show',\n",
       " 85: 'unhelpful',\n",
       " 86: 'used'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the key-value order is different of gensim from the native Python's\n",
    "dict(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEcAMbOLHAIo",
    "outputId": "16346ac8-4771-4c71-adf8-5fc77d83faaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.token2id['corpora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7CQ2gbqHAIs",
    "outputId": "f5855372-e4f3-4236-b910-72a342dae641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 10, 7, 3, 11, 9, 0, 2, 6, 5, 4, 8, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.doc2idx(sent0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8_Dg_tMHAIv"
   },
   "source": [
    "The \"indexed form\" of the tokens in the sentence forms the ***vectorized*** input to the `nn.Embedding` layer in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZGA2_RLHAIw"
   },
   "source": [
    "<a id=\"section-3-0-2\"></a>\n",
    "\n",
    "# 3.0.2 Dataset\n",
    "\n",
    "Lets try creating a `torch.utils.data.Dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLDrY4UDHAIx"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Text(Dataset):\n",
    "    def __init__(self, tokenized_texts):\n",
    "        \"\"\"\n",
    "        :param tokenized_texts: Tokenized text.\n",
    "        :type tokenized_texts: list(list(str))\n",
    "        \"\"\"\n",
    "        self.sents = tokenized_texts\n",
    "        self.vocab = Dictionary(tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Each data input, in this case, is a non-padded vectorised sentence (indices of tokens).\n",
    "        Because of non-padding, each X has different length\n",
    "        \n",
    "        :param index: Index to the data point.\n",
    "        :type index: int\n",
    "        \"\"\"\n",
    "        # Hint: You want to return a vectorized sentence here.\n",
    "        return {'x': self.vectorize(self.sents[index])}\n",
    "\n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        return self.vocab.doc2idx(tokens)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rD0LtXVSHAI0"
   },
   "source": [
    "<a id=\"section-3-0-2-hints\"></a>\n",
    "## Hints to the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYmg5cqJHAI1"
   },
   "outputs": [],
   "source": [
    "# Option 1: To see the hint and partial code for the cell above, uncomment the following line.\n",
    "#hint_dataset_vectorize()\n",
    "#code_text_dataset_vectorize()\n",
    "\n",
    "# Option 2: \"I give up just, run the code for me\" \n",
    "# Uncomment the next two lines, if you really gave up... \n",
    "#full_code_text_dataset_vectorize()\n",
    "#from tsundoku.word2vec import Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xHVvYSpHAI4"
   },
   "outputs": [],
   "source": [
    "text_dataset = Text(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfupnp_cHAI5",
    "outputId": "9fbe524d-3791-4925-b6a9-6de0f8d6a09a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [6, 10, 7, 3, 11, 9, 0, 2, 6, 5, 4, 8, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset[0] # First sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34a_siOHHAI9"
   },
   "source": [
    "<a id=\"section-3-0-2-return-dict\"></a>\n",
    "\n",
    "### Return `dict` in `__getitem__()`\n",
    "\n",
    "This is nice if we're just representing sentences/documents by their indices but when we're doing machine learning, we usually have `X` and `Y`. \n",
    "\n",
    "If we have labels for the each sentence, we can also put it into to `__getitem__()` by having it return a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3XTAsPGHAI-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LabeledText(Dataset):\n",
    "    def __init__(self, tokenized_texts, labels):\n",
    "        \"\"\"\n",
    "        :param tokenized_texts: Tokenized text.\n",
    "        :type tokenized_texts: list(list(str))\n",
    "        \"\"\"\n",
    "        self.sents = tokenized_texts\n",
    "        self.labels = labels # Sentence level labels.\n",
    "        self.vocab = Dictionary(self.sents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        The primary entry point for PyTorch datasets.\n",
    "        This is were you access the specific data row you want.\n",
    "        \n",
    "        Each data input, in this case, is a non-padded vectorised sentence (indices of tokens), and its label Y.\n",
    "        Because of non-padding, each X has different length\n",
    "        \n",
    "        :param index: Index to the data point.\n",
    "        :type index: int\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'x': self.vectorize(self.sents[index]), \n",
    "            'y': self.labels[index]\n",
    "        }\n",
    "\n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        return self.vocab.doc2idx(tokens)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93706NQMHAJB"
   },
   "source": [
    "<a id=\"section-3-0-2-labeleddata\"></a>\n",
    "\n",
    "### Lets try the `LabeledDataset` on a movie review corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZc9TAkaHAJD"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dd2lVKPvHAJI",
    "outputId": "848c0622-d6ea-448c-d108-f7447ac01c06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:06<00:00, 290.93it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "labels = []\n",
    "\n",
    "for fileid in tqdm(movie_reviews.fileids()):\n",
    "    label = fileid.split('/')[0]\n",
    "    doc = word_tokenize(movie_reviews.open(fileid).read())\n",
    "    documents.append(doc)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6v0H41lDHAJK",
    "outputId": "c33bb1e5-50d2-4c2d-d759-3fd2eccab2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(review docs): 2000\n",
      "len(docs[0]) i.e. tokens: 841\n",
      "len(labels): 2000\n",
      "first 5 labels: ['neg', 'neg', 'neg', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(\"len(review docs): {}\".format(len(documents)))\n",
    "print(\"len(docs[0]) i.e. tokens: {}\".format(len(documents[0])))\n",
    "print(\"len(labels): {}\".format(len(labels)))\n",
    "print(\"first 5 labels: {}\".format(labels[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONbM7Rz7HAJQ"
   },
   "outputs": [],
   "source": [
    "labeled_dataset = LabeledText(documents, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNCIdsKtHAJT",
    "outputId": "a6add92a-d5fb-45a3-b23b-4fa073b15eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [243, 17, 314, 294, 77, 140, 307, 20, 68, 237, 6, 97, 34, 299, 98, 8, 302, 135, 167, 33, 22, 8, 226, 220, 297, 145, 87, 6, 60, 158, 136, 74, 307, 262, 157, 165, 153, 179, 6, 34, 149, 214, 8, 333, 2, 297, 82, 18, 326, 297, 204, 34, 19, 280, 19, 124, 230, 8, 8, 8, 79, 17, 20, 199, 204, 129, 297, 294, 133, 296, 311, 225, 20, 322, 75, 164, 6, 60, 245, 169, 165, 20, 322, 46, 234, 8, 337, 168, 333, 188, 304, 253, 33, 108, 148, 226, 307, 345, 6, 272, 163, 132, 37, 122, 337, 42, 307, 59, 297, 201, 6, 196, 341, 348, 152, 34, 290, 4, 185, 156, 1, 195, 5, 6, 60, 300, 38, 142, 34, 46, 328, 220, 189, 28, 315, 220, 122, 6, 34, 301, 128, 173, 86, 208, 276, 304, 226, 76, 8, 302, 263, 307, 150, 293, 304, 246, 209, 72, 6, 60, 113, 169, 295, 8, 277, 333, 38, 297, 248, 341, 297, 204, 18, 331, 6, 170, 186, 247, 168, 296, 169, 2, 271, 309, 172, 8, 169, 282, 221, 19, 216, 19, 60, 299, 95, 167, 304, 19, 116, 19, 342, 165, 337, 347, 6, 40, 33, 43, 194, 6, 150, 215, 164, 333, 2, 141, 225, 8, 300, 38, 96, 6, 300, 38, 64, 70, 45, 130, 297, 81, 6, 300, 38, 229, 339, 183, 180, 297, 81, 6, 300, 38, 286, 36, 6, 300, 38, 91, 6, 300, 38, 20, 184, 220, 65, 260, 6, 300, 38, 308, 220, 330, 303, 296, 147, 6, 34, 203, 220, 169, 168, 271, 217, 114, 8, 218, 163, 240, 92, 208, 198, 312, 307, 317, 20, 121, 110, 218, 34, 299, 6, 60, 335, 28, 169, 93, 168, 137, 190, 297, 259, 69, 231, 34, 231, 26, 6, 163, 135, 175, 220, 117, 320, 25, 20, 338, 6, 337, 168, 304, 121, 2, 54, 247, 8, 169, 2, 219, 143, 304, 53, 261, 307, 155, 6, 60, 169, 265, 307, 325, 307, 155, 169, 71, 319, 170, 123, 125, 200, 8, 34, 92, 302, 187, 303, 106, 6, 305, 228, 108, 103, 6, 165, 297, 192, 18, 217, 251, 8, 297, 256, 236, 168, 296, 297, 39, 34, 163, 57, 89, 225, 127, 180, 304, 6, 277, 329, 24, 120, 203, 220, 169, 230, 61, 297, 146, 244, 6, 277, 28, 220, 297, 287, 25, 296, 86, 281, 307, 187, 20, 182, 55, 220, 266, 6, 60, 169, 284, 86, 208, 297, 187, 297, 121, 28, 296, 202, 106, 8, 163, 144, 297, 58, 181, 341, 205, 180, 304, 168, 296, 347, 268, 31, 187, 292, 296, 297, 43, 168, 19, 167, 169, 19, 108, 51, 302, 38, 138, 297, 261, 238, 307, 104, 348, 342, 220, 316, 8, 163, 191, 6, 269, 193, 257, 254, 44, 130, 324, 129, 21, 11, 200, 306, 297, 204, 168, 173, 241, 178, 0, 0, 224, 6, 329, 135, 169, 8, 8, 8, 300, 38, 239, 66, 153, 34, 329, 92, 208, 176, 339, 302, 38, 8, 92, 329, 251, 210, 307, 262, 169, 231, 34, 231, 26, 18, 162, 21, 139, 321, 88, 260, 222, 131, 166, 167, 28, 220, 297, 287, 141, 94, 165, 297, 204, 18, 35, 6, 297, 289, 310, 304, 121, 44, 130, 170, 90, 34, 67, 169, 320, 298, 6, 34, 169, 270, 8, 300, 197, 3, 50, 20, 246, 83, 294, 199, 204, 165, 154, 279, 6, 60, 163, 144, 19, 297, 291, 19, 84, 296, 313, 169, 167, 20, 206, 323, 341, 182, 100, 6, 343, 187, 202, 266, 8, 297, 23, 38, 246, 142, 129, 297, 203, 236, 6, 30, 332, 52, 173, 264, 307, 47, 242, 297, 111, 259, 63, 296, 151, 86, 165, 32, 48, 6, 227, 165, 20, 212, 211, 8, 60, 207, 54, 177, 140, 230, 307, 257, 6, 339, 159, 153, 233, 306, 297, 107, 121, 6, 34, 24, 149, 347, 118, 153, 63, 2, 318, 8, 232, 6, 297, 121, 93, 208, 283, 49, 169, 93, 208, 105, 6, 169, 2, 73, 6, 169, 250, 112, 34, 169, 119, 246, 252, 129, 203, 220, 170, 255, 6, 85, 20, 246, 75, 102, 34, 115, 307, 28, 220, 297, 78, 296, 62, 51, 169, 8, 223, 6, 34, 61, 297, 327, 6, 304, 168, 217, 20, 160, 228, 294, 275, 126, 8, 8, 8, 169, 2, 173, 235, 307, 183, 296, 327, 49, 278, 168, 35, 41, 296, 297, 134, 168, 284, 161, 341, 297, 174, 8, 169, 29, 344, 249, 314, 346, 27, 34, 149, 50, 273, 225, 297, 267, 109, 272, 8, 334, 8, 8, 8, 274, 169, 0, 336, 2, 171, 70, 130, 18, 20, 213, 220, 101, 288, 12, 4, 14, 5, 7, 56, 340, 10, 4, 14, 5, 7, 297, 80, 4, 16, 5, 7, 297, 80, 17, 258, 4, 13, 5, 7, 185, 156, 4, 9, 5, 7, 195, 4, 9, 5, 7, 297, 229, 4, 16, 5, 7, 285, 220, 99, 4, 15, 5], 'y': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(labeled_dataset[0])  # First review in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BE5n1Bn6HAJV",
    "outputId": "04490253-43dc-4d6b-b3b7-b07891667b1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243, 17, 314, 294, 77, 140, 307, 20, 68, 237, 6, 97, 34, 299, 98, 8, 302, 135, 167, 33, 22, 8, 226, 220, 297, 145, 87, 6, 60, 158, 136, 74, 307, 262, 157, 165, 153, 179, 6, 34, 149, 214, 8, 333, 2, 297, 82, 18, 326, 297, 204, 34, 19, 280, 19, 124, 230, 8, 8, 8, 79, 17, 20, 199, 204, 129, 297, 294, 133, 296, 311, 225, 20, 322, 75, 164, 6, 60, 245, 169, 165, 20, 322, 46, 234, 8, 337, 168, 333, 188, 304, 253, 33, 108, 148, 226, 307, 345, 6, 272, 163, 132, 37, 122, 337, 42, 307, 59, 297, 201, 6, 196, 341, 348, 152, 34, 290, 4, 185, 156, 1, 195, 5, 6, 60, 300, 38, 142, 34, 46, 328, 220, 189, 28, 315, 220, 122, 6, 34, 301, 128, 173, 86, 208, 276, 304, 226, 76, 8, 302, 263, 307, 150, 293, 304, 246, 209, 72, 6, 60, 113, 169, 295, 8, 277, 333, 38, 297, 248, 341, 297, 204, 18, 331, 6, 170, 186, 247, 168, 296, 169, 2, 271, 309, 172, 8, 169, 282, 221, 19, 216, 19, 60, 299, 95, 167, 304, 19, 116, 19, 342, 165, 337, 347, 6, 40, 33, 43, 194, 6, 150, 215, 164, 333, 2, 141, 225, 8, 300, 38, 96, 6, 300, 38, 64, 70, 45, 130, 297, 81, 6, 300, 38, 229, 339, 183, 180, 297, 81, 6, 300, 38, 286, 36, 6, 300, 38, 91, 6, 300, 38, 20, 184, 220, 65, 260, 6, 300, 38, 308, 220, 330, 303, 296, 147, 6, 34, 203, 220, 169, 168, 271, 217, 114, 8, 218, 163, 240, 92, 208, 198, 312, 307, 317, 20, 121, 110, 218, 34, 299, 6, 60, 335, 28, 169, 93, 168, 137, 190, 297, 259, 69, 231, 34, 231, 26, 6, 163, 135, 175, 220, 117, 320, 25, 20, 338, 6, 337, 168, 304, 121, 2, 54, 247, 8, 169, 2, 219, 143, 304, 53, 261, 307, 155, 6, 60, 169, 265, 307, 325, 307, 155, 169, 71, 319, 170, 123, 125, 200, 8, 34, 92, 302, 187, 303, 106, 6, 305, 228, 108, 103, 6, 165, 297, 192, 18, 217, 251, 8, 297, 256, 236, 168, 296, 297, 39, 34, 163, 57, 89, 225, 127, 180, 304, 6, 277, 329, 24, 120, 203, 220, 169, 230, 61, 297, 146, 244, 6, 277, 28, 220, 297, 287, 25, 296, 86, 281, 307, 187, 20, 182, 55, 220, 266, 6, 60, 169, 284, 86, 208, 297, 187, 297, 121, 28, 296, 202, 106, 8, 163, 144, 297, 58, 181, 341, 205, 180, 304, 168, 296, 347, 268, 31, 187, 292, 296, 297, 43, 168, 19, 167, 169, 19, 108, 51, 302, 38, 138, 297, 261, 238, 307, 104, 348, 342, 220, 316, 8, 163, 191, 6, 269, 193, 257, 254, 44, 130, 324, 129, 21, 11, 200, 306, 297, 204, 168, 173, 241, 178, 0, 0, 224, 6, 329, 135, 169, 8, 8, 8, 300, 38, 239, 66, 153, 34, 329, 92, 208, 176, 339, 302, 38, 8, 92, 329, 251, 210, 307, 262, 169, 231, 34, 231, 26, 18, 162, 21, 139, 321, 88, 260, 222, 131, 166, 167, 28, 220, 297, 287, 141, 94, 165, 297, 204, 18, 35, 6, 297, 289, 310, 304, 121, 44, 130, 170, 90, 34, 67, 169, 320, 298, 6, 34, 169, 270, 8, 300, 197, 3, 50, 20, 246, 83, 294, 199, 204, 165, 154, 279, 6, 60, 163, 144, 19, 297, 291, 19, 84, 296, 313, 169, 167, 20, 206, 323, 341, 182, 100, 6, 343, 187, 202, 266, 8, 297, 23, 38, 246, 142, 129, 297, 203, 236, 6, 30, 332, 52, 173, 264, 307, 47, 242, 297, 111, 259, 63, 296, 151, 86, 165, 32, 48, 6, 227, 165, 20, 212, 211, 8, 60, 207, 54, 177, 140, 230, 307, 257, 6, 339, 159, 153, 233, 306, 297, 107, 121, 6, 34, 24, 149, 347, 118, 153, 63, 2, 318, 8, 232, 6, 297, 121, 93, 208, 283, 49, 169, 93, 208, 105, 6, 169, 2, 73, 6, 169, 250, 112, 34, 169, 119, 246, 252, 129, 203, 220, 170, 255, 6, 85, 20, 246, 75, 102, 34, 115, 307, 28, 220, 297, 78, 296, 62, 51, 169, 8, 223, 6, 34, 61, 297, 327, 6, 304, 168, 217, 20, 160, 228, 294, 275, 126, 8, 8, 8, 169, 2, 173, 235, 307, 183, 296, 327, 49, 278, 168, 35, 41, 296, 297, 134, 168, 284, 161, 341, 297, 174, 8, 169, 29, 344, 249, 314, 346, 27, 34, 149, 50, 273, 225, 297, 267, 109, 272, 8, 334, 8, 8, 8, 274, 169, 0, 336, 2, 171, 70, 130, 18, 20, 213, 220, 101, 288, 12, 4, 14, 5, 7, 56, 340, 10, 4, 14, 5, 7, 297, 80, 4, 16, 5, 7, 297, 80, 17, 258, 4, 13, 5, 7, 185, 156, 4, 9, 5, 7, 195, 4, 9, 5, 7, 297, 229, 4, 16, 5, 7, 285, 220, 99, 4, 15, 5]\n"
     ]
    }
   ],
   "source": [
    "print(labeled_dataset[0]['x'])  # First review in vectorized index format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYKW3HTAHAJe",
    "outputId": "a56569b3-e66d-4718-aff9-c4801f79626f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(labeled_dataset[0]['y'])  # Label of the first review in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAmO-CfpHAJi"
   },
   "source": [
    "<a id=\"section-3-1\"></a>\n",
    "\n",
    "# 3.1 Word2Vec Training\n",
    "\n",
    "Word2Vec has two training variants:\n",
    "\n",
    " - **Continuous Bag of Words (CBOW)**: Predict center word from (bag of) context words.\n",
    " - **Skip-grams**: Predict context words given center word.\n",
    "  \n",
    "Visually, they look like this:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/word2vec-cbow.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8s5BWXEHAJj"
   },
   "source": [
    "Fig. 1. The skip-gram model. Both the input vector xx and the output yy are one-hot encoded word representations. <br>The hidden layer is the word embedding of size NN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3Tott_jHAKY"
   },
   "source": [
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/word2vec-skip-gram.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGbH-mS-HAKa"
   },
   "source": [
    "Fig. 2. The CBOW model. Word vectors of multiple context words are averaged to get a fixed-length vector as in the hidden layer. Other symbols have the same meanings as in Fig 1.\n",
    "\n",
    "(Pretty network images above are from [https://lilianweng.github.io](https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html#context-based-continuous-bag-of-words-cbow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSckJrhpHAKc"
   },
   "source": [
    "<a id=\"section-3-1-1\"></a>\n",
    "\n",
    "## 3.1.1. CBOW\n",
    "\n",
    "CBOW windows through the sentence and picks out the center word as the `Y` and the surrounding context words as the inputs `X`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW uses the neighbouring 4 tokens to predict the center token, i.e. every input X has dim of 4, and y has dim of 1.\n",
    "\n",
    "input lookup matrix X shape: (4, V)\n",
    "embedding matrix W shape: (V, N)   V: vocabulary size, N: embedding size\n",
    "intermediate layer H = input lookup matrix X multiply embedding matrix W, in shape (4, N), then flatten to (1, 4*N)\n",
    "intermediate layer H then multiplys Matrix W' to product softmax output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAPrZ_tsHAKt",
    "outputId": "3c743c14-6a77-4c86-d24a-2b3919bd558c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use per_window to create windows for [1, 2, 3, 4, 5]\n",
      "[(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "[(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
      "[]\n",
      "\n",
      "use per_chunk to create windows for [1, 2, 3, 4, 5]\n",
      "[(1, 2), (3, 4), (5, None)]\n",
      "[(1, 2, 3), (4, 5, None)]\n",
      "[(1, 2, 3, 4), (5, None, None, None)]\n",
      "[(1, 2, 3, 4, 5, None, None, None, None, None)]\n"
     ]
    }
   ],
   "source": [
    "from lazyme import per_window, per_chunk\n",
    "\n",
    "xx =[1,2,3,4,5]\n",
    "print(\"use per_window to create windows for {}\".format(xx))\n",
    "print(list(per_window(xx, n=2)))\n",
    "print(list(per_window(xx, n=3)))\n",
    "print(list(per_window(xx, n=10)))\n",
    "print()\n",
    "print(\"use per_chunk to create windows for {}\".format(xx))\n",
    "print(list(per_chunk(xx, n=2)))\n",
    "print(list(per_chunk(xx, n=3)))\n",
    "print(list(per_chunk(xx, n=4)))\n",
    "print(list(per_chunk(xx, n=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FV3-eKJgHAK0"
   },
   "outputs": [],
   "source": [
    "def per_window(sequence, n=1):\n",
    "    \"\"\"\n",
    "    From http://stackoverflow.com/q/42220614/610569\n",
    "        >>> list(per_window([1,2,3,4], n=2))\n",
    "        [(1, 2), (2, 3), (3, 4)]\n",
    "        >>> list(per_window([1,2,3,4], n=3))\n",
    "        [(1, 2, 3), (2, 3, 4)]\n",
    "    \"\"\"\n",
    "    start, stop = 0, n\n",
    "    seq = list(sequence)\n",
    "    while stop <= len(seq):\n",
    "        yield seq[start:stop]\n",
    "        start += 1\n",
    "        stop += 1\n",
    "\n",
    "def cbow_iterator(tokens, window_size):\n",
    "    n = window_size * 2 + 1\n",
    "    for window in per_window(tokens, n):\n",
    "        target = window.pop(window_size)\n",
    "        yield window, target   # X = window ; Y = target. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use per_window to create windows for [1, 2, 3, 4, 5]\n",
      "[[1, 2], [2, 3], [3, 4], [4, 5]]\n"
     ]
    }
   ],
   "source": [
    "xx =[1,2,3,4,5]\n",
    "print(\"use per_window to create windows for {}\".format(xx))\n",
    "print(list(per_window(xx, n=2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzyORy8cHALB"
   },
   "outputs": [],
   "source": [
    "sent0 = ['language', 'users', 'never', 'choose', 'words', 'randomly', ',', \n",
    "         'and', 'language', 'is', 'essentially', 'non-random', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNEkMM0DHALJ",
    "outputId": "6b8ce2b4-dfc9-426a-9e1a-a17da38c27b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['language', 'users', 'choose', 'words'], 'never'),\n",
       " (['users', 'never', 'words', 'randomly'], 'choose'),\n",
       " (['never', 'choose', 'randomly', ','], 'words'),\n",
       " (['choose', 'words', ',', 'and'], 'randomly'),\n",
       " (['words', 'randomly', 'and', 'language'], ','),\n",
       " (['randomly', ',', 'language', 'is'], 'and'),\n",
       " ([',', 'and', 'is', 'essentially'], 'language'),\n",
       " (['and', 'language', 'essentially', 'non-random'], 'is'),\n",
       " (['language', 'is', 'non-random', '.'], 'essentially')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cbow_iterator(sent0, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-6qY-gaHALm",
    "outputId": "2965aa31-98d0-421a-fd12-cd5c510b5e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['language', 'users', 'never', 'words', 'randomly', ','], 'choose'),\n",
       " (['users', 'never', 'choose', 'randomly', ',', 'and'], 'words'),\n",
       " (['never', 'choose', 'words', ',', 'and', 'language'], 'randomly'),\n",
       " (['choose', 'words', 'randomly', 'and', 'language', 'is'], ','),\n",
       " (['words', 'randomly', ',', 'language', 'is', 'essentially'], 'and'),\n",
       " (['randomly', ',', 'and', 'is', 'essentially', 'non-random'], 'language'),\n",
       " ([',', 'and', 'language', 'essentially', 'non-random', '.'], 'is')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cbow_iterator(sent0, 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljJ20HHFHAL-"
   },
   "source": [
    "<a id=\"section-3-1-2\"></a>\n",
    "\n",
    "## 3.1.2. Skipgram\n",
    "\n",
    "Skipgram training windows through the sentence and pictures out the center word as the input `X` and the context words as the outputs `Y`, additionally, it will randommly sample words not in the window as **negative samples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3fPMkoZHAL_"
   },
   "outputs": [],
   "source": [
    "def skipgram_iterator(tokens, window_size):\n",
    "    n = window_size * 2 + 1 \n",
    "    for i, window in enumerate(per_window(tokens, n)):\n",
    "        target = window.pop(window_size)\n",
    "        # Generate positive samples.\n",
    "        for context_word in window:\n",
    "            yield target, context_word, 1\n",
    "        # Generate negative samples.\n",
    "        for _ in range(n-1):\n",
    "            leftovers = tokens[:i] + tokens[i+n:]\n",
    "            yield target, random.choice(leftovers), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-esIo3JlHAME",
    "outputId": "744f2af7-d053-4846-e303-c68893c21e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('never', 'language', 1),\n",
       " ('never', 'users', 1),\n",
       " ('never', 'choose', 1),\n",
       " ('never', 'words', 1),\n",
       " ('never', 'and', 0),\n",
       " ('never', 'essentially', 0),\n",
       " ('never', 'essentially', 0),\n",
       " ('never', '.', 0),\n",
       " ('choose', 'users', 1),\n",
       " ('choose', 'never', 1),\n",
       " ('choose', 'words', 1),\n",
       " ('choose', 'randomly', 1),\n",
       " ('choose', '.', 0),\n",
       " ('choose', 'is', 0),\n",
       " ('choose', 'language', 0),\n",
       " ('choose', ',', 0),\n",
       " ('words', 'never', 1),\n",
       " ('words', 'choose', 1),\n",
       " ('words', 'randomly', 1),\n",
       " ('words', ',', 1),\n",
       " ('words', 'language', 0),\n",
       " ('words', 'non-random', 0),\n",
       " ('words', 'essentially', 0),\n",
       " ('words', 'language', 0),\n",
       " ('randomly', 'choose', 1),\n",
       " ('randomly', 'words', 1),\n",
       " ('randomly', ',', 1),\n",
       " ('randomly', 'and', 1),\n",
       " ('randomly', 'language', 0),\n",
       " ('randomly', 'non-random', 0),\n",
       " ('randomly', 'language', 0),\n",
       " ('randomly', 'never', 0),\n",
       " (',', 'words', 1),\n",
       " (',', 'randomly', 1),\n",
       " (',', 'and', 1),\n",
       " (',', 'language', 1),\n",
       " (',', 'non-random', 0),\n",
       " (',', 'language', 0),\n",
       " (',', 'choose', 0),\n",
       " (',', 'never', 0),\n",
       " ('and', 'randomly', 1),\n",
       " ('and', ',', 1),\n",
       " ('and', 'language', 1),\n",
       " ('and', 'is', 1),\n",
       " ('and', 'choose', 0),\n",
       " ('and', 'non-random', 0),\n",
       " ('and', 'choose', 0),\n",
       " ('and', 'words', 0),\n",
       " ('language', ',', 1),\n",
       " ('language', 'and', 1),\n",
       " ('language', 'is', 1),\n",
       " ('language', 'essentially', 1),\n",
       " ('language', 'language', 0),\n",
       " ('language', 'choose', 0),\n",
       " ('language', 'choose', 0),\n",
       " ('language', 'users', 0),\n",
       " ('is', 'and', 1),\n",
       " ('is', 'language', 1),\n",
       " ('is', 'essentially', 1),\n",
       " ('is', 'non-random', 1),\n",
       " ('is', ',', 0),\n",
       " ('is', 'never', 0),\n",
       " ('is', 'users', 0),\n",
       " ('is', 'never', 0),\n",
       " ('essentially', 'language', 1),\n",
       " ('essentially', 'is', 1),\n",
       " ('essentially', 'non-random', 1),\n",
       " ('essentially', '.', 1),\n",
       " ('essentially', ',', 0),\n",
       " ('essentially', 'users', 0),\n",
       " ('essentially', 'users', 0),\n",
       " ('essentially', 'never', 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(skipgram_iterator(sent0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MR1oCgnCHAMM"
   },
   "source": [
    "## Cut-away: What is `partial`?\n",
    "\n",
    "The [`functools.partial`](https://docs.python.org/3.7/library/functools.html#functools.partial) function in Python is a mechanism to overload a function with preset arguments. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o37H0cxxHAMN",
    "outputId": "d4e2f38e-e33f-4320-bc7c-d05cf9589b79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'is'), ('is', 'a'), ('a', 'sentence')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# Generates bigrams\n",
    "list(ngrams('this is a sentence'.split(), n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFdDjEZvHAMd"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# You can create a new function that \"preset\" the `n` argument, e.g.\n",
    "bigrams = partial(ngrams, n=2)\n",
    "trigrams = partial(ngrams, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5gDUuojHAMg",
    "outputId": "c7bcb042-ee0d-4c53-85ec-c555f46001e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'is', 'a'), ('is', 'a', 'sentence')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trigrams('this is a sentence'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnZTSkGIHAMn",
    "outputId": "9e3c3ea0-74d7-4ae6-906f-6ef0448ad93d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'is'), ('is', 'a'), ('a', 'sentence')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams('this is a sentence'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7v5X8GlHAMw"
   },
   "source": [
    "<a id=\"section-3-1-3\"></a>\n",
    "\n",
    "## 3.1.3 Word2Vec Dataset\n",
    "\n",
    "Now that we know what are the inputs `X` and outputs `Y` of the Word2Vec task. \n",
    "\n",
    "Lets put everything together and modify the `Dataset` so that `__getitem__` retrieves CBOW or Skipgram formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UaPLt9WrHAMx"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Word2VecText(Dataset):\n",
    "    def __init__(self, tokenized_texts, window_size=2, variant=\"cbow\"):\n",
    "        \"\"\"\n",
    "        :param tokenized_texts: Tokenized text.\n",
    "        :type tokenized_texts: list(list(str))\n",
    "        \"\"\"\n",
    "        self.sents = tokenized_texts\n",
    "        self._len = len(self.sents)\n",
    "        self.vocab = Dictionary(self.sents)\n",
    "        self.window_size = window_size\n",
    "        self.variant = variant\n",
    "        if variant.lower() == 'cbow':\n",
    "            self._iterator = partial(self.cbow_iterator, window_size=self.window_size)\n",
    "        elif variant.lower() == 'skipgram':\n",
    "            self._iterator = partial(self.skipgram_iterator, window_size=self.window_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        The primary entry point for PyTorch datasets.\n",
    "        This is were you access the specific data row you want.\n",
    "        \n",
    "        Each item is a list of windows for a sentence/document. \n",
    "        Each window is composed of a dictionary of x = window vector, y = target value at the center of the window.\n",
    "        CBOW e.g.\n",
    "        [\n",
    "            {'x': [x1,x2,x4,x5], 'y': x3},\n",
    "            {'x': [x2,x3,x5,x6], 'y': x4},\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "        SkipGram e.g.\n",
    "        [\n",
    "            {'x': (x1, x3), 'y': 1},\n",
    "            {'x': (x2, x3), 'y': 1},\n",
    "            {'x': (x4, x3), 'y': 1},\n",
    "            {'x': (x5, x3), 'y': 1},\n",
    "            {'x': (x9, x3), 'y': 0},\n",
    "            {'x': (x10, x3), 'y': 0},\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "\n",
    "        :param index: Index to the data point.\n",
    "        :type index: int\n",
    "        \"\"\"\n",
    "        vectorized_sent = self.vectorize(self.sents[index])\n",
    "        return list(self._iterator(vectorized_sent))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized.\n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx\n",
    "        return self.vocab.doc2idx(tokens)\n",
    "\n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]\n",
    "\n",
    "    def cbow_iterator(self, sent_tokens, window_size):\n",
    "        n = window_size * 2 + 1\n",
    "        for window in per_window(sent_tokens, n):\n",
    "            window = list(window)\n",
    "            target = window.pop(window_size)\n",
    "            yield {\"x\": window, \"y\": target}   # X = window ; Y = target. \n",
    "\n",
    "    def skipgram_iterator(self, sent_tokens, window_size):\n",
    "        n = window_size * 2 + 1 \n",
    "        for i, window in enumerate(per_window(sent_tokens, n)):\n",
    "            window = list(window)\n",
    "            target = window.pop(window_size)\n",
    "            # Generate positive samples.\n",
    "            for context_word in window:\n",
    "                yield {\"x\": (target, context_word), \"y\": 1}\n",
    "            # Generate negative samples.\n",
    "            for _ in range(n-1):\n",
    "                leftovers = sent_tokens[:i] + sent_tokens[i+n:]\n",
    "                yield {\"x\": (target, random.choice(leftovers)), \"y\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXE9ukTcHAM2"
   },
   "source": [
    "<a id=\"section-3-1-3-hint\"></a>\n",
    "## Hints for the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymXcYy25HAM5"
   },
   "outputs": [],
   "source": [
    "# Option 1: To see the hint and partial code for the cell above, uncomment the following line.\n",
    "##hint_word2vec_dataset()\n",
    "\n",
    "# Option 2: \"I give up just, run the code for me\" \n",
    "# Uncomment the next two lines, if you really gave up... \n",
    "##full_code_word2vec_dataset()\n",
    "##from tsundoku.word2vec import Word2VecText\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXFpDkcXHAM9"
   },
   "source": [
    "<a id=\"section-3-1-4-hint\"></a>\n",
    "\n",
    "## 3.1.4. Train a CBOW model\n",
    "\n",
    "### Lets Get Some Data\n",
    "\n",
    "Lets take Kilgarriff (2005) , \"Language is never ever, ever random\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEYnPscyHANA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': [10, 8, 0, 7], 'y': 11}, {'x': [8, 11, 7, 0], 'y': 0}, {'x': [11, 0, 0, 7], 'y': 7}, {'x': [0, 7, 7, 0], 'y': 0}, {'x': [7, 0, 0, 13], 'y': 7}, {'x': [0, 7, 13, 3], 'y': 0}, {'x': [7, 0, 3, 9], 'y': 13}, {'x': [0, 13, 9, 2], 'y': 3}, {'x': [13, 3, 2, 10], 'y': 9}, {'x': [3, 9, 10, 15], 'y': 2}, {'x': [9, 2, 15, 11], 'y': 10}, {'x': [2, 10, 11, 5], 'y': 15}, {'x': [10, 15, 5, 16], 'y': 11}, {'x': [15, 11, 16, 14], 'y': 5}, {'x': [11, 5, 14, 0], 'y': 16}, {'x': [5, 16, 0, 4], 'y': 14}, {'x': [16, 14, 4, 10], 'y': 0}, {'x': [14, 0, 10, 8], 'y': 4}, {'x': [0, 4, 8, 6], 'y': 10}, {'x': [4, 10, 6, 12], 'y': 8}, {'x': [10, 8, 12, 1], 'y': 6}]\n",
      "\n",
      "[{'x': (11, 10), 'y': 1}, {'x': (11, 8), 'y': 1}, {'x': (11, 0), 'y': 1}, {'x': (11, 7), 'y': 1}, {'x': (11, 3), 'y': 0}, {'x': (11, 11), 'y': 0}, {'x': (11, 7), 'y': 0}, {'x': (11, 0), 'y': 0}, {'x': (0, 8), 'y': 1}, {'x': (0, 11), 'y': 1}, {'x': (0, 7), 'y': 1}, {'x': (0, 0), 'y': 1}, {'x': (0, 9), 'y': 0}, {'x': (0, 6), 'y': 0}, {'x': (0, 6), 'y': 0}, {'x': (0, 4), 'y': 0}, {'x': (7, 11), 'y': 1}, {'x': (7, 0), 'y': 1}, {'x': (7, 0), 'y': 1}, {'x': (7, 7), 'y': 1}, {'x': (7, 0), 'y': 0}, {'x': (7, 12), 'y': 0}, {'x': (7, 15), 'y': 0}, {'x': (7, 6), 'y': 0}, {'x': (0, 0), 'y': 1}, {'x': (0, 7), 'y': 1}, {'x': (0, 7), 'y': 1}, {'x': (0, 0), 'y': 1}, {'x': (0, 5), 'y': 0}, {'x': (0, 6), 'y': 0}, {'x': (0, 1), 'y': 0}, {'x': (0, 11), 'y': 0}, {'x': (7, 7), 'y': 1}, {'x': (7, 0), 'y': 1}, {'x': (7, 0), 'y': 1}, {'x': (7, 13), 'y': 1}, {'x': (7, 11), 'y': 0}, {'x': (7, 1), 'y': 0}, {'x': (7, 3), 'y': 0}, {'x': (7, 12), 'y': 0}, {'x': (0, 0), 'y': 1}, {'x': (0, 7), 'y': 1}, {'x': (0, 13), 'y': 1}, {'x': (0, 3), 'y': 1}, {'x': (0, 11), 'y': 0}, {'x': (0, 16), 'y': 0}, {'x': (0, 5), 'y': 0}, {'x': (0, 10), 'y': 0}, {'x': (13, 7), 'y': 1}, {'x': (13, 0), 'y': 1}, {'x': (13, 3), 'y': 1}, {'x': (13, 9), 'y': 1}, {'x': (13, 8), 'y': 0}, {'x': (13, 11), 'y': 0}, {'x': (13, 5), 'y': 0}, {'x': (13, 10), 'y': 0}, {'x': (3, 0), 'y': 1}, {'x': (3, 13), 'y': 1}, {'x': (3, 9), 'y': 1}, {'x': (3, 2), 'y': 1}, {'x': (3, 0), 'y': 0}, {'x': (3, 11), 'y': 0}, {'x': (3, 0), 'y': 0}, {'x': (3, 16), 'y': 0}, {'x': (9, 13), 'y': 1}, {'x': (9, 3), 'y': 1}, {'x': (9, 2), 'y': 1}, {'x': (9, 10), 'y': 1}, {'x': (9, 0), 'y': 0}, {'x': (9, 15), 'y': 0}, {'x': (9, 16), 'y': 0}, {'x': (9, 4), 'y': 0}, {'x': (2, 3), 'y': 1}, {'x': (2, 9), 'y': 1}, {'x': (2, 10), 'y': 1}, {'x': (2, 15), 'y': 1}, {'x': (2, 10), 'y': 0}, {'x': (2, 12), 'y': 0}, {'x': (2, 0), 'y': 0}, {'x': (2, 0), 'y': 0}, {'x': (10, 9), 'y': 1}, {'x': (10, 2), 'y': 1}, {'x': (10, 15), 'y': 1}, {'x': (10, 11), 'y': 1}, {'x': (10, 14), 'y': 0}, {'x': (10, 0), 'y': 0}, {'x': (10, 12), 'y': 0}, {'x': (10, 7), 'y': 0}, {'x': (15, 2), 'y': 1}, {'x': (15, 10), 'y': 1}, {'x': (15, 11), 'y': 1}, {'x': (15, 5), 'y': 1}, {'x': (15, 13), 'y': 0}, {'x': (15, 4), 'y': 0}, {'x': (15, 10), 'y': 0}, {'x': (15, 7), 'y': 0}, {'x': (11, 10), 'y': 1}, {'x': (11, 15), 'y': 1}, {'x': (11, 5), 'y': 1}, {'x': (11, 16), 'y': 1}, {'x': (11, 0), 'y': 0}, {'x': (11, 9), 'y': 0}, {'x': (11, 13), 'y': 0}, {'x': (11, 12), 'y': 0}, {'x': (5, 15), 'y': 1}, {'x': (5, 11), 'y': 1}, {'x': (5, 16), 'y': 1}, {'x': (5, 14), 'y': 1}, {'x': (5, 4), 'y': 0}, {'x': (5, 2), 'y': 0}, {'x': (5, 10), 'y': 0}, {'x': (5, 13), 'y': 0}, {'x': (16, 11), 'y': 1}, {'x': (16, 5), 'y': 1}, {'x': (16, 14), 'y': 1}, {'x': (16, 0), 'y': 1}, {'x': (16, 0), 'y': 0}, {'x': (16, 10), 'y': 0}, {'x': (16, 3), 'y': 0}, {'x': (16, 9), 'y': 0}, {'x': (14, 5), 'y': 1}, {'x': (14, 16), 'y': 1}, {'x': (14, 0), 'y': 1}, {'x': (14, 4), 'y': 1}, {'x': (14, 8), 'y': 0}, {'x': (14, 2), 'y': 0}, {'x': (14, 0), 'y': 0}, {'x': (14, 13), 'y': 0}, {'x': (0, 16), 'y': 1}, {'x': (0, 14), 'y': 1}, {'x': (0, 4), 'y': 1}, {'x': (0, 10), 'y': 1}, {'x': (0, 7), 'y': 0}, {'x': (0, 5), 'y': 0}, {'x': (0, 13), 'y': 0}, {'x': (0, 6), 'y': 0}, {'x': (4, 14), 'y': 1}, {'x': (4, 0), 'y': 1}, {'x': (4, 10), 'y': 1}, {'x': (4, 8), 'y': 1}, {'x': (4, 3), 'y': 0}, {'x': (4, 6), 'y': 0}, {'x': (4, 0), 'y': 0}, {'x': (4, 0), 'y': 0}, {'x': (10, 0), 'y': 1}, {'x': (10, 4), 'y': 1}, {'x': (10, 8), 'y': 1}, {'x': (10, 6), 'y': 1}, {'x': (10, 10), 'y': 0}, {'x': (10, 10), 'y': 0}, {'x': (10, 3), 'y': 0}, {'x': (10, 11), 'y': 0}, {'x': (8, 4), 'y': 1}, {'x': (8, 10), 'y': 1}, {'x': (8, 6), 'y': 1}, {'x': (8, 12), 'y': 1}, {'x': (8, 1), 'y': 0}, {'x': (8, 16), 'y': 0}, {'x': (8, 0), 'y': 0}, {'x': (8, 11), 'y': 0}, {'x': (6, 10), 'y': 1}, {'x': (6, 8), 'y': 1}, {'x': (6, 12), 'y': 1}, {'x': (6, 1), 'y': 1}, {'x': (6, 0), 'y': 0}, {'x': (6, 0), 'y': 0}, {'x': (6, 9), 'y': 0}, {'x': (6, 9), 'y': 0}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import io #codecs\n",
    "\n",
    "\n",
    "# Text version of https://kilgarriff.co.uk/Publications/2005-K-lineer.pdf\n",
    "if os.path.isfile('language-never-random.txt'):\n",
    "    with io.open('language-never-random.txt', encoding='utf8') as fin:\n",
    "        text = fin.read()\n",
    "else:\n",
    "    url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
    "    text = requests.get(url).content.decode('utf8')\n",
    "    with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
    "        fout.write(text)\n",
    "\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(text)]\n",
    "window_size = 2\n",
    "w2v_dataset = Word2VecText(tokenized_text, window_size=window_size, variant='cbow')\n",
    "print(w2v_dataset[0])\n",
    "print()\n",
    "w2v_dataset_skipgram = Word2VecText(tokenized_text, window_size=window_size, variant='skipgram')\n",
    "print(w2v_dataset_skipgram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOFKsFVZHANE",
    "outputId": "39bed45c-d098-4726-a5a6-0bbb4281d1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Language is never, ever, ever, random\n",
      "\n",
      "                                                               ADAM KILGARRIFF\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Abstract\n",
      "Language users never choose words randomly, and language is essentially\n",
      "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
      "posits randomness. Hence, when we look at linguistic phenomena in cor-\n",
      "pora, the null hypothesis will never be true. Moreover, where there is enough\n",
      "data, we shall (almost) always be able to establish that it is not true. In\n",
      "corpus studies, we frequently do have enough data, so the fact that a rela-\n",
      "tion between two phenomena is demonstrably non-random, does not sup-\n",
      "port the inference that it is not arbitrary. We present experimental evidence\n",
      "of how arbitrary associations between word frequencies and corpora are\n",
      "systematically non-random. We review literature in which hypothesis test-\n",
      "ing has been used, and show how it has often led to unhelpful or mislead-\n",
      "ing results.\n",
      "Keywords: 쎲쎲쎲\n",
      "\n",
      "1. Int\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfarUjiGHANJ",
    "outputId": "4c946f67-f4df-40f8-fc6a-6d6c9539127e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['language', 'is', 'never', ',', 'ever', ',', 'ever', ',', 'random', 'adam', 'kilgarriff', 'abstract', 'language', 'users', 'never', 'choose', 'words', 'randomly', ',', 'and', 'language', 'is', 'essentially', 'non-random', '.']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check, lets take a look at the data.\n",
    "print(tokenized_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRmEPBJbHANP"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KJ4NHacHANS",
    "outputId": "63500498-f0f0-40f3-8da2-86027094c125"
   },
   "outputs": [],
   "source": [
    "from lazyme import color_str\n",
    "\n",
    "def visualize_predictions(x, y, prediction, vocab, window_size, unk='<unk>'):\n",
    "    left = ' '.join([vocab.get(int(_x), '<unk>') for _x in x[:window_size]])\n",
    "    right = ' '.join([vocab.get(int(_x), '<unk>') for _x in x[window_size:]])\n",
    "    target = vocab.get(int(y), '<unk>')\n",
    "\n",
    "    if not prediction:\n",
    "        predicted_word = '______'\n",
    "    else:\n",
    "        predicted_word = vocab.get(int(prediction), '<unk>') \n",
    "    print(color_str(target, 'green'), '\\t' if len(target) > 6 else '\\t\\t', \n",
    "          left, color_str(predicted_word, 'green' if target == predicted_word else 'red'), right)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCTIgQLwHAOM"
   },
   "source": [
    "<a id=\"section-3-1-4-cbow-model\"></a>\n",
    "\n",
    "## The CBOW Model\n",
    "\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/word2vec-cbow.png\" width=\"500\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bulk of linguistic questions concern the dis- tinction between a and m. a linguistic account of a phenomenon gen- erally gives us reason to view the relation between , for example , a verb ’ s syntax and its semantics , as motivated rather than arbitrary .\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b1b3cd414631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw2v_io\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw2v_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_io\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_io\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mvisualize_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "sent_idx = 10\n",
    "window_size = 2\n",
    "w2v_dataset = Word2VecText(tokenized_text, window_size=window_size, variant='cbow')\n",
    "print(' '.join(w2v_dataset.sents[sent_idx]))\n",
    "for w2v_io in w2v_dataset[sent_idx]:\n",
    "    context, target = w2v_io['x'], w2v_io['y']\n",
    "    context, target = tensor(context).to(device), tensor(target).to(device)\n",
    "    visualize_predictions(context, target, None, w2v_dataset.vocab, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVhbh2OoHAON"
   },
   "source": [
    "(Image from https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bE4_o2uHAOO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # vocab_size: V\n",
    "        # embed_size: E\n",
    "        # hidden_size: H\n",
    "        \n",
    "        # shape: (, 4) ~~> (4, V) ==> via x weights:(V, E) ==>  (4, E)\n",
    "        embedded = self.embeddings(inputs)\n",
    "        \n",
    "        # shape: (4, E) ==> via flatten ==> (1, 4*E)\n",
    "        flatten_embed = embedded.view((1, -1))\n",
    "        \n",
    "        # shape: (1, 4*E) ==> via x weights:(4*E, H) ==> (1, H)\n",
    "        hid = F.relu(self.linear1(flatten_embed)) \n",
    "        \n",
    "        # shape: (1, H) ==> via x weights:(H, V) ==> (1, V)\n",
    "        out = self.linear2(hid)\n",
    "        \n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0XM-9CoHAOQ"
   },
   "source": [
    "## Lets take a closer look from the inputs to the first `nn.Linear`\n",
    "\n",
    "Cos after it reach the first `nn.Linear` it's just the same as our multi-layered perceptron example =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWtD5VoxHAOR",
    "outputId": "e602d428-841e-4caf-c8c1-96139cb58fde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': [10, 8, 0, 7], 'y': 11},\n",
       " {'x': [8, 11, 7, 0], 'y': 0},\n",
       " {'x': [11, 0, 0, 7], 'y': 7},\n",
       " {'x': [0, 7, 7, 0], 'y': 0},\n",
       " {'x': [7, 0, 0, 13], 'y': 7},\n",
       " {'x': [0, 7, 13, 3], 'y': 0},\n",
       " {'x': [7, 0, 3, 9], 'y': 13},\n",
       " {'x': [0, 13, 9, 2], 'y': 3},\n",
       " {'x': [13, 3, 2, 10], 'y': 9},\n",
       " {'x': [3, 9, 10, 15], 'y': 2},\n",
       " {'x': [9, 2, 15, 11], 'y': 10},\n",
       " {'x': [2, 10, 11, 5], 'y': 15},\n",
       " {'x': [10, 15, 5, 16], 'y': 11},\n",
       " {'x': [15, 11, 16, 14], 'y': 5},\n",
       " {'x': [11, 5, 14, 0], 'y': 16},\n",
       " {'x': [5, 16, 0, 4], 'y': 14},\n",
       " {'x': [16, 14, 4, 10], 'y': 0},\n",
       " {'x': [14, 0, 10, 8], 'y': 4},\n",
       " {'x': [0, 4, 8, 6], 'y': 10},\n",
       " {'x': [4, 10, 6, 12], 'y': 8},\n",
       " {'x': [10, 8, 12, 1], 'y': 6}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrihyEczHAOa",
    "outputId": "3e24e240-1b66-443a-fa8b-be608b5b7e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  8,  0,  7])\n",
      "tensor(11)\n"
     ]
    }
   ],
   "source": [
    "# Lets take a look at the first output.\n",
    "\n",
    "x, y = w2v_dataset[0][0]['x'],  w2v_dataset[0][0]['y']\n",
    "\n",
    "x = tensor(x)\n",
    "y = autograd.Variable(tensor(y, dtype=torch.long))\n",
    "# eqv to y = tensor(y, dtype=torch.long, requires_grad=True)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSQ1tZxaHAOd",
    "outputId": "5829ea69-2a46-4cf6-e542-bd150de0f2c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.7153,  1.7479, -0.6117,  ...,  1.0815, -1.7000, -0.6705],\n",
       "                      [ 0.3753,  0.3314,  0.0829,  ...,  1.0841, -0.8687, -2.0626],\n",
       "                      [ 0.8162,  1.1755, -1.8758,  ...,  0.2869,  1.5779, -0.2956],\n",
       "                      ...,\n",
       "                      [ 0.7069,  0.9629,  1.3972,  ..., -1.6224, -1.4650, -1.1592],\n",
       "                      [-0.0302, -1.2826, -1.6638,  ...,  0.2575,  0.7669,  1.5370],\n",
       "                      [-1.1147, -1.0100, -1.1918,  ..., -0.8127, -0.0152, -1.4089]]))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd_size = 16\n",
    "emb = nn.Embedding(len(w2v_dataset.vocab), embd_size)\n",
    "emb.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMSpy8GNHAOf",
    "outputId": "83be6b9c-7fc2-4ef8-e420-2e680fb88dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1388, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7153,  1.7479, -0.6117,  ...,  1.0815, -1.7000, -0.6705],\n",
       "        [ 0.3753,  0.3314,  0.0829,  ...,  1.0841, -0.8687, -2.0626],\n",
       "        [ 0.8162,  1.1755, -1.8758,  ...,  0.2869,  1.5779, -0.2956],\n",
       "        ...,\n",
       "        [ 0.7069,  0.9629,  1.3972,  ..., -1.6224, -1.4650, -1.1592],\n",
       "        [-0.0302, -1.2826, -1.6638,  ...,  0.2575,  0.7669,  1.5370],\n",
       "        [-1.1147, -1.0100, -1.1918,  ..., -0.8127, -0.0152, -1.4089]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emb.state_dict()['weight'].shape)\n",
    "emb.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_5qYpO8HAOh",
    "outputId": "dfb5fe3d-7f02-407b-ee86-50c86179917c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "tensor([[-0.3253, -0.2608,  0.2228, -1.4508,  1.0638,  0.1867, -0.3235,  0.5421,\n",
      "         -1.1007, -2.0327, -0.4239, -1.2057,  0.7376,  1.0613, -0.8919,  1.2731],\n",
      "        [ 0.4798,  0.5355,  0.0711, -0.5138,  1.5813, -2.1590,  0.4064, -0.0569,\n",
      "         -0.3886,  0.5179,  0.9036,  0.2085, -1.1335,  0.5126, -1.0820, -1.0251],\n",
      "        [ 0.7153,  1.7479, -0.6117, -1.4266,  0.8099,  1.6911,  0.6661, -1.0740,\n",
      "         -1.3789, -1.7196, -0.8043,  0.1148, -1.8357,  1.0815, -1.7000, -0.6705],\n",
      "        [ 0.0192,  0.8208,  1.2063,  0.0301,  0.6522,  0.2502,  0.9660,  0.6276,\n",
      "         -1.5130, -1.1698,  0.8151, -0.9970,  0.8429,  0.6015,  0.3918, -0.0344]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(emb(x).shape)\n",
    "print(emb(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suT4Nm24HAOj",
    "outputId": "9e348f3b-fc50-4bba-981a-86448bd21775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3253, -0.2608,  0.2228, -1.4508,  1.0638,  0.1867, -0.3235,  0.5421,\n",
       "         -1.1007, -2.0327, -0.4239, -1.2057,  0.7376,  1.0613, -0.8919,  1.2731,\n",
       "          0.4798,  0.5355,  0.0711, -0.5138,  1.5813, -2.1590,  0.4064, -0.0569,\n",
       "         -0.3886,  0.5179,  0.9036,  0.2085, -1.1335,  0.5126, -1.0820, -1.0251,\n",
       "          0.7153,  1.7479, -0.6117, -1.4266,  0.8099,  1.6911,  0.6661, -1.0740,\n",
       "         -1.3789, -1.7196, -0.8043,  0.1148, -1.8357,  1.0815, -1.7000, -0.6705,\n",
       "          0.0192,  0.8208,  1.2063,  0.0301,  0.6522,  0.2502,  0.9660,  0.6276,\n",
       "         -1.5130, -1.1698,  0.8151, -0.9970,  0.8429,  0.6015,  0.3918, -0.0344]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emb(x).view(1, -1).shape)\n",
    "emb(x).view(1, -1) # view() = reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Trdx-g3SHAOl",
    "outputId": "c4720d0f-0acc-4e8c-ce73-47f84cf1f564",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.0506,  0.0021,  0.1154,  ..., -0.0767, -0.0202, -0.0624],\n",
      "        [ 0.0939, -0.0023,  0.0396,  ...,  0.0817,  0.1098, -0.1113],\n",
      "        [-0.1063,  0.1238,  0.0366,  ..., -0.1244, -0.0652, -0.0574],\n",
      "        ...,\n",
      "        [ 0.1086,  0.0232,  0.0480,  ...,  0.0869,  0.0604,  0.0619],\n",
      "        [-0.1002, -0.0821,  0.0834,  ...,  0.0251, -0.0598,  0.1157],\n",
      "        [ 0.0528, -0.0539,  0.0341,  ...,  0.0835, -0.0745,  0.0463]])), ('bias', tensor([ 5.1154e-02,  3.7107e-02,  1.0507e-01,  6.9028e-03,  1.1038e-01,\n",
      "        -2.6856e-02, -2.9821e-02, -5.7821e-02, -1.1637e-02,  4.2438e-02,\n",
      "         1.0412e-02,  6.3235e-02,  1.4381e-02, -1.2058e-01, -4.0786e-02,\n",
      "        -2.5160e-02, -4.4839e-02, -1.0301e-01,  8.9467e-02,  1.2248e-01,\n",
      "        -1.0799e-01, -4.5749e-02, -3.0971e-02, -1.1941e-01,  3.1865e-02,\n",
      "        -8.2862e-02, -6.5516e-02, -3.9175e-04, -4.4868e-02, -5.2012e-02,\n",
      "         1.2923e-02,  2.4054e-02,  3.5355e-02,  5.7571e-02,  2.6998e-03,\n",
      "         9.4156e-02, -3.4981e-02,  3.1748e-02,  9.5843e-02,  2.1189e-02,\n",
      "        -6.4079e-02,  6.6885e-02, -1.1930e-04,  6.6045e-02, -1.0639e-02,\n",
      "         7.2028e-02,  4.2256e-02, -9.3609e-02,  1.1179e-02,  1.5298e-02,\n",
      "        -1.0331e-01,  6.5518e-02,  1.1525e-01,  1.1942e-01,  6.0174e-02,\n",
      "        -1.0528e-01, -1.2319e-01, -4.5928e-02, -1.7924e-02, -6.7820e-02,\n",
      "         9.7144e-02,  5.4318e-02, -7.9690e-02, -2.6486e-02,  4.3424e-02,\n",
      "        -5.5222e-02,  2.7405e-02,  2.2028e-02, -4.6379e-02,  3.7875e-02,\n",
      "         1.1690e-01,  7.3680e-02, -1.6514e-02, -7.7849e-02, -2.6680e-02,\n",
      "        -1.1562e-01,  2.6717e-02,  2.4723e-02, -3.2609e-02,  6.5452e-02,\n",
      "         9.2744e-02,  2.8315e-02, -1.1917e-01, -4.2340e-02, -1.2430e-01,\n",
      "         1.1271e-01, -7.9391e-02, -1.1973e-01, -6.3606e-02, -4.7410e-02,\n",
      "         4.0040e-02,  5.8042e-02,  4.9015e-02, -9.0028e-02,  8.1351e-02,\n",
      "         5.3473e-02,  3.6937e-02,  9.5909e-02, -4.2752e-02, -7.7939e-02]))])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "lin1 = nn.Linear(len(x)*embd_size, hidden_size)\n",
    "print(lin1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pekv5vr3HAOn",
    "outputId": "9120d23d-3dbf-4690-b0e0-dc246f160a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64])\n",
      "tensor([[-0.0506,  0.0021,  0.1154,  ..., -0.0767, -0.0202, -0.0624],\n",
      "        [ 0.0939, -0.0023,  0.0396,  ...,  0.0817,  0.1098, -0.1113],\n",
      "        [-0.1063,  0.1238,  0.0366,  ..., -0.1244, -0.0652, -0.0574],\n",
      "        ...,\n",
      "        [ 0.1086,  0.0232,  0.0480,  ...,  0.0869,  0.0604,  0.0619],\n",
      "        [-0.1002, -0.0821,  0.0834,  ...,  0.0251, -0.0598,  0.1157],\n",
      "        [ 0.0528, -0.0539,  0.0341,  ...,  0.0835, -0.0745,  0.0463]])\n"
     ]
    }
   ],
   "source": [
    "print(lin1.state_dict()['weight'].shape)\n",
    "print(lin1.state_dict()['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8PYFtEKHAOn",
    "outputId": "7a53ced5-d039-40c1-f35e-c48aac1a0ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2689,  0.1491, -0.2944, -0.8299,  0.6464,  0.2149,  0.8135, -1.1905,\n",
       "          1.1258,  0.8768,  0.0539, -0.6027,  0.3818,  0.4208,  0.5270, -0.8406,\n",
       "         -0.7669, -0.2208, -0.5445,  0.3252, -0.1530,  0.3448,  0.1566,  0.5688,\n",
       "          0.4407,  0.2625, -0.3181,  0.5758,  0.6550, -0.3085, -0.0901, -1.3622,\n",
       "          0.3786, -0.9632,  0.2392, -0.3284, -1.2036,  0.3415, -0.5742,  0.8493,\n",
       "         -0.2941,  0.4608,  0.1220,  0.4874, -0.5853,  0.5183, -0.0247, -0.8890,\n",
       "         -1.3457, -0.3019,  0.0433,  0.3913,  0.8927,  0.8925, -0.3889, -0.5671,\n",
       "         -0.4037, -0.6404,  0.1642, -1.4540, -0.7041,  0.3827,  0.6824,  0.1639,\n",
       "          0.5283,  0.2287,  0.1899, -0.0336, -0.1974,  0.4755,  0.0246, -0.9769,\n",
       "          0.3483, -0.7468, -1.1082, -0.2819, -0.8269, -0.4429, -0.6402, -0.2782,\n",
       "          0.2357,  0.4178,  0.2248, -0.1553,  0.6363, -0.6831, -0.0275, -0.8776,\n",
       "         -0.5874,  1.0407,  0.0969, -0.1305, -1.4278, -0.5536, -0.0446, -0.7551,\n",
       "         -0.2387,  0.4420,  0.1143, -0.5075]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lin1(emb(x).view(1, -1)).shape)\n",
    "lin1(emb(x).view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnMag-0tHAOp",
    "outputId": "559bea7c-34e1-42d2-b1b3-7457e00b7f7e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2689, 0.1491, 0.0000, 0.0000, 0.6464, 0.2149, 0.8135, 0.0000, 1.1258,\n",
       "         0.8768, 0.0539, 0.0000, 0.3818, 0.4208, 0.5270, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3252, 0.0000, 0.3448, 0.1566, 0.5688, 0.4407, 0.2625, 0.0000,\n",
       "         0.5758, 0.6550, 0.0000, 0.0000, 0.0000, 0.3786, 0.0000, 0.2392, 0.0000,\n",
       "         0.0000, 0.3415, 0.0000, 0.8493, 0.0000, 0.4608, 0.1220, 0.4874, 0.0000,\n",
       "         0.5183, 0.0000, 0.0000, 0.0000, 0.0000, 0.0433, 0.3913, 0.8927, 0.8925,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1642, 0.0000, 0.0000, 0.3827, 0.6824,\n",
       "         0.1639, 0.5283, 0.2287, 0.1899, 0.0000, 0.0000, 0.4755, 0.0246, 0.0000,\n",
       "         0.3483, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2357,\n",
       "         0.4178, 0.2248, 0.0000, 0.6363, 0.0000, 0.0000, 0.0000, 0.0000, 1.0407,\n",
       "         0.0969, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4420, 0.1143,\n",
       "         0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "print(relu(lin1(emb(x).view(1, -1))).shape)\n",
    "relu(lin1(emb(x).view(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVwej9y_HAOr",
    "outputId": "b2f5a8fc-bf76-42c7-8fdd-4d1ed4db4e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1388, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0433, -0.0022,  0.0363,  ...,  0.0138, -0.0349, -0.0199],\n",
       "        [-0.0478,  0.0824, -0.0099,  ...,  0.0979,  0.0941, -0.0290],\n",
       "        [-0.0352,  0.0961, -0.0827,  ...,  0.0174,  0.0876,  0.0253],\n",
       "        ...,\n",
       "        [ 0.0594,  0.0685,  0.0564,  ..., -0.0227, -0.0058,  0.0499],\n",
       "        [-0.0168,  0.0030,  0.0279,  ...,  0.0057,  0.0448,  0.0037],\n",
       "        [ 0.0339, -0.0923,  0.0680,  ..., -0.0628,  0.0379, -0.0388]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin2 = nn.Linear(hidden_size, len(w2v_dataset.vocab))\n",
    "print(lin2.state_dict()['weight'].shape)\n",
    "lin2.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asgRwXehHAOs",
    "outputId": "dd545005-24ae-49d6-922a-c63393c4472f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1388])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0038,  0.1834,  0.1476,  ..., -0.3712, -0.0427,  0.0289]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_x = relu(lin1(emb(x).view(1, -1)))\n",
    "print(lin2(h_x).shape)\n",
    "lin2(h_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GJLGwdkHAOv",
    "outputId": "22a0b70d-977e-47f8-98ca-18f90f248b0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-7.252162933349609,\n",
       "  -7.072550296783447,\n",
       "  -7.108374118804932,\n",
       "  -7.20729398727417,\n",
       "  -7.617002964019775,\n",
       "  -7.630112171173096,\n",
       "  -7.162570476531982,\n",
       "  -6.918042182922363,\n",
       "  -7.005789279937744,\n",
       "  -7.161597728729248,\n",
       "  -7.170647621154785,\n",
       "  -7.653318881988525,\n",
       "  -7.321627140045166,\n",
       "  -7.838001251220703,\n",
       "  -7.375617504119873,\n",
       "  -7.493913650512695,\n",
       "  -7.183315753936768,\n",
       "  -7.60685920715332,\n",
       "  -7.1636881828308105,\n",
       "  -7.343142986297607,\n",
       "  -7.628304958343506,\n",
       "  -7.375884056091309,\n",
       "  -7.088252544403076,\n",
       "  -7.174910545349121,\n",
       "  -7.156351089477539,\n",
       "  -7.492038249969482,\n",
       "  -6.958305358886719,\n",
       "  -7.8140106201171875,\n",
       "  -7.453192710876465,\n",
       "  -7.362573146820068,\n",
       "  -7.268645286560059,\n",
       "  -7.407510757446289,\n",
       "  -7.3799357414245605,\n",
       "  -7.364015579223633,\n",
       "  -7.284485816955566,\n",
       "  -7.174019813537598,\n",
       "  -7.6030592918396,\n",
       "  -7.623497486114502,\n",
       "  -7.058132171630859,\n",
       "  -7.456703186035156,\n",
       "  -7.244445323944092,\n",
       "  -7.475480079650879,\n",
       "  -7.380141735076904,\n",
       "  -7.039546489715576,\n",
       "  -7.495331287384033,\n",
       "  -7.069267749786377,\n",
       "  -7.241220474243164,\n",
       "  -7.419578552246094,\n",
       "  -7.5368499755859375,\n",
       "  -7.309144973754883,\n",
       "  -7.260221004486084,\n",
       "  -7.169872760772705,\n",
       "  -7.061738967895508,\n",
       "  -7.203861236572266,\n",
       "  -7.411920547485352,\n",
       "  -7.013947486877441,\n",
       "  -7.237018585205078,\n",
       "  -6.760635852813721,\n",
       "  -7.127782821655273,\n",
       "  -7.282485008239746,\n",
       "  -7.470410346984863,\n",
       "  -7.202929973602295,\n",
       "  -6.983566761016846,\n",
       "  -6.824987888336182,\n",
       "  -7.185708999633789,\n",
       "  -6.948057651519775,\n",
       "  -7.007857799530029,\n",
       "  -7.1322736740112305,\n",
       "  -7.3519182205200195,\n",
       "  -6.869755744934082,\n",
       "  -6.82758903503418,\n",
       "  -6.914280891418457,\n",
       "  -6.7270989418029785,\n",
       "  -7.081377029418945,\n",
       "  -7.398591995239258,\n",
       "  -7.295327186584473,\n",
       "  -7.464356422424316,\n",
       "  -7.0315752029418945,\n",
       "  -7.615239143371582,\n",
       "  -7.544297695159912,\n",
       "  -7.266775131225586,\n",
       "  -6.953469276428223,\n",
       "  -6.982694149017334,\n",
       "  -7.085177898406982,\n",
       "  -7.167694568634033,\n",
       "  -7.328183174133301,\n",
       "  -7.213404655456543,\n",
       "  -7.569960594177246,\n",
       "  -7.418214797973633,\n",
       "  -7.306098461151123,\n",
       "  -6.9288482666015625,\n",
       "  -7.376594066619873,\n",
       "  -7.269692897796631,\n",
       "  -7.699222564697266,\n",
       "  -7.381860733032227,\n",
       "  -6.9531097412109375,\n",
       "  -7.283114433288574,\n",
       "  -7.504533767700195,\n",
       "  -7.098136901855469,\n",
       "  -6.996575355529785,\n",
       "  -7.716235160827637,\n",
       "  -7.161383152008057,\n",
       "  -7.349740505218506,\n",
       "  -7.5188398361206055,\n",
       "  -7.420126914978027,\n",
       "  -7.0493998527526855,\n",
       "  -6.827244281768799,\n",
       "  -6.998954772949219,\n",
       "  -7.265984058380127,\n",
       "  -7.167260646820068,\n",
       "  -7.230344295501709,\n",
       "  -7.334382057189941,\n",
       "  -7.48875093460083,\n",
       "  -7.343258380889893,\n",
       "  -7.195794105529785,\n",
       "  -7.454593181610107,\n",
       "  -7.377608776092529,\n",
       "  -7.688854694366455,\n",
       "  -7.44791841506958,\n",
       "  -7.263931751251221,\n",
       "  -7.4818525314331055,\n",
       "  -7.406793594360352,\n",
       "  -7.118407726287842,\n",
       "  -7.282478332519531,\n",
       "  -7.561212539672852,\n",
       "  -7.181186199188232,\n",
       "  -7.396945476531982,\n",
       "  -7.43160343170166,\n",
       "  -7.132111072540283,\n",
       "  -7.42364501953125,\n",
       "  -7.29580545425415,\n",
       "  -7.096675872802734,\n",
       "  -7.1209797859191895,\n",
       "  -7.16558837890625,\n",
       "  -7.58820104598999,\n",
       "  -7.222672462463379,\n",
       "  -7.009431838989258,\n",
       "  -7.323356628417969,\n",
       "  -7.170295715332031,\n",
       "  -7.2925310134887695,\n",
       "  -7.393195152282715,\n",
       "  -7.426015377044678,\n",
       "  -7.169867515563965,\n",
       "  -6.986742973327637,\n",
       "  -6.923084735870361,\n",
       "  -7.1193928718566895,\n",
       "  -7.277376174926758,\n",
       "  -7.308041572570801,\n",
       "  -7.198323726654053,\n",
       "  -7.429840564727783,\n",
       "  -7.607823848724365,\n",
       "  -7.044933319091797,\n",
       "  -7.272140026092529,\n",
       "  -7.040678977966309,\n",
       "  -7.356187343597412,\n",
       "  -6.961259841918945,\n",
       "  -7.269863605499268,\n",
       "  -7.462407112121582,\n",
       "  -7.205318927764893,\n",
       "  -7.309087753295898,\n",
       "  -7.201182842254639,\n",
       "  -7.0778584480285645,\n",
       "  -7.465197563171387,\n",
       "  -7.294826984405518,\n",
       "  -7.143626689910889,\n",
       "  -7.227731227874756,\n",
       "  -7.610095024108887,\n",
       "  -7.260262489318848,\n",
       "  -7.544465065002441,\n",
       "  -7.025639533996582,\n",
       "  -6.985619068145752,\n",
       "  -7.424489498138428,\n",
       "  -7.162614345550537,\n",
       "  -7.331731796264648,\n",
       "  -6.942164421081543,\n",
       "  -7.416812419891357,\n",
       "  -7.276401996612549,\n",
       "  -7.253231525421143,\n",
       "  -7.3628363609313965,\n",
       "  -6.758042812347412,\n",
       "  -7.24375581741333,\n",
       "  -7.066205024719238,\n",
       "  -7.199901580810547,\n",
       "  -7.64304256439209,\n",
       "  -7.379212379455566,\n",
       "  -7.146060466766357,\n",
       "  -7.489315986633301,\n",
       "  -7.202482223510742,\n",
       "  -7.057870864868164,\n",
       "  -7.069764137268066,\n",
       "  -7.358060359954834,\n",
       "  -7.274530410766602,\n",
       "  -7.315945148468018,\n",
       "  -7.2986650466918945,\n",
       "  -7.1885552406311035,\n",
       "  -7.118056297302246,\n",
       "  -7.1616597175598145,\n",
       "  -7.213373184204102,\n",
       "  -7.6346893310546875,\n",
       "  -7.484207630157471,\n",
       "  -6.724948406219482,\n",
       "  -7.079996585845947,\n",
       "  -7.252535343170166,\n",
       "  -7.109468460083008,\n",
       "  -6.9483466148376465,\n",
       "  -7.798189163208008,\n",
       "  -7.51552677154541,\n",
       "  -6.919733047485352,\n",
       "  -7.846139907836914,\n",
       "  -7.189916133880615,\n",
       "  -7.335182189941406,\n",
       "  -7.399899482727051,\n",
       "  -7.048271179199219,\n",
       "  -7.213576316833496,\n",
       "  -6.942427635192871,\n",
       "  -6.757065296173096,\n",
       "  -7.408808708190918,\n",
       "  -7.2511186599731445,\n",
       "  -7.418084144592285,\n",
       "  -7.111239433288574,\n",
       "  -7.241573333740234,\n",
       "  -7.677414894104004,\n",
       "  -7.267663478851318,\n",
       "  -7.58383321762085,\n",
       "  -7.2115797996521,\n",
       "  -7.398242950439453,\n",
       "  -7.327388286590576,\n",
       "  -7.135403633117676,\n",
       "  -7.492248058319092,\n",
       "  -7.56304407119751,\n",
       "  -7.748445510864258,\n",
       "  -7.166207790374756,\n",
       "  -7.004619598388672,\n",
       "  -7.066493034362793,\n",
       "  -7.142195701599121,\n",
       "  -7.387661933898926,\n",
       "  -7.081109523773193,\n",
       "  -6.916830062866211,\n",
       "  -7.34002685546875,\n",
       "  -7.401271343231201,\n",
       "  -7.190550327301025,\n",
       "  -7.446496486663818,\n",
       "  -7.189317226409912,\n",
       "  -7.77968692779541,\n",
       "  -7.0510029792785645,\n",
       "  -7.108306884765625,\n",
       "  -7.406830310821533,\n",
       "  -7.701619625091553,\n",
       "  -7.617251873016357,\n",
       "  -7.069028854370117,\n",
       "  -6.982593059539795,\n",
       "  -6.961575031280518,\n",
       "  -7.291085243225098,\n",
       "  -7.140448093414307,\n",
       "  -7.378097057342529,\n",
       "  -7.3462700843811035,\n",
       "  -7.2327704429626465,\n",
       "  -6.791586399078369,\n",
       "  -7.4806928634643555,\n",
       "  -7.06361198425293,\n",
       "  -6.842963695526123,\n",
       "  -7.459414005279541,\n",
       "  -7.134048938751221,\n",
       "  -7.16451358795166,\n",
       "  -7.590339183807373,\n",
       "  -7.180537700653076,\n",
       "  -6.992118835449219,\n",
       "  -7.39671516418457,\n",
       "  -7.336182594299316,\n",
       "  -7.098867416381836,\n",
       "  -7.323976993560791,\n",
       "  -7.52485990524292,\n",
       "  -7.367817401885986,\n",
       "  -7.357044219970703,\n",
       "  -7.275488376617432,\n",
       "  -6.954977512359619,\n",
       "  -7.073544502258301,\n",
       "  -6.7791972160339355,\n",
       "  -7.5607008934021,\n",
       "  -7.22237491607666,\n",
       "  -7.151673793792725,\n",
       "  -7.23388671875,\n",
       "  -7.153101921081543,\n",
       "  -6.959163188934326,\n",
       "  -7.729647636413574,\n",
       "  -7.526076316833496,\n",
       "  -7.459125995635986,\n",
       "  -7.0340895652771,\n",
       "  -7.405467987060547,\n",
       "  -7.5010833740234375,\n",
       "  -7.6124267578125,\n",
       "  -7.526711463928223,\n",
       "  -7.140963077545166,\n",
       "  -7.420665264129639,\n",
       "  -7.457160472869873,\n",
       "  -7.327649116516113,\n",
       "  -7.024910926818848,\n",
       "  -7.134029865264893,\n",
       "  -7.609027862548828,\n",
       "  -7.047848224639893,\n",
       "  -7.259376049041748,\n",
       "  -7.261911392211914,\n",
       "  -7.1973466873168945,\n",
       "  -7.109508991241455,\n",
       "  -7.444079399108887,\n",
       "  -7.178756237030029,\n",
       "  -7.394593238830566,\n",
       "  -6.934719085693359,\n",
       "  -7.624166488647461,\n",
       "  -7.460313320159912,\n",
       "  -7.320016384124756,\n",
       "  -7.5438127517700195,\n",
       "  -6.878925323486328,\n",
       "  -7.181473731994629,\n",
       "  -6.898441791534424,\n",
       "  -7.520855903625488,\n",
       "  -7.373419284820557,\n",
       "  -7.28083610534668,\n",
       "  -7.148538112640381,\n",
       "  -7.156142711639404,\n",
       "  -7.473424911499023,\n",
       "  -7.032975673675537,\n",
       "  -7.3744072914123535,\n",
       "  -7.434049129486084,\n",
       "  -7.036121368408203,\n",
       "  -7.05462646484375,\n",
       "  -7.120449542999268,\n",
       "  -7.163137435913086,\n",
       "  -7.564858436584473,\n",
       "  -7.371052265167236,\n",
       "  -7.579743385314941,\n",
       "  -7.60466194152832,\n",
       "  -7.469087600708008,\n",
       "  -6.856908798217773,\n",
       "  -7.348628997802734,\n",
       "  -7.145291328430176,\n",
       "  -7.030722618103027,\n",
       "  -7.459788799285889,\n",
       "  -7.2929816246032715,\n",
       "  -7.171723365783691,\n",
       "  -7.229380130767822,\n",
       "  -6.758856296539307,\n",
       "  -7.705082893371582,\n",
       "  -7.508737564086914,\n",
       "  -7.285443305969238,\n",
       "  -7.146268367767334,\n",
       "  -7.153783798217773,\n",
       "  -7.368869304656982,\n",
       "  -6.9009199142456055,\n",
       "  -7.10212516784668,\n",
       "  -7.244845867156982,\n",
       "  -7.187335014343262,\n",
       "  -7.345931529998779,\n",
       "  -7.221495151519775,\n",
       "  -7.483240127563477,\n",
       "  -7.401894569396973,\n",
       "  -7.339776992797852,\n",
       "  -7.27097225189209,\n",
       "  -7.227535724639893,\n",
       "  -7.00114107131958,\n",
       "  -7.197325229644775,\n",
       "  -7.318745136260986,\n",
       "  -7.420370578765869,\n",
       "  -7.45989465713501,\n",
       "  -7.1290178298950195,\n",
       "  -7.235002040863037,\n",
       "  -7.403082847595215,\n",
       "  -7.181647300720215,\n",
       "  -7.467256546020508,\n",
       "  -7.076148509979248,\n",
       "  -7.22071647644043,\n",
       "  -7.205808639526367,\n",
       "  -7.220903396606445,\n",
       "  -7.2548604011535645,\n",
       "  -7.382441997528076,\n",
       "  -7.444641590118408,\n",
       "  -7.34975004196167,\n",
       "  -7.313342571258545,\n",
       "  -7.167505741119385,\n",
       "  -7.474907875061035,\n",
       "  -7.567135810852051,\n",
       "  -7.555075645446777,\n",
       "  -7.223915100097656,\n",
       "  -6.952085494995117,\n",
       "  -7.4179182052612305,\n",
       "  -7.186282157897949,\n",
       "  -7.1493730545043945,\n",
       "  -7.422850131988525,\n",
       "  -7.207409858703613,\n",
       "  -7.206038951873779,\n",
       "  -6.973247528076172,\n",
       "  -7.220961570739746,\n",
       "  -7.002138614654541,\n",
       "  -7.394813537597656,\n",
       "  -7.621318340301514,\n",
       "  -7.2055277824401855,\n",
       "  -6.769803047180176,\n",
       "  -7.641422271728516,\n",
       "  -6.868689060211182,\n",
       "  -7.402247905731201,\n",
       "  -7.16262674331665,\n",
       "  -7.071346759796143,\n",
       "  -7.433932781219482,\n",
       "  -7.401505947113037,\n",
       "  -7.166821479797363,\n",
       "  -7.233035564422607,\n",
       "  -7.373966217041016,\n",
       "  -6.887124061584473,\n",
       "  -7.391231536865234,\n",
       "  -7.378793716430664,\n",
       "  -7.416609764099121,\n",
       "  -7.276920795440674,\n",
       "  -7.5409464836120605,\n",
       "  -7.02634334564209,\n",
       "  -7.393310070037842,\n",
       "  -7.265406131744385,\n",
       "  -6.844259262084961,\n",
       "  -7.5384521484375,\n",
       "  -7.25337028503418,\n",
       "  -6.720697402954102,\n",
       "  -7.381683349609375,\n",
       "  -7.361380100250244,\n",
       "  -7.350649833679199,\n",
       "  -7.093607425689697,\n",
       "  -7.183493137359619,\n",
       "  -7.181878566741943,\n",
       "  -7.188124179840088,\n",
       "  -7.4280009269714355,\n",
       "  -7.1653618812561035,\n",
       "  -7.541670799255371,\n",
       "  -7.140833377838135,\n",
       "  -7.225942611694336,\n",
       "  -7.07064151763916,\n",
       "  -7.141772270202637,\n",
       "  -7.0795063972473145,\n",
       "  -7.470355033874512,\n",
       "  -7.266335964202881,\n",
       "  -7.235506057739258,\n",
       "  -7.12805700302124,\n",
       "  -6.97648811340332,\n",
       "  -6.9961395263671875,\n",
       "  -7.264984130859375,\n",
       "  -6.903542995452881,\n",
       "  -7.376328945159912,\n",
       "  -6.89406156539917,\n",
       "  -7.226171016693115,\n",
       "  -7.084480285644531,\n",
       "  -7.025482654571533,\n",
       "  -7.143923282623291,\n",
       "  -7.473114490509033,\n",
       "  -7.302107810974121,\n",
       "  -7.269063949584961,\n",
       "  -7.284605026245117,\n",
       "  -7.45091438293457,\n",
       "  -7.576756477355957,\n",
       "  -7.347645282745361,\n",
       "  -7.456124782562256,\n",
       "  -7.268031120300293,\n",
       "  -7.147225856781006,\n",
       "  -6.882264137268066,\n",
       "  -7.701624870300293,\n",
       "  -7.156888008117676,\n",
       "  -7.421508312225342,\n",
       "  -7.123741626739502,\n",
       "  -6.803192615509033,\n",
       "  -7.069799900054932,\n",
       "  -7.24908447265625,\n",
       "  -7.239524841308594,\n",
       "  -7.211712837219238,\n",
       "  -7.266190528869629,\n",
       "  -7.168776512145996,\n",
       "  -6.715261936187744,\n",
       "  -7.372402191162109,\n",
       "  -7.153255462646484,\n",
       "  -7.335283279418945,\n",
       "  -7.0715765953063965,\n",
       "  -7.1052470207214355,\n",
       "  -7.108345031738281,\n",
       "  -7.01332950592041,\n",
       "  -7.118422031402588,\n",
       "  -7.316773891448975,\n",
       "  -6.867791652679443,\n",
       "  -7.342184543609619,\n",
       "  -7.310815334320068,\n",
       "  -7.447080135345459,\n",
       "  -7.02634859085083,\n",
       "  -7.574950695037842,\n",
       "  -6.903539180755615,\n",
       "  -7.682168006896973,\n",
       "  -7.480632781982422,\n",
       "  -6.918034076690674,\n",
       "  -7.521323204040527,\n",
       "  -7.186134338378906,\n",
       "  -7.285094738006592,\n",
       "  -7.2513227462768555,\n",
       "  -7.0943827629089355,\n",
       "  -7.296957969665527,\n",
       "  -7.333557605743408,\n",
       "  -7.2004804611206055,\n",
       "  -7.722927093505859,\n",
       "  -7.1154093742370605,\n",
       "  -7.40158748626709,\n",
       "  -6.845522880554199,\n",
       "  -7.3200297355651855,\n",
       "  -7.132364749908447,\n",
       "  -7.172404766082764,\n",
       "  -6.964001655578613,\n",
       "  -7.467124938964844,\n",
       "  -6.74648380279541,\n",
       "  -7.585224151611328,\n",
       "  -7.013503074645996,\n",
       "  -7.2122273445129395,\n",
       "  -7.361155986785889,\n",
       "  -7.231410980224609,\n",
       "  -7.459622383117676,\n",
       "  -7.151209354400635,\n",
       "  -7.189184188842773,\n",
       "  -7.3605241775512695,\n",
       "  -7.040372848510742,\n",
       "  -7.171167373657227,\n",
       "  -7.497191429138184,\n",
       "  -7.1956987380981445,\n",
       "  -7.366030693054199,\n",
       "  -7.080840587615967,\n",
       "  -6.898963928222656,\n",
       "  -7.02051305770874,\n",
       "  -7.1343092918396,\n",
       "  -7.469891548156738,\n",
       "  -7.406672477722168,\n",
       "  -7.634427070617676,\n",
       "  -7.050795078277588,\n",
       "  -7.519220352172852,\n",
       "  -7.345399379730225,\n",
       "  -7.332148551940918,\n",
       "  -7.637110710144043,\n",
       "  -7.415987014770508,\n",
       "  -7.293194770812988,\n",
       "  -7.207597255706787,\n",
       "  -7.389737129211426,\n",
       "  -7.191103935241699,\n",
       "  -6.979251384735107,\n",
       "  -6.881761074066162,\n",
       "  -7.45124626159668,\n",
       "  -7.26456880569458,\n",
       "  -7.414299011230469,\n",
       "  -7.357723236083984,\n",
       "  -7.148052215576172,\n",
       "  -7.042260646820068,\n",
       "  -7.082152843475342,\n",
       "  -7.061581134796143,\n",
       "  -7.221432685852051,\n",
       "  -7.2731170654296875,\n",
       "  -7.250969886779785,\n",
       "  -7.214323043823242,\n",
       "  -6.936100482940674,\n",
       "  -7.756066799163818,\n",
       "  -7.584854602813721,\n",
       "  -7.314735412597656,\n",
       "  -7.255002498626709,\n",
       "  -6.6962199211120605,\n",
       "  -7.196017265319824,\n",
       "  -7.492691993713379,\n",
       "  -7.108381271362305,\n",
       "  -7.670662879943848,\n",
       "  -6.889980792999268,\n",
       "  -7.5305070877075195,\n",
       "  -7.456745624542236,\n",
       "  -6.8189191818237305,\n",
       "  -7.2225847244262695,\n",
       "  -7.541312217712402,\n",
       "  -7.016728401184082,\n",
       "  -7.618041038513184,\n",
       "  -7.5147881507873535,\n",
       "  -7.010662078857422,\n",
       "  -7.467183589935303,\n",
       "  -7.237484455108643,\n",
       "  -7.371697425842285,\n",
       "  -7.4402360916137695,\n",
       "  -7.399697303771973,\n",
       "  -7.301172733306885,\n",
       "  -7.701695919036865,\n",
       "  -6.932288646697998,\n",
       "  -7.1284003257751465,\n",
       "  -6.968413829803467,\n",
       "  -7.359038829803467,\n",
       "  -7.038937568664551,\n",
       "  -7.551855087280273,\n",
       "  -7.393451690673828,\n",
       "  -7.536386489868164,\n",
       "  -7.156827449798584,\n",
       "  -7.449850082397461,\n",
       "  -7.3585028648376465,\n",
       "  -7.519566535949707,\n",
       "  -7.1537322998046875,\n",
       "  -7.140151023864746,\n",
       "  -7.089621543884277,\n",
       "  -7.366936683654785,\n",
       "  -7.201319694519043,\n",
       "  -7.159577369689941,\n",
       "  -6.917906761169434,\n",
       "  -7.4594879150390625,\n",
       "  -7.448164939880371,\n",
       "  -7.39455509185791,\n",
       "  -7.067465305328369,\n",
       "  -7.2929582595825195,\n",
       "  -7.156249523162842,\n",
       "  -7.3159918785095215,\n",
       "  -7.250752925872803,\n",
       "  -6.941993713378906,\n",
       "  -7.213653087615967,\n",
       "  -7.407114505767822,\n",
       "  -7.2492780685424805,\n",
       "  -7.310737609863281,\n",
       "  -7.20228385925293,\n",
       "  -7.366881370544434,\n",
       "  -6.881447792053223,\n",
       "  -7.332155227661133,\n",
       "  -7.019353866577148,\n",
       "  -7.391173839569092,\n",
       "  -7.542243480682373,\n",
       "  -7.3916850090026855,\n",
       "  -7.236993789672852,\n",
       "  -7.045809745788574,\n",
       "  -7.255124092102051,\n",
       "  -7.352480411529541,\n",
       "  -7.043961524963379,\n",
       "  -7.055634498596191,\n",
       "  -7.345983505249023,\n",
       "  -7.261427879333496,\n",
       "  -7.2859578132629395,\n",
       "  -6.745291709899902,\n",
       "  -7.226891994476318,\n",
       "  -7.207499027252197,\n",
       "  -7.159224033355713,\n",
       "  -7.49900484085083,\n",
       "  -7.2515974044799805,\n",
       "  -7.151752948760986,\n",
       "  -7.3963823318481445,\n",
       "  -7.287331581115723,\n",
       "  -7.162303447723389,\n",
       "  -7.479935646057129,\n",
       "  -7.13724946975708,\n",
       "  -7.268104553222656,\n",
       "  -7.078885555267334,\n",
       "  -7.256076335906982,\n",
       "  -7.200212478637695,\n",
       "  -7.160966873168945,\n",
       "  -7.278535842895508,\n",
       "  -7.276963233947754,\n",
       "  -7.11376428604126,\n",
       "  -7.101841926574707,\n",
       "  -7.323609352111816,\n",
       "  -7.50971794128418,\n",
       "  -7.367110729217529,\n",
       "  -7.471859931945801,\n",
       "  -7.219865798950195,\n",
       "  -7.387302875518799,\n",
       "  -7.392702579498291,\n",
       "  -7.556835174560547,\n",
       "  -7.30000638961792,\n",
       "  -7.12501335144043,\n",
       "  -6.93856143951416,\n",
       "  -6.993821144104004,\n",
       "  -7.141556262969971,\n",
       "  -7.387343406677246,\n",
       "  -7.062993049621582,\n",
       "  -7.089600563049316,\n",
       "  -7.381166458129883,\n",
       "  -7.340218544006348,\n",
       "  -7.015026092529297,\n",
       "  -7.4694294929504395,\n",
       "  -6.709914207458496,\n",
       "  -7.623301029205322,\n",
       "  -7.272400856018066,\n",
       "  -6.936387062072754,\n",
       "  -7.298730373382568,\n",
       "  -7.3312153816223145,\n",
       "  -7.072466850280762,\n",
       "  -7.505707263946533,\n",
       "  -7.319582939147949,\n",
       "  -7.262734413146973,\n",
       "  -7.218647480010986,\n",
       "  -7.1697540283203125,\n",
       "  -7.3836822509765625,\n",
       "  -7.615913391113281,\n",
       "  -7.334974765777588,\n",
       "  -7.243288993835449,\n",
       "  -7.399815559387207,\n",
       "  -7.132226943969727,\n",
       "  -7.4519782066345215,\n",
       "  -7.103705406188965,\n",
       "  -7.335638523101807,\n",
       "  -7.262345790863037,\n",
       "  -7.109686851501465,\n",
       "  -7.5755791664123535,\n",
       "  -7.401126861572266,\n",
       "  -7.253598690032959,\n",
       "  -6.78826904296875,\n",
       "  -7.179975509643555,\n",
       "  -7.412298679351807,\n",
       "  -7.141452789306641,\n",
       "  -7.275738716125488,\n",
       "  -7.1516900062561035,\n",
       "  -7.119423866271973,\n",
       "  -7.248475551605225,\n",
       "  -7.207947731018066,\n",
       "  -7.440605163574219,\n",
       "  -7.305516719818115,\n",
       "  -7.366495609283447,\n",
       "  -7.102831840515137,\n",
       "  -7.238561630249023,\n",
       "  -7.3196916580200195,\n",
       "  -7.158958911895752,\n",
       "  -7.206880569458008,\n",
       "  -7.351800918579102,\n",
       "  -7.1281304359436035,\n",
       "  -7.116325855255127,\n",
       "  -7.582273006439209,\n",
       "  -7.418344974517822,\n",
       "  -7.294053554534912,\n",
       "  -7.239091873168945,\n",
       "  -7.17292594909668,\n",
       "  -7.3100504875183105,\n",
       "  -7.658055305480957,\n",
       "  -7.225885391235352,\n",
       "  -7.232583045959473,\n",
       "  -7.609780311584473,\n",
       "  -7.480856418609619,\n",
       "  -7.321853160858154,\n",
       "  -7.187110900878906,\n",
       "  -7.446063995361328,\n",
       "  -7.054450511932373,\n",
       "  -7.409405708312988,\n",
       "  -7.217787265777588,\n",
       "  -7.0064616203308105,\n",
       "  -7.17001485824585,\n",
       "  -7.027414321899414,\n",
       "  -7.511944770812988,\n",
       "  -7.4193115234375,\n",
       "  -7.520853519439697,\n",
       "  -7.57292366027832,\n",
       "  -7.562615871429443,\n",
       "  -7.477630615234375,\n",
       "  -7.5973076820373535,\n",
       "  -7.120631217956543,\n",
       "  -7.035675525665283,\n",
       "  -7.319697380065918,\n",
       "  -7.255603790283203,\n",
       "  -7.463642120361328,\n",
       "  -7.310579776763916,\n",
       "  -7.203567981719971,\n",
       "  -7.431991100311279,\n",
       "  -6.759129524230957,\n",
       "  -7.262739181518555,\n",
       "  -7.144826889038086,\n",
       "  -7.515244960784912,\n",
       "  -6.960703372955322,\n",
       "  -7.56242036819458,\n",
       "  -6.91421365737915,\n",
       "  -7.473645210266113,\n",
       "  -7.658987998962402,\n",
       "  -7.09478759765625,\n",
       "  -7.514529228210449,\n",
       "  -7.132513046264648,\n",
       "  -7.311298847198486,\n",
       "  -7.442440509796143,\n",
       "  -7.041045665740967,\n",
       "  -7.0416131019592285,\n",
       "  -7.532505035400391,\n",
       "  -7.253448009490967,\n",
       "  -7.417732238769531,\n",
       "  -7.3004655838012695,\n",
       "  -7.344560623168945,\n",
       "  -7.346784591674805,\n",
       "  -6.954596996307373,\n",
       "  -7.387809753417969,\n",
       "  -7.293692111968994,\n",
       "  -7.234197616577148,\n",
       "  -7.238491058349609,\n",
       "  -7.248425483703613,\n",
       "  -6.769481182098389,\n",
       "  -7.166133403778076,\n",
       "  -7.1005353927612305,\n",
       "  -7.119991302490234,\n",
       "  -6.991189479827881,\n",
       "  -7.236438751220703,\n",
       "  -7.371694087982178,\n",
       "  -7.113308906555176,\n",
       "  -7.08554220199585,\n",
       "  -7.56718635559082,\n",
       "  -7.113193511962891,\n",
       "  -7.226037502288818,\n",
       "  -7.536315441131592,\n",
       "  -7.234989643096924,\n",
       "  -6.809937953948975,\n",
       "  -7.305824279785156,\n",
       "  -7.1915202140808105,\n",
       "  -7.323908805847168,\n",
       "  -7.381027698516846,\n",
       "  -7.341818809509277,\n",
       "  -7.597701072692871,\n",
       "  -7.08310604095459,\n",
       "  -7.243755340576172,\n",
       "  -7.036011219024658,\n",
       "  -7.062606334686279,\n",
       "  -7.300686359405518,\n",
       "  -7.1371612548828125,\n",
       "  -7.031008720397949,\n",
       "  -7.196774482727051,\n",
       "  -7.172096252441406,\n",
       "  -7.009861946105957,\n",
       "  -7.1315412521362305,\n",
       "  -7.808251857757568,\n",
       "  -7.3138909339904785,\n",
       "  -7.430530071258545,\n",
       "  -7.3712592124938965,\n",
       "  -7.605206489562988,\n",
       "  -7.2587690353393555,\n",
       "  -7.613204002380371,\n",
       "  -7.452116966247559,\n",
       "  -7.474714279174805,\n",
       "  -7.291003227233887,\n",
       "  -7.280766010284424,\n",
       "  -7.216435432434082,\n",
       "  -7.478959560394287,\n",
       "  -7.125921726226807,\n",
       "  -7.355530261993408,\n",
       "  -7.363656997680664,\n",
       "  -7.4321608543396,\n",
       "  -7.4324798583984375,\n",
       "  -7.011050701141357,\n",
       "  -7.56541109085083,\n",
       "  -7.319377899169922,\n",
       "  -7.291780471801758,\n",
       "  -7.736119270324707,\n",
       "  -7.091092109680176,\n",
       "  -7.200793266296387,\n",
       "  -6.9107441902160645,\n",
       "  -6.65022611618042,\n",
       "  -7.658020496368408,\n",
       "  -7.401611328125,\n",
       "  -7.235280513763428,\n",
       "  -7.01132345199585,\n",
       "  -7.139420509338379,\n",
       "  -7.179940223693848,\n",
       "  -7.8176984786987305,\n",
       "  -6.8580451011657715,\n",
       "  -7.193962097167969,\n",
       "  -7.1433281898498535,\n",
       "  -7.631816864013672,\n",
       "  -7.6973981857299805,\n",
       "  -6.975058555603027,\n",
       "  -7.075428485870361,\n",
       "  -6.807765483856201,\n",
       "  -7.5253705978393555,\n",
       "  -7.279640197753906,\n",
       "  -7.4434733390808105,\n",
       "  -7.083256721496582,\n",
       "  -7.087423324584961,\n",
       "  -6.917806625366211,\n",
       "  -7.3582282066345215,\n",
       "  -7.224668502807617,\n",
       "  -7.143932342529297,\n",
       "  -7.512767791748047,\n",
       "  -7.000364303588867,\n",
       "  -7.027527809143066,\n",
       "  -7.117763042449951,\n",
       "  -7.289318561553955,\n",
       "  -7.294525146484375,\n",
       "  -7.077371120452881,\n",
       "  -7.421219348907471,\n",
       "  -7.488729000091553,\n",
       "  -7.323888301849365,\n",
       "  -7.293303489685059,\n",
       "  -7.356512546539307,\n",
       "  -7.2616095542907715,\n",
       "  -7.064787864685059,\n",
       "  -7.515777111053467,\n",
       "  -7.451960563659668,\n",
       "  -7.559165954589844,\n",
       "  -7.337041854858398,\n",
       "  -7.464802265167236,\n",
       "  -7.4261064529418945,\n",
       "  -7.550227165222168,\n",
       "  -7.217259407043457,\n",
       "  -7.344632148742676,\n",
       "  -7.611480236053467,\n",
       "  -7.320551872253418,\n",
       "  -7.042044162750244,\n",
       "  -7.19386100769043,\n",
       "  -7.205855846405029,\n",
       "  -7.089908123016357,\n",
       "  -7.040160179138184,\n",
       "  -7.104619026184082,\n",
       "  -7.298401832580566,\n",
       "  -7.655008792877197,\n",
       "  -7.483710289001465,\n",
       "  -7.031771659851074,\n",
       "  -7.219485282897949,\n",
       "  -7.623373031616211,\n",
       "  -7.396232604980469,\n",
       "  -7.437164306640625,\n",
       "  -7.14362907409668,\n",
       "  -7.254249095916748,\n",
       "  -7.277666091918945,\n",
       "  -7.77409029006958,\n",
       "  -7.788491725921631,\n",
       "  -7.502607345581055,\n",
       "  -7.327746868133545,\n",
       "  -7.250097274780273,\n",
       "  -7.144693374633789,\n",
       "  -7.124416828155518,\n",
       "  -7.409773826599121,\n",
       "  -6.935035228729248,\n",
       "  -7.06727933883667,\n",
       "  -7.210262298583984,\n",
       "  -7.3230509757995605,\n",
       "  -6.973214626312256,\n",
       "  -7.251904487609863,\n",
       "  -7.715467929840088,\n",
       "  -7.304067134857178,\n",
       "  -7.061948776245117,\n",
       "  -6.964890003204346,\n",
       "  -7.22329044342041,\n",
       "  -7.086755752563477,\n",
       "  -7.068349838256836,\n",
       "  -7.2399516105651855,\n",
       "  -7.398221969604492,\n",
       "  -7.561310768127441,\n",
       "  -7.420804500579834,\n",
       "  -7.5450944900512695,\n",
       "  -7.268587112426758,\n",
       "  -7.2716875076293945,\n",
       "  -7.578103542327881,\n",
       "  -7.498195171356201,\n",
       "  -7.567406177520752,\n",
       "  -7.125180721282959,\n",
       "  -7.299883842468262,\n",
       "  -7.425508499145508,\n",
       "  -7.13129997253418,\n",
       "  -7.329097270965576,\n",
       "  -7.515381813049316,\n",
       "  -7.335543632507324,\n",
       "  -7.12311315536499,\n",
       "  -7.300324440002441,\n",
       "  -7.350407123565674,\n",
       "  -7.211956024169922,\n",
       "  -7.219456672668457,\n",
       "  -7.605271816253662,\n",
       "  -7.22855281829834,\n",
       "  -7.230033874511719,\n",
       "  -7.408969879150391,\n",
       "  -7.251230239868164,\n",
       "  -7.492877006530762,\n",
       "  -7.798092842102051,\n",
       "  -6.9516472816467285,\n",
       "  -6.750802040100098,\n",
       "  -7.063654899597168,\n",
       "  -7.470655918121338,\n",
       "  -7.47188138961792,\n",
       "  -6.959228038787842,\n",
       "  -7.4027628898620605,\n",
       "  -7.255141258239746,\n",
       "  -7.208030700683594,\n",
       "  -7.24788236618042,\n",
       "  -6.864241600036621,\n",
       "  -7.457313537597656,\n",
       "  -7.272041320800781,\n",
       "  -7.399626731872559,\n",
       "  -7.334389686584473,\n",
       "  -7.157599925994873,\n",
       "  -6.948352336883545,\n",
       "  -7.124651908874512,\n",
       "  -7.085682392120361,\n",
       "  -6.938232421875,\n",
       "  -7.367892265319824,\n",
       "  -7.358407974243164,\n",
       "  -7.2831878662109375,\n",
       "  -6.947970390319824,\n",
       "  -7.135612487792969,\n",
       "  -7.405740737915039,\n",
       "  -7.146519660949707,\n",
       "  -7.040504455566406,\n",
       "  -7.339583873748779,\n",
       "  -7.445213317871094,\n",
       "  -7.665505409240723,\n",
       "  -7.545351028442383,\n",
       "  -7.473094463348389,\n",
       "  -7.478617191314697,\n",
       "  -7.519062519073486,\n",
       "  -7.284491062164307,\n",
       "  -7.3107194900512695,\n",
       "  -7.60257625579834,\n",
       "  -7.187033653259277,\n",
       "  -7.334055423736572,\n",
       "  -7.032968521118164,\n",
       "  -7.236209392547607,\n",
       "  -7.325509548187256,\n",
       "  -6.68812370300293,\n",
       "  -7.26008415222168,\n",
       "  ...]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.LogSoftmax(dim=1)\n",
    "softmax(lin2(h_x)).detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRQWuqqEHAOy",
    "outputId": "b415f713-540a-4ea5-c47e-37119170e1a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-6.5896], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([1241]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the index with highest softmax probabilities\n",
    "# See https://pytorch.org/docs/stable/torch.html#torch.max\n",
    "torch.max(softmax(lin2(h_x)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ff9AI3AzHAO1"
   },
   "source": [
    "<a id=\"section-3-1-4-train-cbow\"></a>\n",
    "\n",
    "# Now, we train the CBOW model for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KajporK5HAO1",
    "outputId": "64a80e84-7ccf-430e-b754-453ead42ccb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we split the data into training and testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenized_text_train, tokenized_text_test = train_test_split(tokenized_text, test_size=0.1, random_state=42)\n",
    "len(tokenized_text_train), len(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e-DyvAPHAO3"
   },
   "outputs": [],
   "source": [
    "### Hint: Click here to go back up to see the CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNV7M6HiHAO3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Put the input context indices into the embeddings\n",
    "        # then squeeze it into a single dimension vector with tensor.view((1,-1))\n",
    "        embedded = self.embeddings(inputs).view((1, -1))\n",
    "        # Put the embedding input through linear layer,\n",
    "        # then an activation function to create the hidden layer.\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        # Put the hidden layer through a second linear layer,\n",
    "        out = self.linear2(hid)\n",
    "        # then a last layer activation function to generate\n",
    "        # pobabilities, hint https://pytorch.org/docs/stable/nn.html#torch.nn.functional.log_softmax\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IyJ3a03DHAO6",
    "outputId": "a74a8ea3-91e3-42a7-ef0d-6f49b63b60e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor(7.2880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(13.2742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(17.4191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.1475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(11.2918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.1112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.2774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.2065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.9180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.4996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.5492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.7015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.7412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(13.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:15<02:23, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.6616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.3254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.2484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.4142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4787, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:31<02:07, 15.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.2101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.6321e-05, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.0491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4294, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [00:48<01:52, 16.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.0202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.7668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.7628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4009, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:03<01:35, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.3793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.1701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1444e-05, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.2700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3982, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:20<01:20, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7220e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.6117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4092, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:35<01:03, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.2938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.5367e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(27.5029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.3663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4254, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:52<00:48, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.2557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.2376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9073e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9073e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:06<00:31, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.2090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.6294e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.5367e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2738, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:26<00:16, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.7416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.4919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.1593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.7534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2888e-05, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.9133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(15.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2259, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:43<00:00, 16.39s/it]\n"
     ]
    }
   ],
   "source": [
    "embd_size = 100\n",
    "learning_rate = 0.003\n",
    "hidden_size = 100\n",
    "window_size = 2\n",
    "\n",
    "\n",
    "# Initialize the dataset.\n",
    "w2v_dataset = Word2VecText(tokenized_text_train, window_size=window_size, variant='cbow')\n",
    "vocab_size = len(w2v_dataset.vocab)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "# Hint: the CBOW model object you've created.\n",
    "model = CBOW(vocab_size, embd_size, window_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "model = nn.DataParallel(model) # copy data across multiple GPUs\n",
    "\n",
    "num_epochs = 10\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    epoch_loss = []\n",
    "    epoch_counter = 0\n",
    "    for sent_idx in range(w2v_dataset._len):\n",
    "        for w2v_io in w2v_dataset[sent_idx]:\n",
    "            # Zero gradient.\n",
    "            optimizer.zero_grad()\n",
    "            # Retrieve the inputs and outputs.\n",
    "            x, y = w2v_io['x'], w2v_io['y']\n",
    "            x = tensor(x).to(device)\n",
    "            y = autograd.Variable(tensor(y, dtype=torch.long)).to(device)\n",
    "            # Calculate the log probability of the context embeddings.\n",
    "            logprobs = model(x)\n",
    "            # This unsqueeze thing is really a feature/bug... -_-\n",
    "            loss = criterion(logprobs, y.unsqueeze(0)) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "            \n",
    "            if epoch_counter % 100 == 0:\n",
    "                print(loss)\n",
    "            epoch_counter = epoch_counter + 1\n",
    "            \n",
    "    # Save model after every epoch.\n",
    "    torch.save(model.state_dict(), 'cbow_checkpoint_{}.pt'.format(_e))\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8HrtnnIHAO6",
    "outputId": "cc6cc1b7-bf8a-47c0-ee9e-27df461e114d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qc82I7eiHAO8"
   },
   "source": [
    "<a id=\"section-3-1-4-evaluate-cbow\"></a>\n",
    "\n",
    "# Apply and Evaluate the CBOW Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_dataset.vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRk8qOwUHAO8",
    "outputId": "6a6cd788-b5e1-4dc7-a0e2-bbee3e053bf1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f007e0c54498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw2v_io\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw2v_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Retrieve the inputs and outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_io\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_io\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Skip unknown words.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from lazyme import color_str\n",
    "\n",
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_dataset._iterator(w2v_dataset.vectorize(sent)):\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x = tensor(w2v_io['x']).to(device)\n",
    "        y = tensor(w2v_io['y']).to(device)\n",
    "        if -1 in x: # Skip unknown words.\n",
    "            continue\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Remember how to get the best prediction output? \n",
    "            # Hint: https://pytorch.org/docs/stable/torch.html#torch.max\n",
    "            _, prediction =  torch.max(model(x), 1)\n",
    "        true_positive += int(prediction) == int(y)\n",
    "        visualize_predictions(x, y, prediction, w2v_dataset.vocab, window_size=window_size)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PelknL2MHAO9",
    "outputId": "07bf09ce-6bd3-445d-93b9-8d323e4536ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9573], device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(x), 1).values\n",
    "#model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFxlL7a-HAO-",
    "outputId": "d9b07963-2da0-488b-fb44-8138e2cda4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15319148936170213\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfJ52Vf3HAO_"
   },
   "source": [
    "<a id=\"section-3-1-4-load-model\"></a>\n",
    "\n",
    "# Go back to the 5th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLyxuoUCHAO_",
    "outputId": "8c7afdee-a14e-4252-90c9-27b661c0d1a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CBOW(\n",
       "    (embeddings): Embedding(1303, 100)\n",
       "    (linear1): Linear(in_features=400, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=1303, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = CBOW(vocab_size, embd_size, window_size, hidden_size)\n",
    "model_5 = torch.nn.DataParallel(model_5)\n",
    "model_5.load_state_dict(torch.load('cbow_checkpoint_5.pt'))\n",
    "model_5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvy7BIcaHAPB",
    "outputId": "08f74835-bc89-4a1b-bab7-72a7cd2dadde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mis\u001b[0m \t\t the problem \u001b[91min\u001b[0m essentially this\n",
      "\u001b[92messentially\u001b[0m \t problem is \u001b[91m______\u001b[0m this :\n",
      "\u001b[92mthis\u001b[0m \t\t is essentially \u001b[91m______\u001b[0m : if\n",
      "\u001b[92m:\u001b[0m \t\t essentially this \u001b[91m______\u001b[0m if a\n",
      "\u001b[92mif\u001b[0m \t\t this : \u001b[91m______\u001b[0m a word\n",
      "\u001b[92ma\u001b[0m \t\t : if \u001b[91m______\u001b[0m word (\n",
      "\u001b[92mword\u001b[0m \t\t if a \u001b[91m______\u001b[0m ( or\n",
      "\u001b[92m(\u001b[0m \t\t a word \u001b[91m______\u001b[0m or bigram\n",
      "\u001b[92mor\u001b[0m \t\t word ( \u001b[91m______\u001b[0m bigram ,\n",
      "\u001b[92mbigram\u001b[0m \t\t ( or \u001b[91m______\u001b[0m , or\n",
      "\u001b[92m<unk>\u001b[0m \t\t , or \u001b[91m______\u001b[0m , or\n",
      "\u001b[92m<unk>\u001b[0m \t\t , or \u001b[91m______\u001b[0m etc .\n",
      "\u001b[92mis\u001b[0m \t\t the web \u001b[91m______\u001b[0m a vast\n",
      "\u001b[92ma\u001b[0m \t\t web is \u001b[91mthe\u001b[0m vast re-\n",
      "\u001b[92mvast\u001b[0m \t\t is a \u001b[91m______\u001b[0m re- source\n",
      "\u001b[92mre-\u001b[0m \t\t a vast \u001b[91m______\u001b[0m source for\n",
      "\u001b[92msource\u001b[0m \t\t vast re- \u001b[91m______\u001b[0m for many\n",
      "\u001b[92mthe\u001b[0m \t\t is that \u001b[91m______\u001b[0m association is\n",
      "\u001b[92massociation\u001b[0m \t that the \u001b[91m______\u001b[0m is random\n",
      "\u001b[92mis\u001b[0m \t\t the association \u001b[91m______\u001b[0m random ,\n",
      "\u001b[92mrandom\u001b[0m \t\t association is \u001b[91m______\u001b[0m , arbitrary\n",
      "\u001b[92m,\u001b[0m \t\t is random \u001b[91m______\u001b[0m arbitrary ,\n",
      "\u001b[92marbitrary\u001b[0m \t random , \u001b[91m______\u001b[0m , motivated\n",
      "\u001b[92m,\u001b[0m \t\t , arbitrary \u001b[91m______\u001b[0m motivated or\n",
      "\u001b[92mmotivated\u001b[0m \t arbitrary , \u001b[91m______\u001b[0m or pre-\n",
      "\u001b[92m<unk>\u001b[0m \t\t or pre- \u001b[91m______\u001b[0m ( r\n",
      "\u001b[92m,\u001b[0m \t\t ( r \u001b[91m)\u001b[0m a ,\n",
      "\u001b[92m<unk>\u001b[0m \t\t a , \u001b[91m______\u001b[0m , p\n",
      "\u001b[92mtheir\u001b[0m \t\t however , \u001b[91m______\u001b[0m methods are\n",
      "\u001b[92mexample\u001b[0m \t , for \u001b[91m______\u001b[0m , from\n",
      "\u001b[92m,\u001b[0m \t\t for example \u001b[91m______\u001b[0m from just\n",
      "\u001b[92mfrom\u001b[0m \t\t example , \u001b[91mrandom\u001b[0m just those\n",
      "\u001b[92m<unk>\u001b[0m \t\t just those \u001b[91m______\u001b[0m errors that\n",
      "\u001b[92mthey\u001b[0m \t\t , and \u001b[91m______\u001b[0m do not\n",
      "\u001b[92mdo\u001b[0m \t\t and they \u001b[92mdo\u001b[0m not wish\n",
      "\u001b[92mnot\u001b[0m \t\t they do \u001b[91m______\u001b[0m wish to\n",
      "\u001b[92m<unk>\u001b[0m \t\t wish to \u001b[91m______\u001b[0m any scf\n",
      "\u001b[92mfor\u001b[0m \t\t any scf \u001b[91m______\u001b[0m which there\n",
      "\u001b[92mwhich\u001b[0m \t\t scf for \u001b[91m______\u001b[0m there is\n",
      "\u001b[92mthere\u001b[0m \t\t for which \u001b[91m______\u001b[0m is any\n",
      "\u001b[92mis\u001b[0m \t\t which there \u001b[91mthe\u001b[0m any evidence\n",
      "\u001b[92many\u001b[0m \t\t there is \u001b[91m______\u001b[0m evidence as\n",
      "\u001b[92mevidence\u001b[0m \t is any \u001b[91m______\u001b[0m as a\n",
      "\u001b[92mas\u001b[0m \t\t any evidence \u001b[91mis\u001b[0m a true\n",
      "\u001b[92ma\u001b[0m \t\t evidence as \u001b[91m______\u001b[0m true scf\n",
      "\u001b[92mtrue\u001b[0m \t\t as a \u001b[91m______\u001b[0m scf for\n",
      "\u001b[92mscf\u001b[0m \t\t a true \u001b[91m______\u001b[0m for the\n",
      "\u001b[92mfor\u001b[0m \t\t true scf \u001b[91mis\u001b[0m the verb\n",
      "\u001b[92mthe\u001b[0m \t\t scf for \u001b[91m______\u001b[0m verb .\n",
      "\u001b[92m<unk>\u001b[0m \t\t some way \u001b[91mvery\u001b[0m out to\n",
      "\u001b[92mwas\u001b[0m \t\t tion that \u001b[91m______\u001b[0m indistinguishable from\n",
      "\u001b[92mindistinguishable\u001b[0m \t that was \u001b[91m______\u001b[0m from one\n",
      "\u001b[92mfrom\u001b[0m \t\t was indistinguishable \u001b[91m______\u001b[0m one where\n",
      "\u001b[92mone\u001b[0m \t\t indistinguishable from \u001b[91m______\u001b[0m where the\n",
      "\u001b[92mwhere\u001b[0m \t\t from one \u001b[91m______\u001b[0m the individual\n",
      "\u001b[92mthe\u001b[0m \t\t one where \u001b[91mas\u001b[0m individual words\n",
      "\u001b[92mindividual\u001b[0m \t where the \u001b[91m______\u001b[0m words (\n",
      "\u001b[92mwords\u001b[0m \t\t the individual \u001b[91m______\u001b[0m ( as\n",
      "\u001b[92m(\u001b[0m \t\t individual words \u001b[91mor\u001b[0m as opposed\n",
      "\u001b[92mas\u001b[0m \t\t words ( \u001b[91m______\u001b[0m opposed to\n",
      "\u001b[92mopposed\u001b[0m \t ( as \u001b[91m______\u001b[0m to the\n",
      "\u001b[92mto\u001b[0m \t\t as opposed \u001b[91m______\u001b[0m the texts\n",
      "\u001b[92mthe\u001b[0m \t\t opposed to \u001b[91m______\u001b[0m texts )\n",
      "\u001b[92mtexts\u001b[0m \t\t to the \u001b[91m______\u001b[0m ) had\n",
      "\u001b[92m)\u001b[0m \t\t the texts \u001b[91m______\u001b[0m had been\n",
      "\u001b[92mhad\u001b[0m \t\t texts ) \u001b[91mare\u001b[0m been randomly\n",
      "\u001b[92mbeen\u001b[0m \t\t ) had \u001b[91m______\u001b[0m randomly selected\n",
      "\u001b[92mrandomly\u001b[0m \t had been \u001b[91m______\u001b[0m selected ,\n",
      "\u001b[92mselected\u001b[0m \t been randomly \u001b[91m______\u001b[0m , this\n",
      "\u001b[92m<unk>\u001b[0m \t\t , this \u001b[91m______\u001b[0m out not\n",
      "\u001b[92mto\u001b[0m \t\t out not \u001b[91m______\u001b[0m be the\n",
      "\u001b[92mbe\u001b[0m \t\t not to \u001b[91m______\u001b[0m the case\n",
      "\u001b[92mthe\u001b[0m \t\t to be \u001b[91m______\u001b[0m case .\n",
      "\u001b[92m<unk>\u001b[0m \t\t ted and \u001b[91m______\u001b[0m carroll 1997\n",
      "\u001b[92m<unk>\u001b[0m \t\t 1997 automatic \u001b[91mthe\u001b[0m of subcategorization\n",
      "\u001b[92mfrom\u001b[0m \t\t of subcategorization \u001b[91m______\u001b[0m corpora .\n",
      "\u001b[92mwere\u001b[0m \t\t the ho \u001b[91m______\u001b[0m tested using\n",
      "\u001b[92mtested\u001b[0m \t\t ho were \u001b[91m______\u001b[0m using the\n",
      "\u001b[92m<unk>\u001b[0m \t\t using the \u001b[91m______\u001b[0m : is\n",
      "\u001b[92m<unk>\u001b[0m \t\t ⫺ e \u001b[91m______\u001b[0m ⫺ 0.5\n",
      "\u001b[92m<unk>\u001b[0m \t\t ) 2 \u001b[91mthe\u001b[0m greater than\n",
      "\u001b[92mthe\u001b[0m \t\t greater than \u001b[92mthe\u001b[0m critical value\n",
      "\u001b[92mcritical\u001b[0m \t than the \u001b[91m______\u001b[0m value ?\n",
      "\u001b[92m<unk>\u001b[0m \t\t schütze 1999 \u001b[91m______\u001b[0m of statistical\n",
      "\u001b[92mnatural\u001b[0m \t of statistical \u001b[91m______\u001b[0m language processing\n",
      "\u001b[92mlanguage\u001b[0m \t statistical natural \u001b[91m______\u001b[0m processing .\n",
      "\u001b[92mlikelihood\u001b[0m \t if the \u001b[91m______\u001b[0m is low\n",
      "\u001b[92mis\u001b[0m \t\t the likelihood \u001b[91m______\u001b[0m low ,\n",
      "\u001b[92mlow\u001b[0m \t\t likelihood is \u001b[91m______\u001b[0m , we\n",
      "\u001b[92m,\u001b[0m \t\t is low \u001b[91m______\u001b[0m we reject\n",
      "\u001b[92mwe\u001b[0m \t\t low , \u001b[91m______\u001b[0m reject h0\n",
      "\u001b[92mreject\u001b[0m \t\t , we \u001b[91m______\u001b[0m h0 .\n",
      "\u001b[92mthe\u001b[0m \t\t however where \u001b[92mthe\u001b[0m sample size\n",
      "\u001b[92m<unk>\u001b[0m \t\t sample size \u001b[91m______\u001b[0m by an\n",
      "\u001b[92m<unk>\u001b[0m \t\t order of \u001b[91m______\u001b[0m , or\n",
      "\u001b[92mwhere\u001b[0m \t\t , or \u001b[91m______\u001b[0m it is\n",
      "\u001b[92mit\u001b[0m \t\t or where \u001b[91m______\u001b[0m is enormous\n",
      "\u001b[92mis\u001b[0m \t\t where it \u001b[91m______\u001b[0m enormous ,\n",
      "\u001b[92menormous\u001b[0m \t it is \u001b[91m______\u001b[0m , it\n",
      "\u001b[92m,\u001b[0m \t\t is enormous \u001b[91m______\u001b[0m it is\n",
      "\u001b[92mit\u001b[0m \t\t enormous , \u001b[91m______\u001b[0m is wrong\n",
      "\u001b[92mis\u001b[0m \t\t , it \u001b[91m______\u001b[0m wrong to\n",
      "\u001b[92mwrong\u001b[0m \t\t it is \u001b[91m______\u001b[0m to identify\n",
      "\u001b[92mto\u001b[0m \t\t is wrong \u001b[91m______\u001b[0m identify the\n",
      "\u001b[92m<unk>\u001b[0m \t\t identify the \u001b[91m______\u001b[0m distinction with\n",
      "\u001b[92m<unk>\u001b[0m \t\t with the \u001b[91m______\u001b[0m one .\n",
      "\u001b[92mthe\u001b[0m \t\t proceedings of \u001b[92mthe\u001b[0m conference of\n",
      "\u001b[92mconference\u001b[0m \t of the \u001b[91m______\u001b[0m of the\n",
      "\u001b[92mis\u001b[0m \t\t false assumptions \u001b[91m______\u001b[0m often an\n",
      "\u001b[92m<unk>\u001b[0m \t\t often an \u001b[91mthe\u001b[0m way to\n",
      "\u001b[92m<unk>\u001b[0m \t\t way to \u001b[91m______\u001b[0m ; the\n",
      "\u001b[92m<unk>\u001b[0m \t\t the problem \u001b[91m______\u001b[0m where the\n",
      "\u001b[92m<unk>\u001b[0m \t\t of the \u001b[91m______\u001b[0m is overlooked\n",
      "\u001b[92mlinguistics\u001b[0m \t compu- tational \u001b[92mlinguistics\u001b[0m 16 (\n",
      "\u001b[92m16\u001b[0m \t\t tational linguistics \u001b[91m______\u001b[0m ( 1\n",
      "\u001b[92m(\u001b[0m \t\t linguistics 16 \u001b[92m(\u001b[0m 1 )\n",
      "\u001b[92m1\u001b[0m \t\t 16 ( \u001b[91m______\u001b[0m ) ,\n",
      "\u001b[92mis\u001b[0m \t\t conclusion language \u001b[91m______\u001b[0m non-random and\n",
      "\u001b[92mnon-random\u001b[0m \t language is \u001b[91m______\u001b[0m and hence\n",
      "\u001b[92mand\u001b[0m \t\t is non-random \u001b[91m______\u001b[0m hence ,\n",
      "\u001b[92mhence\u001b[0m \t\t non-random and \u001b[91m______\u001b[0m , when\n",
      "\u001b[92m,\u001b[0m \t\t and hence \u001b[91m______\u001b[0m when we\n",
      "\u001b[92mwhen\u001b[0m \t\t hence , \u001b[91m______\u001b[0m we look\n",
      "\u001b[92mwe\u001b[0m \t\t , when \u001b[91m______\u001b[0m look at\n",
      "\u001b[92mlook\u001b[0m \t\t when we \u001b[91m______\u001b[0m at linguistic\n",
      "\u001b[92m,\u001b[0m \t\t in corpora \u001b[91m______\u001b[0m the null\n",
      "\u001b[92mthe\u001b[0m \t\t corpora , \u001b[92mthe\u001b[0m null hypothesis\n",
      "\u001b[92mnull\u001b[0m \t\t , the \u001b[91m______\u001b[0m hypothesis will\n",
      "\u001b[92mhypothesis\u001b[0m \t the null \u001b[91m______\u001b[0m will never\n",
      "\u001b[92mwill\u001b[0m \t\t null hypothesis \u001b[91m______\u001b[0m never be\n",
      "\u001b[92mnever\u001b[0m \t\t hypothesis will \u001b[91m______\u001b[0m be true\n",
      "\u001b[92mbe\u001b[0m \t\t will never \u001b[92mbe\u001b[0m true .\n",
      "\u001b[92mnot\u001b[0m \t\t we do \u001b[91m______\u001b[0m always have\n",
      "\u001b[92malways\u001b[0m \t\t do not \u001b[91mdo\u001b[0m have enough\n",
      "\u001b[92mhave\u001b[0m \t\t not always \u001b[91mhas\u001b[0m enough data\n",
      "\u001b[92menough\u001b[0m \t\t always have \u001b[91m______\u001b[0m data to\n",
      "\u001b[92mdata\u001b[0m \t\t have enough \u001b[92mdata\u001b[0m to reject\n",
      "\u001b[92mto\u001b[0m \t\t enough data \u001b[91m______\u001b[0m reject the\n",
      "\u001b[92mreject\u001b[0m \t\t data to \u001b[91m______\u001b[0m the null\n",
      "\u001b[92mthe\u001b[0m \t\t to reject \u001b[92mthe\u001b[0m null hypothesis\n",
      "\u001b[92mnull\u001b[0m \t\t reject the \u001b[91m______\u001b[0m hypothesis ,\n",
      "\u001b[92mhypothesis\u001b[0m \t the null \u001b[91m______\u001b[0m , but\n",
      "\u001b[92m,\u001b[0m \t\t null hypothesis \u001b[91m______\u001b[0m but that\n",
      "\u001b[92mbut\u001b[0m \t\t hypothesis , \u001b[91m______\u001b[0m that is\n",
      "\u001b[92mthat\u001b[0m \t\t , but \u001b[91m______\u001b[0m is a\n",
      "\u001b[92m<unk>\u001b[0m \t\t is a \u001b[91m______\u001b[0m issue :\n",
      "\u001b[92mwherever\u001b[0m \t issue : \u001b[91mwhere\u001b[0m there is\n",
      "\u001b[92mthere\u001b[0m \t\t : wherever \u001b[91mdo\u001b[0m is enough\n",
      "\u001b[92mis\u001b[0m \t\t wherever there \u001b[92mis\u001b[0m enough data\n",
      "\u001b[92menough\u001b[0m \t\t there is \u001b[91m______\u001b[0m data ,\n",
      "\u001b[92mdata\u001b[0m \t\t is enough \u001b[92mdata\u001b[0m , it\n",
      "\u001b[92m,\u001b[0m \t\t enough data \u001b[91m______\u001b[0m it is\n",
      "\u001b[92mit\u001b[0m \t\t data , \u001b[91m______\u001b[0m is rejected\n",
      "\u001b[92mis\u001b[0m \t\t , it \u001b[91m______\u001b[0m rejected .\n",
      "\u001b[92min\u001b[0m \t\t since words \u001b[91m______\u001b[0m a text\n",
      "\u001b[92ma\u001b[0m \t\t words in \u001b[91m______\u001b[0m text are\n",
      "\u001b[92mtext\u001b[0m \t\t in a \u001b[91m______\u001b[0m are not\n",
      "\u001b[92mare\u001b[0m \t\t a text \u001b[91mdoes\u001b[0m not random\n",
      "\u001b[92mnot\u001b[0m \t\t text are \u001b[91m______\u001b[0m random ,\n",
      "\u001b[92mrandom\u001b[0m \t\t are not \u001b[91m______\u001b[0m , we\n",
      "\u001b[92m,\u001b[0m \t\t not random \u001b[91m______\u001b[0m we know\n",
      "\u001b[92mwe\u001b[0m \t\t random , \u001b[91m______\u001b[0m know that\n",
      "\u001b[92mknow\u001b[0m \t\t , we \u001b[91m______\u001b[0m that our\n",
      "\u001b[92mthat\u001b[0m \t\t we know \u001b[91m______\u001b[0m our corpora\n",
      "\u001b[92mour\u001b[0m \t\t know that \u001b[91m______\u001b[0m corpora are\n",
      "\u001b[92mcorpora\u001b[0m \t that our \u001b[91m______\u001b[0m are not\n",
      "\u001b[92mare\u001b[0m \t\t our corpora \u001b[91mdo\u001b[0m not randomly\n",
      "\u001b[92mnot\u001b[0m \t\t corpora are \u001b[91mthe\u001b[0m randomly generated\n",
      "\u001b[92mrandomly\u001b[0m \t are not \u001b[91m______\u001b[0m generated ,\n",
      "\u001b[92mgenerated\u001b[0m \t not randomly \u001b[91m______\u001b[0m , and\n",
      "\u001b[92m,\u001b[0m \t\t randomly generated \u001b[91m______\u001b[0m and the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mand\u001b[0m \t\t generated , \u001b[91m______\u001b[0m the hypothesis\n",
      "\u001b[92mthe\u001b[0m \t\t , and \u001b[91m______\u001b[0m hypothesis test\n",
      "\u001b[92mhypothesis\u001b[0m \t and the \u001b[91m______\u001b[0m test con-\n",
      "\u001b[92m<unk>\u001b[0m \t\t test con- \u001b[91mis\u001b[0m the fact\n",
      "\u001b[92m<unk>\u001b[0m \t\t cases are \u001b[91m______\u001b[0m in section\n",
      "\u001b[92m<unk>\u001b[0m \t\t of linguistic \u001b[91m______\u001b[0m concern the\n",
      "\u001b[92m<unk>\u001b[0m \t\t the dis- \u001b[91m______\u001b[0m between a\n",
      "\u001b[92m<unk>\u001b[0m \t\t a and \u001b[91m______\u001b[0m a linguistic\n",
      "\u001b[92m<unk>\u001b[0m \t\t a linguistic \u001b[91m______\u001b[0m of a\n",
      "\u001b[92m<unk>\u001b[0m \t\t reason to \u001b[91m______\u001b[0m the relation\n",
      "\u001b[92mbetween\u001b[0m \t the relation \u001b[91m______\u001b[0m , for\n",
      "\u001b[92m,\u001b[0m \t\t relation between \u001b[91m______\u001b[0m for example\n",
      "\u001b[92mfor\u001b[0m \t\t between , \u001b[91m______\u001b[0m example ,\n",
      "\u001b[92mexample\u001b[0m \t , for \u001b[91m______\u001b[0m , a\n",
      "\u001b[92m,\u001b[0m \t\t for example \u001b[91mthe\u001b[0m a verb\n",
      "\u001b[92ma\u001b[0m \t\t example , \u001b[91mever\u001b[0m verb ’\n",
      "\u001b[92mverb\u001b[0m \t\t , a \u001b[91m______\u001b[0m ’ s\n",
      "\u001b[92m’\u001b[0m \t\t a verb \u001b[92m’\u001b[0m s syntax\n",
      "\u001b[92ms\u001b[0m \t\t verb ’ \u001b[91mis\u001b[0m syntax and\n",
      "\u001b[92msyntax\u001b[0m \t\t ’ s \u001b[91m______\u001b[0m and its\n",
      "\u001b[92m<unk>\u001b[0m \t\t and its \u001b[91m______\u001b[0m , as\n",
      "\u001b[92mmotivated\u001b[0m \t , as \u001b[91m______\u001b[0m rather than\n",
      "\u001b[92mrather\u001b[0m \t\t as motivated \u001b[91m______\u001b[0m than arbitrary\n",
      "\u001b[92mthan\u001b[0m \t\t motivated rather \u001b[91m______\u001b[0m arbitrary .\n",
      "\u001b[92mvalue\u001b[0m \t\t the average \u001b[91m______\u001b[0m of the\n",
      "\u001b[92mof\u001b[0m \t\t average value \u001b[92mof\u001b[0m the error\n",
      "\u001b[92mthe\u001b[0m \t\t value of \u001b[92mthe\u001b[0m error term\n",
      "\u001b[92merror\u001b[0m \t\t of the \u001b[91m______\u001b[0m term ,\n",
      "\u001b[92mterm\u001b[0m \t\t the error \u001b[91m______\u001b[0m , language\n",
      "\u001b[92m,\u001b[0m \t\t error term \u001b[91m______\u001b[0m language is\n",
      "\u001b[92mlanguage\u001b[0m \t term , \u001b[91m______\u001b[0m is never\n",
      "\u001b[92mis\u001b[0m \t\t , language \u001b[91m______\u001b[0m never ,\n",
      "\u001b[92mnever\u001b[0m \t\t language is \u001b[91m______\u001b[0m , ever\n",
      "\u001b[92m,\u001b[0m \t\t is never \u001b[91m______\u001b[0m ever ,\n",
      "\u001b[92mever\u001b[0m \t\t never , \u001b[92mever\u001b[0m , ever\n",
      "\u001b[92m,\u001b[0m \t\t , ever \u001b[91m______\u001b[0m ever ,\n",
      "\u001b[92mever\u001b[0m \t\t ever , \u001b[92mever\u001b[0m , random\n",
      "\u001b[92m<unk>\u001b[0m \t\t ) 2 \u001b[91m______\u001b[0m is then\n",
      "\u001b[92m<unk>\u001b[0m \t\t is then \u001b[91m______\u001b[0m the hypothesis\n",
      "\u001b[92m<unk>\u001b[0m \t\t can , \u001b[91m______\u001b[0m , be\n",
      "\u001b[92m<unk>\u001b[0m \t\t , be \u001b[91m______\u001b[0m as :\n",
      "\u001b[92mare\u001b[0m \t\t as : \u001b[91m______\u001b[0m the error\n",
      "\u001b[92mthe\u001b[0m \t\t : are \u001b[91m______\u001b[0m error terms\n",
      "\u001b[92merror\u001b[0m \t\t are the \u001b[91m______\u001b[0m terms systematically\n",
      "\u001b[92mterms\u001b[0m \t\t the error \u001b[91m______\u001b[0m systematically greater\n",
      "\u001b[92msystematically\u001b[0m \t error terms \u001b[91m______\u001b[0m greater than\n",
      "\u001b[92mgreater\u001b[0m \t terms systematically \u001b[91mor\u001b[0m than 0.5\n",
      "\u001b[92mthan\u001b[0m \t\t systematically greater \u001b[91mabout\u001b[0m 0.5 ?\n",
      "\u001b[92m1\u001b[0m \t\t with just \u001b[91m______\u001b[0m % of\n",
      "\u001b[92m%\u001b[0m \t\t just 1 \u001b[91m______\u001b[0m of them\n",
      "\u001b[92mof\u001b[0m \t\t 1 % \u001b[91m______\u001b[0m them ,\n",
      "\u001b[92mthem\u001b[0m \t\t % of \u001b[91m______\u001b[0m , devastate\n",
      "\u001b[92m<unk>\u001b[0m \t\t , devastate \u001b[91m______\u001b[0m one of\n",
      "\u001b[92mthe\u001b[0m \t\t one of \u001b[91m______\u001b[0m verbs for\n",
      "\u001b[92mverbs\u001b[0m \t\t of the \u001b[91m______\u001b[0m for which\n",
      "\u001b[92mfor\u001b[0m \t\t the verbs \u001b[91m______\u001b[0m which we\n",
      "\u001b[92mwhich\u001b[0m \t\t verbs for \u001b[91m______\u001b[0m we have\n",
      "\u001b[92m<unk>\u001b[0m \t\t we have \u001b[91m______\u001b[0m of data\n",
      "\u001b[92m<unk>\u001b[0m \t\t , and \u001b[91m______\u001b[0m thresholding methods\n",
      "\u001b[92mwill\u001b[0m \t\t thresholding methods \u001b[91min\u001b[0m distinguish associated\n",
      "\u001b[92mdistinguish\u001b[0m \t methods will \u001b[91m______\u001b[0m associated scfs\n",
      "\u001b[92massociated\u001b[0m \t will distinguish \u001b[91m______\u001b[0m scfs from\n",
      "\u001b[92mscfs\u001b[0m \t\t distinguish associated \u001b[91m______\u001b[0m from noise\n",
      "\u001b[92mfrom\u001b[0m \t\t associated scfs \u001b[91m______\u001b[0m noise .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_dataset._iterator(w2v_dataset.vectorize(sent)):\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x = tensor(w2v_io['x']).to(device)\n",
    "        y = tensor(w2v_io['y']).to(device)\n",
    "        \n",
    "        if -1 in x: # Skip unknown words.\n",
    "            continue\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            _, prediction =  torch.max(model_5(x), 1)\n",
    "        true_positive += int(prediction) == int(y)\n",
    "#         print(prediction)\n",
    "        visualize_predictions(x, y, prediction, w2v_dataset.vocab, window_size=window_size)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YUJqPZ7HAPB",
    "outputId": "5a656132-a709-446a-fc9e-d80de50149b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13617021276595745\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahfez391HAPC",
    "outputId": "ca734d53-ad82-4bd9-ab89-7acad3b3865a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape[1] == len(w2v_dataset.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byBffEPbHAPD"
   },
   "source": [
    "# [optional] How to Handle Unknown Words? \n",
    "\n",
    "This is not the best way to handle unknown words, but we can simply assign an index for unknown words.\n",
    "\n",
    "**Hint:** Ensure that you have `gensim` version >= 3.7.0 first. Otherwise this part of the code won't work. \n",
    "\n",
    "Try in your Python environment installation:\n",
    "\n",
    "```\n",
    "python -m pip install -U pip\n",
    "python -m pip install -U gensim>=3.7.0\n",
    "```\n",
    "\n",
    "Or within the jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXrkv7c7HAPD",
    "outputId": "990513e6-3892-4141-eef3-aeed109069ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in d:\\apps\\anaconda3\\envs\\torch-nlp\\lib\\site-packages (19.3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U pip\n",
    "!python -m pip install -U gensim>=3.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pvz2r2H7HAPF"
   },
   "source": [
    "To check version of `gensim` after installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lr7AsumYHAPH",
    "outputId": "0536f940-f7a0-4277-eb45-d78f6146d15d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a', 1: 'bar', 2: 'foo', 3: 'is', 4: 'sentence', 5: 'this'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Dictionary(['this is a foo bar sentence'.split()])\n",
    "dict(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLLNGLkmHAPH",
    "outputId": "02b4fc5f-7a07-4a85-a1c5-11b3dd425f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 'a',\n",
       " 7: 'bar',\n",
       " 2: 'foo',\n",
       " 3: 'is',\n",
       " 4: 'sentence',\n",
       " 5: 'this',\n",
       " 0: '<pad>',\n",
       " 1: '<unk>'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.patch_with_special_tokens\n",
    "vocab = Dictionary(['this is a foo bar sentence'.split()])\n",
    "\n",
    "try:\n",
    "    special_tokens = {'<pad>': 0, '<unk>': 1}\n",
    "    vocab.patch_with_special_tokens(special_tokens)\n",
    "except: # If gensim is not 3.7.0\n",
    "    pass\n",
    "    \n",
    "dict(vocab.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mSN-D1_HAPI"
   },
   "source": [
    "# [optional] Lets Rewrite the `Word2VecText` Object\n",
    "\n",
    "Now with the (i) unknown word patch in the vocabulary as well as (ii) `skipgram_iterator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kiHLsrp6HAPI"
   },
   "outputs": [],
   "source": [
    "class Word2VecText(Dataset):\n",
    "    def __init__(self, tokenized_texts, window_size, variant):\n",
    "        \"\"\"\n",
    "        :param tokenized_texts: Tokenized text.\n",
    "        :type tokenized_texts: list(list(str))\n",
    "        \"\"\"\n",
    "        self.sents = tokenized_texts\n",
    "        self._len = len(self.sents)\n",
    "        \n",
    "        # Add the unknown word patch here.\n",
    "        self.vocab = Dictionary(self.sents)\n",
    "        try:\n",
    "            special_tokens = {'<pad>': 0, '<unk>': 1}\n",
    "            self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.variant = variant\n",
    "        if variant.lower() == 'cbow':\n",
    "            self._iterator = partial(self.cbow_iterator, window_size=self.window_size)\n",
    "        elif variant.lower() == 'skipgram':\n",
    "            self._iterator = partial(self.skipgram_iterator, window_size=self.window_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        The primary entry point for PyTorch datasets.\n",
    "        This is were you access the specific data row you want.\n",
    "        \n",
    "        :param index: Index to the data point.\n",
    "        :type index: int\n",
    "        \"\"\"\n",
    "        vectorized_sent = self.vectorize(self.sents[index])\n",
    "        \n",
    "        return list(self._iterator(vectorized_sent))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        return self.vocab.doc2idx(tokens, unknown_word_index=1)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]\n",
    "    \n",
    "    def cbow_iterator(self, tokens, window_size):\n",
    "        n = window_size * 2 + 1\n",
    "        for window in per_window(tokens, n):\n",
    "            target = window.pop(window_size)\n",
    "            yield {'x': window, 'y': target}   # X = window ; Y = target. \n",
    "            \n",
    "    def skipgram_iterator(self, tokens, window_size):\n",
    "        n = window_size * 2 + 1 \n",
    "        for i, window in enumerate(per_window(tokens, n)):\n",
    "            focus = window.pop(window_size)\n",
    "            # Generate positive samples.\n",
    "            for context_word in window:\n",
    "                yield {'x': (focus, context_word), 'y':1}\n",
    "            # Generate negative samples.\n",
    "            for _ in range(n-1):\n",
    "                leftovers = tokens[:i] + tokens[i+n:]\n",
    "                if leftovers:\n",
    "                    yield {'x': (focus, random.choice(leftovers)), 'y':0}\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZYpe5oyHAPK"
   },
   "source": [
    "<a id=\"section-3-1-5\"></a>\n",
    "\n",
    "# Lets try the skipgram task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDLnpSjWHAPK"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "    \n",
    "    def forward(self, x_focus, x_context):\n",
    "        # vocab_size: V\n",
    "        # embed_size: N\n",
    "        # hidden_size: H\n",
    "        \n",
    "        # shape: (, 1) ~~> (1, V) ==> via x weights:(V, N) ==>  (1, N)\n",
    "        embed_focus = self.embeddings(x_focus).view((1, -1))\n",
    "        \n",
    "        # shape: (, 1) ~~> (1, V) ==> via x weights:(V, N) ==>  (1, N)\n",
    "        embed_context = self.embeddings(x_context).view((1, -1))\n",
    "        \n",
    "        # See https://pytorch.org/docs/stable/torch.html#torch.t\n",
    "        # shape: (1, N), (1, N) ==> via (1,N) x T(1,N) ==> (, 1)\n",
    "        dotprod_score = torch.mm(embed_focus, torch.t(embed_context))\n",
    "        log_probs = F.logsigmoid(dotprod_score)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSiH5MPkHAPK"
   },
   "source": [
    "<a id=\"section-3-1-5-foward\"></a>\n",
    "\n",
    "# Take a closer look at what's in the `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xyw44fdTHAPL"
   },
   "outputs": [],
   "source": [
    "xx1 = torch.rand(1,20)\n",
    "xx2 = torch.rand(1,20)\n",
    "\n",
    "xx1_numpy = xx1.detach().numpy()\n",
    "xx2_numpy = xx2.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TaDPAuwHAPN",
    "outputId": "31359962-d996-45dc-c33b-53ad2d2fc7f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "(20, 1)\n",
      "[[6.1949725]]\n"
     ]
    }
   ],
   "source": [
    "print(xx1_numpy.shape)\n",
    "print(xx2_numpy.T.shape)\n",
    "print(np.dot(xx1_numpy, xx2_numpy.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlm-KSkfHAPQ",
    "outputId": "e54c0fc5-2b98-42be-d8f6-a750c6616ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([20, 1])\n",
      "tensor([[6.1950]])\n",
      "torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "print(xx1.shape)\n",
    "print(torch.t(xx2).shape) \n",
    "\n",
    "print(torch.mm(xx1, torch.t(xx2))) # \n",
    "print(torch.mm(torch.t(xx1), xx2).shape) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7I5p6iiHAPQ"
   },
   "source": [
    "<a id=\"section-3-1-5-train\"></a>\n",
    "\n",
    "# Train a Skipgram model (for real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARKBllDSHAPR",
    "outputId": "837743f3-e00c-4e10-cdc8-ea73ae3fa794"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]D:\\apps\\Anaconda3\\envs\\torch-nlp\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(316.7239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                      | 1/6 [01:16<06:22, 76.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 2/6 [02:32<05:05, 76.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 3/6 [03:48<03:48, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [05:04<02:32, 76.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [06:21<01:16, 76.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [07:35<00:00, 75.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embd_size = 100\n",
    "learning_rate = 0.03\n",
    "hidden_size = 300\n",
    "window_size = 3\n",
    "\n",
    "# Initialize the dataset.\n",
    "w2v_skipgram_dataset = Word2VecText(tokenized_text_train, window_size=3, variant='skipgram')\n",
    "vocab_size = len(w2v_skipgram_dataset.vocab)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# Use the Skipgram object\n",
    "model = SkipGram(vocab_size, embd_size).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "num_epochs = 6\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    epoch_loss = []\n",
    "    epoch_count = 0\n",
    "    for sent_idx in range(w2v_skipgram_dataset._len):\n",
    "        for w2v_io in w2v_skipgram_dataset[sent_idx]:\n",
    "            # Retrieve the inputs and outputs.\n",
    "            x_focus, x_context = w2v_io['x']\n",
    "            x_focus, x_context = tensor(x_focus).to(device).view((1,1)), tensor(x_context).to(device).view((1,1))\n",
    "            y = autograd.Variable(tensor(w2v_io['y'], dtype=torch.float)).to(device)\n",
    "            # Zero gradient.\n",
    "            model.zero_grad()\n",
    "            # Calculate the log probability of the context embeddings.\n",
    "            logprobs = model(x_focus, x_context)\n",
    "            # This unsqueeze thing is really a feature/bug... -_-\n",
    "            loss = criterion(logprobs, y.unsqueeze(0)) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "            \n",
    "            if epoch_count % 100 == 0:\n",
    "                print(loss)\n",
    "            epoch_count += 1\n",
    "            \n",
    "    torch.save(model.state_dict(), 'skipgram_checkpoint_{}.pt'.format(_e))\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5076"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISCj45lKHAPT"
   },
   "source": [
    "<a id=\"section-3-1-5-evaluate\"></a>\n",
    "\n",
    "# Evaluate the model on the skipgram task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "590qbKawHAPU"
   },
   "outputs": [],
   "source": [
    "\n",
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_skipgram_dataset._iterator(w2v_skipgram_dataset.vectorize(sent)):\n",
    "        model.zero_grad()\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x1, x2 = w2v_io['x']\n",
    "        x1, x2 = tensor(x1).view((1,1)).to(device), tensor(x2).view((1,1)).to(device)\n",
    "        y = w2v_io['y']\n",
    "        _, prediction =  torch.max(model(x1, x2), 1)    \n",
    "        true_positive += int(prediction) == int(y)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyFGwLo0HAPW",
    "outputId": "34adc1fd-1f7b-4884-ba3c-b749599885f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9S1fV59wHAPY"
   },
   "source": [
    "## Download the Collobert and Weston SENNA Embeddings\n",
    "\n",
    "\n",
    "If you're on a Mac or Linux, you can use the `!` bang commands in the next cell to get the data.\n",
    "\n",
    "```\n",
    "!pip install kaggle\n",
    "!mkdir -p .kaggle\n",
    "!echo '{\"username\":\"natgillin\",\"key\":\"54ae95ab760b52c3307ed4645c6c9b5d\"}' > .kaggle/kaggle.json\n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "!kaggle datasets download -d alvations/vegetables-senna-embeddings --force -p ./\n",
    "```\n",
    "\n",
    "If you're on windows go to https://www.kaggle.com/alvations/vegetables-senna-embeddings and download the data files. \n",
    "\n",
    "What's most important are the \n",
    " - `.txt` file that contains the vocabulary list\n",
    " - `.npy` file that contains the binarized numpy array\n",
    " \n",
    "The rows of the numpy array corresponds to the vocabulary in the order from the `.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGoQhZaUHAPZ"
   },
   "source": [
    "<a id=\"section-3-1-6-vocab\"></a>\n",
    "\n",
    "\n",
    "## 3.1.6. Loading Pre-trained Embeddings\n",
    "\n",
    "Lets overwrite the `Word2VecText` object with the pretrained embeddings. \n",
    "\n",
    "Most important thing is the overwrite the `Dictionary` from `gensim` with the vocabulary of the pre-trained embeddings, as such:\n",
    "\n",
    "```python\n",
    "        # Loads the pretrained keys. \n",
    "        with open('senna.wiki-reuters.lm2.50d.txt') as fin:\n",
    "            pretrained_keys = {line.strip():i for i, line in enumerate(fin)}\n",
    "        self.vocab = Dictionary({})\n",
    "        self.vocab.token2id = pretrained_keys\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgibLmBxHAPZ"
   },
   "outputs": [],
   "source": [
    "pretrained_dir = \"D:/projects/tsundoku-master/completed/\"\n",
    "\n",
    "class Word2VecText(Dataset):\n",
    "    def __init__(self, tokenized_texts, window_size, variant):\n",
    "        \"\"\"\n",
    "        :param tokenized_texts: Tokenized text.\n",
    "        :type tokenized_texts: list(list(str))\n",
    "        \"\"\"\n",
    "        self.sents = tokenized_texts\n",
    "        self._len = len(self.sents)\n",
    "        \n",
    "        # Loads the pretrained keys. \n",
    "        with open(pretrained_dir + 'senna.wiki-reuters.lm2.50d.txt') as fin:\n",
    "            pretrained_keys = {line.strip():i for i, line in enumerate(fin)}\n",
    "        self.vocab = Dictionary({})\n",
    "        self.vocab.token2id = pretrained_keys\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.variant = variant\n",
    "        if variant.lower() == 'cbow':\n",
    "            self._iterator = partial(self.cbow_iterator, window_size=self.window_size)\n",
    "        elif variant.lower() == 'skipgram':\n",
    "            self._iterator = partial(self.skipgram_iterator, window_size=self.window_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        The primary entry point for PyTorch datasets.\n",
    "        This is were you access the specific data row you want.\n",
    "        \n",
    "        :param index: Index to the data point.\n",
    "        :type index: int\n",
    "        \"\"\"\n",
    "        vectorized_sent = self.vectorize(self.sents[index])\n",
    "        \n",
    "        return list(self._iterator(vectorized_sent))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        return self.vocab.doc2idx(tokens, unknown_word_index=-1)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]\n",
    "    \n",
    "    def cbow_iterator(self, tokens, window_size):\n",
    "        n = window_size * 2 + 1\n",
    "        for window in per_window(tokens, n):\n",
    "            target = window.pop(window_size)\n",
    "            yield {'x': window, 'y': target}   # X = window ; Y = target. \n",
    "            \n",
    "    def skipgram_iterator(self, tokens, window_size):\n",
    "        n = window_size * 2 + 1 \n",
    "        for i, window in enumerate(per_window(tokens, n)):\n",
    "            focus = window.pop(window_size)\n",
    "            # Generate positive samples.\n",
    "            for context_word in window:\n",
    "                yield {'x': (focus, context_word), 'y':1}\n",
    "            # Generate negative samples.\n",
    "            for _ in range(n-1):\n",
    "                leftovers = tokens[:i] + tokens[i+n:]\n",
    "                if leftovers:\n",
    "                    yield {'x': (focus, random.choice(leftovers)), 'y':0}\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXnuGFTlHAPZ"
   },
   "source": [
    "<a id=\"section-3-1-6-pretrained\"></a>\n",
    "\n",
    "## Override the embeddings layer with the pre-trained weights.\n",
    "\n",
    "In PyTorch, the weights of the `nn.Embedding` object can be easily overwritten with `from_pretrained` function, see https://pytorch.org/docs/stable/nn.html#embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpnd3WCjHAPc"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, pretrained_npy):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_npy)\n",
    "    \n",
    "    def forward(self, focus, context):\n",
    "        # Put the index of the focus word into the embedding layer.\n",
    "        embed_focus = self.embeddings(focus).view((1, -1))\n",
    "        # Put the index of the context word into the embedding layer.\n",
    "        embed_context = self.embeddings(context).view((1, -1))\n",
    "        # See https://pytorch.org/docs/stable/torch.html#torch.t\n",
    "        # Do a matrix multiplication between the focus and context embedding\n",
    "        score = torch.mm(embed_focus, torch.t(embed_context))\n",
    "        # Then put it through a log sigmoid activation function\n",
    "        # so that the output is between (log(0), log(1))\n",
    "        log_probs = F.logsigmoid(score)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-i2qQprHAPe",
    "outputId": "be80b816-fa74-4003-efa8-b757f4170491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.03682 ,  1.77856 , -0.693547, ..., -0.10278 , -0.36428 ,\n",
       "        -0.64853 ],\n",
       "       [-2.19067 ,  1.16642 , -1.91385 , ...,  0.870654, -0.33808 ,\n",
       "        -0.41957 ],\n",
       "       [ 1.16672 ,  0.811884, -0.115492, ..., -0.104843,  2.26862 ,\n",
       "         1.21729 ],\n",
       "       ...,\n",
       "       [-0.483488,  2.00359 ,  0.186266, ..., -0.114528,  1.50755 ,\n",
       "        -1.25606 ],\n",
       "       [ 0.201604,  1.15796 ,  0.888882, ..., -1.28183 ,  0.465847,\n",
       "        -1.57974 ],\n",
       "       [-0.238824,  0.443876,  0.290836, ..., -0.802705, -0.318169,\n",
       "        -1.4733  ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(pretrained_dir + 'senna.wiki-reuters.lm2.50d.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rHad7RtHAPf"
   },
   "outputs": [],
   "source": [
    "w2v_skipgram_dataset = Word2VecText(tokenized_text_train, window_size=window_size, variant='skipgram')\n",
    "pretrained_npy = torch.tensor(np.load(pretrained_dir + 'senna.wiki-reuters.lm2.50d.npy'))\n",
    "pretrained_model = SkipGram(pretrained_npy).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSYkwNJLHAPf"
   },
   "source": [
    "<a id=\"section-3-1-6-eval-skipgram\"></a>\n",
    "## Test Pretrained Embeddings on the Skipgram Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_8HKzdjHAPf"
   },
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_skipgram_dataset._iterator(w2v_skipgram_dataset.vectorize(sent)):\n",
    "        pretrained_model.zero_grad()\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x1, x2 = w2v_io['x']\n",
    "        if -1 in (x1, x2): # Skip unknown words.\n",
    "            continue\n",
    "        x1, x2 = tensor(x1).to(device), tensor(x2).to(device)\n",
    "        y = w2v_io['y']\n",
    "        with torch.no_grad():\n",
    "            logprobs = pretrained_model(x1, x2)\n",
    "            _, prediction =  torch.max(logprobs, 1)    \n",
    "        true_positive += int(prediction) == int(y)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZLru8qVHAPg"
   },
   "outputs": [],
   "source": [
    "with open(pretrained_dir + 'senna.wiki-reuters.lm2.50d.txt') as fin:\n",
    "    pretrained_keys = {line.strip():i for i, line in enumerate(fin)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJTV2BuDHAPh",
    "outputId": "8d90b9af-e011-4a4a-f499-141fdf8e62a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5001212121212121\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqYhbv64HAPi"
   },
   "source": [
    "<a id=\"section-3-1-6-eval-cbow\"></a>\n",
    "## Test Pretrained Embeddings on the CBOW Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5s3_QXyGHAPi"
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, pretrained_npy, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        vocab_size, embd_size = list(pretrained_npy.shape)\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_npy)\n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embeddings(inputs).float().view((1, -1))\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRnq6bWrHAPi"
   },
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "w2v_dataset = Word2VecText(tokenized_text_train, window_size=window_size, variant='cbow')\n",
    "hidden_size = 300\n",
    "pretrained_cbow_model = CBOW(pretrained_npy, window_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgVYr0S1HAPj",
    "outputId": "16de0d88-8917-4514-afad-828740eddbf6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m:\u001b[0m \t\t the problem is essentially this \u001b[91mmuresan\u001b[0m if a word ( or\n",
      "\u001b[92mre-\u001b[0m \t\t the web is a vast \u001b[91mmladen\u001b[0m source for many languages .\n",
      "\u001b[92mrandom\u001b[0m \t\t is that the association is \u001b[91mabiomed\u001b[0m , arbitrary , motivated or\n",
      "\u001b[92m,\u001b[0m \t\t that the association is random \u001b[91mmotorcade\u001b[0m arbitrary , motivated or pre-\n",
      "\u001b[92m<unk>\u001b[0m \t\t arbitrary , motivated or pre- \u001b[91maccounts\u001b[0m ( r , a ,\n",
      "\u001b[92minevitably\u001b[0m \t however , their methods are \u001b[91munwrapped\u001b[0m noisy , suffering , for\n",
      "\u001b[92mnoisy\u001b[0m \t\t , their methods are inevitably \u001b[91mreasonable\u001b[0m , suffering , for example\n",
      "\u001b[92m,\u001b[0m \t\t their methods are inevitably noisy \u001b[91mhm\u001b[0m suffering , for example ,\n",
      "\u001b[92msuffering\u001b[0m \t methods are inevitably noisy , \u001b[91mheadrests\u001b[0m , for example , from\n",
      "\u001b[92m,\u001b[0m \t\t are inevitably noisy , suffering \u001b[91mrehearsals\u001b[0m for example , from just\n",
      "\u001b[92mfor\u001b[0m \t\t inevitably noisy , suffering , \u001b[91mfarr\u001b[0m example , from just those\n",
      "\u001b[92mexample\u001b[0m \t noisy , suffering , for \u001b[91mahu\u001b[0m , from just those parser\n",
      "\u001b[92m,\u001b[0m \t\t , suffering , for example \u001b[91mmeraj\u001b[0m from just those parser errors\n",
      "\u001b[92mfrom\u001b[0m \t\t suffering , for example , \u001b[91mgiscard\u001b[0m just those parser errors that\n",
      "\u001b[92mjust\u001b[0m \t\t , for example , from \u001b[91mmido\u001b[0m those parser errors that the\n",
      "\u001b[92mthose\u001b[0m \t\t for example , from just \u001b[91mprospekt\u001b[0m parser errors that the whole\n",
      "\u001b[92mparser\u001b[0m \t\t example , from just those \u001b[91mwashing\u001b[0m errors that the whole process\n",
      "\u001b[92merrors\u001b[0m \t\t , from just those parser \u001b[91maeros\u001b[0m that the whole process is\n",
      "\u001b[92mthat\u001b[0m \t\t from just those parser errors \u001b[91mlevett\u001b[0m the whole process is designed\n",
      "\u001b[92mthe\u001b[0m \t\t just those parser errors that \u001b[91mbse-free\u001b[0m whole process is designed to\n",
      "\u001b[92mwhole\u001b[0m \t\t those parser errors that the \u001b[91mtreader\u001b[0m process is designed to address\n",
      "\u001b[92mprocess\u001b[0m \t parser errors that the whole \u001b[91mbhaskara\u001b[0m is designed to address ,\n",
      "\u001b[92mis\u001b[0m \t\t errors that the whole process \u001b[91mheisman\u001b[0m designed to address , and\n",
      "\u001b[92mdesigned\u001b[0m \t that the whole process is \u001b[91munconfirmed\u001b[0m to address , and they\n",
      "\u001b[92mto\u001b[0m \t\t the whole process is designed \u001b[91mgarrod\u001b[0m address , and they do\n",
      "\u001b[92maddress\u001b[0m \t whole process is designed to \u001b[91msunni-shi'ite\u001b[0m , and they do not\n",
      "\u001b[92m,\u001b[0m \t\t process is designed to address \u001b[91mweidling\u001b[0m and they do not wish\n",
      "\u001b[92mand\u001b[0m \t\t is designed to address , \u001b[91mlancasters\u001b[0m they do not wish to\n",
      "\u001b[92mthey\u001b[0m \t\t designed to address , and \u001b[91mabiomed\u001b[0m do not wish to accept\n",
      "\u001b[92mdo\u001b[0m \t\t to address , and they \u001b[91mgrands\u001b[0m not wish to accept any\n",
      "\u001b[92mnot\u001b[0m \t\t address , and they do \u001b[91mfootsteps\u001b[0m wish to accept any scf\n",
      "\u001b[92mwish\u001b[0m \t\t , and they do not \u001b[91mcaniff\u001b[0m to accept any scf for\n",
      "\u001b[92mto\u001b[0m \t\t and they do not wish \u001b[91msherburne\u001b[0m accept any scf for which\n",
      "\u001b[92maccept\u001b[0m \t\t they do not wish to \u001b[91mahonen\u001b[0m any scf for which there\n",
      "\u001b[92many\u001b[0m \t\t do not wish to accept \u001b[91mpff\u001b[0m scf for which there is\n",
      "\u001b[92mscf\u001b[0m \t\t not wish to accept any \u001b[91madler\u001b[0m for which there is any\n",
      "\u001b[92mfor\u001b[0m \t\t wish to accept any scf \u001b[91mindianapolis-based\u001b[0m which there is any evidence\n",
      "\u001b[92mwhich\u001b[0m \t\t to accept any scf for \u001b[91mromania\u001b[0m there is any evidence as\n",
      "\u001b[92mthere\u001b[0m \t\t accept any scf for which \u001b[91munconfirmed\u001b[0m is any evidence as a\n",
      "\u001b[92mis\u001b[0m \t\t any scf for which there \u001b[91mmathur\u001b[0m any evidence as a true\n",
      "\u001b[92many\u001b[0m \t\t scf for which there is \u001b[91msetups\u001b[0m evidence as a true scf\n",
      "\u001b[92mevidence\u001b[0m \t for which there is any \u001b[91mmeraj\u001b[0m as a true scf for\n",
      "\u001b[92mas\u001b[0m \t\t which there is any evidence \u001b[91msaperia\u001b[0m a true scf for the\n",
      "\u001b[92ma\u001b[0m \t\t there is any evidence as \u001b[91mareala\u001b[0m true scf for the verb\n",
      "\u001b[92mtrue\u001b[0m \t\t is any evidence as a \u001b[91mpriya\u001b[0m scf for the verb .\n",
      "\u001b[92mthat\u001b[0m \t\t while it might seem plausible \u001b[91mzooming\u001b[0m oddities would in some way\n",
      "\u001b[92moddities\u001b[0m \t it might seem plausible that \u001b[91mhandpicked\u001b[0m would in some way balance\n",
      "\u001b[92mwould\u001b[0m \t\t might seem plausible that oddities \u001b[91mstand\u001b[0m in some way balance out\n",
      "\u001b[92min\u001b[0m \t\t seem plausible that oddities would \u001b[91mbarlows\u001b[0m some way balance out to\n",
      "\u001b[92msome\u001b[0m \t\t plausible that oddities would in \u001b[91myi\u001b[0m way balance out to give\n",
      "\u001b[92mway\u001b[0m \t\t that oddities would in some \u001b[91mnaibari\u001b[0m balance out to give a\n",
      "\u001b[92m<unk>\u001b[0m \t\t balance out to give a \u001b[91mexcesses\u001b[0m tion that was indistinguishable from\n",
      "\u001b[92mone\u001b[0m \t\t tion that was indistinguishable from \u001b[91midealists\u001b[0m where the individual words (\n",
      "\u001b[92mwhere\u001b[0m \t\t that was indistinguishable from one \u001b[91msaur\u001b[0m the individual words ( as\n",
      "\u001b[92mthe\u001b[0m \t\t was indistinguishable from one where \u001b[91mros\u001b[0m individual words ( as opposed\n",
      "\u001b[92mindividual\u001b[0m \t indistinguishable from one where the \u001b[91mgoaltending\u001b[0m words ( as opposed to\n",
      "\u001b[92mwords\u001b[0m \t\t from one where the individual \u001b[91mboudria\u001b[0m ( as opposed to the\n",
      "\u001b[92m(\u001b[0m \t\t one where the individual words \u001b[91mtwilight\u001b[0m as opposed to the texts\n",
      "\u001b[92mas\u001b[0m \t\t where the individual words ( \u001b[91mheisman\u001b[0m opposed to the texts )\n",
      "\u001b[92mopposed\u001b[0m \t the individual words ( as \u001b[91mdouste-blazy\u001b[0m to the texts ) had\n",
      "\u001b[92mto\u001b[0m \t\t individual words ( as opposed \u001b[91mmielke\u001b[0m the texts ) had been\n",
      "\u001b[92mthe\u001b[0m \t\t words ( as opposed to \u001b[91map0\u001b[0m texts ) had been randomly\n",
      "\u001b[92mtexts\u001b[0m \t\t ( as opposed to the \u001b[91mhopalong\u001b[0m ) had been randomly selected\n",
      "\u001b[92m)\u001b[0m \t\t as opposed to the texts \u001b[91mromania\u001b[0m had been randomly selected ,\n",
      "\u001b[92mhad\u001b[0m \t\t opposed to the texts ) \u001b[91meels\u001b[0m been randomly selected , this\n",
      "\u001b[92mbeen\u001b[0m \t\t to the texts ) had \u001b[91mcfrb\u001b[0m randomly selected , this turns\n",
      "\u001b[92mrandomly\u001b[0m \t the texts ) had been \u001b[91munconfirmed\u001b[0m selected , this turns out\n",
      "\u001b[92mselected\u001b[0m \t texts ) had been randomly \u001b[91mbrydges\u001b[0m , this turns out not\n",
      "\u001b[92m,\u001b[0m \t\t ) had been randomly selected \u001b[91madopter\u001b[0m this turns out not to\n",
      "\u001b[92mthis\u001b[0m \t\t had been randomly selected , \u001b[91mstartup\u001b[0m turns out not to be\n",
      "\u001b[92mturns\u001b[0m \t\t been randomly selected , this \u001b[91mrenumbering\u001b[0m out not to be the\n",
      "\u001b[92mout\u001b[0m \t\t randomly selected , this turns \u001b[91mhalvorsen\u001b[0m not to be the case\n",
      "\u001b[92mnot\u001b[0m \t\t selected , this turns out \u001b[91mcc;nsajan\u001b[0m to be the case .\n",
      "\u001b[92mvaries\u001b[0m \t\t however where the sample size \u001b[91mengels\u001b[0m by an order of magnitude\n",
      "\u001b[92mby\u001b[0m \t\t where the sample size varies \u001b[91mphotonics\u001b[0m an order of magnitude ,\n",
      "\u001b[92man\u001b[0m \t\t the sample size varies by \u001b[91mbrees\u001b[0m order of magnitude , or\n",
      "\u001b[92morder\u001b[0m \t\t sample size varies by an \u001b[91mstartup\u001b[0m of magnitude , or where\n",
      "\u001b[92mof\u001b[0m \t\t size varies by an order \u001b[91mconservatism\u001b[0m magnitude , or where it\n",
      "\u001b[92mmagnitude\u001b[0m \t varies by an order of \u001b[91mleaned\u001b[0m , or where it is\n",
      "\u001b[92m,\u001b[0m \t\t by an order of magnitude \u001b[91mroundly\u001b[0m or where it is enormous\n",
      "\u001b[92mor\u001b[0m \t\t an order of magnitude , \u001b[91mstartup\u001b[0m where it is enormous ,\n",
      "\u001b[92mwhere\u001b[0m \t\t order of magnitude , or \u001b[91mmoderate\u001b[0m it is enormous , it\n",
      "\u001b[92mit\u001b[0m \t\t of magnitude , or where \u001b[91mindex.jun\u001b[0m is enormous , it is\n",
      "\u001b[92mis\u001b[0m \t\t magnitude , or where it \u001b[91mroundly\u001b[0m enormous , it is wrong\n",
      "\u001b[92menormous\u001b[0m \t , or where it is \u001b[91mnovato\u001b[0m , it is wrong to\n",
      "\u001b[92m,\u001b[0m \t\t or where it is enormous \u001b[91mnaibari\u001b[0m it is wrong to identify\n",
      "\u001b[92mit\u001b[0m \t\t where it is enormous , \u001b[91mjumpsuit\u001b[0m is wrong to identify the\n",
      "\u001b[92mthe\u001b[0m \t\t proceedings of the conference of \u001b[91mhynde\u001b[0m south-central sas users group ,\n",
      "\u001b[92man\u001b[0m \t\t making false assumptions is often \u001b[91mmacos\u001b[0m ingenious way to proceed ;\n",
      "\u001b[92mingenious\u001b[0m \t false assumptions is often an \u001b[91mmoneygram\u001b[0m way to proceed ; the\n",
      "\u001b[92mway\u001b[0m \t\t assumptions is often an ingenious \u001b[91m0-series\u001b[0m to proceed ; the problem\n",
      "\u001b[92mto\u001b[0m \t\t is often an ingenious way \u001b[91max\u001b[0m proceed ; the problem arises\n",
      "\u001b[92mproceed\u001b[0m \t often an ingenious way to \u001b[91mheadscarves\u001b[0m ; the problem arises where\n",
      "\u001b[92m;\u001b[0m \t\t an ingenious way to proceed \u001b[91mmedavoy\u001b[0m the problem arises where the\n",
      "\u001b[92mthe\u001b[0m \t\t ingenious way to proceed ; \u001b[91mcognitive\u001b[0m problem arises where the literal\n",
      "\u001b[92mproblem\u001b[0m \t way to proceed ; the \u001b[91mtommy\u001b[0m arises where the literal falsity\n",
      "\u001b[92marises\u001b[0m \t\t to proceed ; the problem \u001b[91mlillie\u001b[0m where the literal falsity of\n",
      "\u001b[92mwhere\u001b[0m \t\t proceed ; the problem arises \u001b[91meloy\u001b[0m the literal falsity of the\n",
      "\u001b[92mthe\u001b[0m \t\t ; the problem arises where \u001b[91mstalemate\u001b[0m literal falsity of the assumption\n",
      "\u001b[92mliteral\u001b[0m \t the problem arises where the \u001b[91mproteges\u001b[0m falsity of the assumption is\n",
      "\u001b[92mfalsity\u001b[0m \t problem arises where the literal \u001b[91mcormar\u001b[0m of the assumption is overlooked\n",
      "\u001b[92mof\u001b[0m \t\t arises where the literal falsity \u001b[91munseemly\u001b[0m the assumption is overlooked ,\n",
      "\u001b[92mthe\u001b[0m \t\t where the literal falsity of \u001b[91meurobeat\u001b[0m assumption is overlooked , and\n",
      "\u001b[92m<unk>\u001b[0m \t\t assumption is overlooked , and \u001b[91maeros\u001b[0m ate inferences are drawn .\n",
      "\u001b[92m<unk>\u001b[0m \t\t when we look at linguistic \u001b[91mtantalus\u001b[0m ena in corpora , the\n",
      "\u001b[92mnull\u001b[0m \t\t ena in corpora , the \u001b[91mncec\u001b[0m hypothesis will never be true\n",
      "\u001b[92mhypothesis\u001b[0m \t in corpora , the null \u001b[91mbranes\u001b[0m will never be true .\n",
      "\u001b[92menough\u001b[0m \t\t we do not always have \u001b[91mviggen\u001b[0m data to reject the null\n",
      "\u001b[92mdata\u001b[0m \t\t do not always have enough \u001b[91mhandpicked\u001b[0m to reject the null hypothesis\n",
      "\u001b[92mto\u001b[0m \t\t not always have enough data \u001b[91mjerald\u001b[0m reject the null hypothesis ,\n",
      "\u001b[92mreject\u001b[0m \t\t always have enough data to \u001b[91mbse-free\u001b[0m the null hypothesis , but\n",
      "\u001b[92mthe\u001b[0m \t\t have enough data to reject \u001b[91mjaneshwar\u001b[0m null hypothesis , but that\n",
      "\u001b[92mnull\u001b[0m \t\t enough data to reject the \u001b[91msteady\u001b[0m hypothesis , but that is\n",
      "\u001b[92mhypothesis\u001b[0m \t data to reject the null \u001b[91mmcclintock\u001b[0m , but that is a\n",
      "\u001b[92m,\u001b[0m \t\t to reject the null hypothesis \u001b[91mguesswork\u001b[0m but that is a distinct\n",
      "\u001b[92mbut\u001b[0m \t\t reject the null hypothesis , \u001b[91mbrainwaves\u001b[0m that is a distinct issue\n",
      "\u001b[92mthat\u001b[0m \t\t the null hypothesis , but \u001b[91mal-qabas\u001b[0m is a distinct issue :\n",
      "\u001b[92mis\u001b[0m \t\t null hypothesis , but that \u001b[91mfdm\u001b[0m a distinct issue : wherever\n",
      "\u001b[92ma\u001b[0m \t\t hypothesis , but that is \u001b[91mpinta\u001b[0m distinct issue : wherever there\n",
      "\u001b[92mdistinct\u001b[0m \t , but that is a \u001b[91mturbowicz\u001b[0m issue : wherever there is\n",
      "\u001b[92missue\u001b[0m \t\t but that is a distinct \u001b[91msavitsky\u001b[0m : wherever there is enough\n",
      "\u001b[92m:\u001b[0m \t\t that is a distinct issue \u001b[91mmillen\u001b[0m wherever there is enough data\n",
      "\u001b[92mwherever\u001b[0m \t is a distinct issue : \u001b[91mrehearsals\u001b[0m there is enough data ,\n",
      "\u001b[92mthere\u001b[0m \t\t a distinct issue : wherever \u001b[91mfood-processing\u001b[0m is enough data , it\n",
      "\u001b[92mis\u001b[0m \t\t distinct issue : wherever there \u001b[91mtafsir\u001b[0m enough data , it is\n",
      "\u001b[92menough\u001b[0m \t\t issue : wherever there is \u001b[91mhelgi\u001b[0m data , it is rejected\n",
      "\u001b[92mdata\u001b[0m \t\t : wherever there is enough \u001b[91msqueaks\u001b[0m , it is rejected .\n",
      "\u001b[92mare\u001b[0m \t\t since words in a text \u001b[91mnarn\u001b[0m not random , we know\n",
      "\u001b[92mnot\u001b[0m \t\t words in a text are \u001b[91mross\u001b[0m random , we know that\n",
      "\u001b[92mrandom\u001b[0m \t\t in a text are not \u001b[91mcriticare\u001b[0m , we know that our\n",
      "\u001b[92m,\u001b[0m \t\t a text are not random \u001b[91mhalvorsen\u001b[0m we know that our corpora\n",
      "\u001b[92mwe\u001b[0m \t\t text are not random , \u001b[91mtortoiseshell\u001b[0m know that our corpora are\n",
      "\u001b[92mknow\u001b[0m \t\t are not random , we \u001b[91mprov;y\u001b[0m that our corpora are not\n",
      "\u001b[92mthat\u001b[0m \t\t not random , we know \u001b[91moutplayed\u001b[0m our corpora are not randomly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mour\u001b[0m \t\t random , we know that \u001b[91minvoicing\u001b[0m corpora are not randomly generated\n",
      "\u001b[92mcorpora\u001b[0m \t , we know that our \u001b[91mwicht\u001b[0m are not randomly generated ,\n",
      "\u001b[92mare\u001b[0m \t\t we know that our corpora \u001b[91mtraditional\u001b[0m not randomly generated , and\n",
      "\u001b[92mnot\u001b[0m \t\t know that our corpora are \u001b[91mtartarstan\u001b[0m randomly generated , and the\n",
      "\u001b[92mrandomly\u001b[0m \t that our corpora are not \u001b[91mamyrlin\u001b[0m generated , and the hypothesis\n",
      "\u001b[92mgenerated\u001b[0m \t our corpora are not randomly \u001b[91mworshipping\u001b[0m , and the hypothesis test\n",
      "\u001b[92mthe\u001b[0m \t\t gives us reason to view \u001b[91mefan\u001b[0m relation between , for example\n",
      "\u001b[92mrelation\u001b[0m \t us reason to view the \u001b[91msaur\u001b[0m between , for example ,\n",
      "\u001b[92mbetween\u001b[0m \t reason to view the relation \u001b[91mtld\u001b[0m , for example , a\n",
      "\u001b[92m,\u001b[0m \t\t to view the relation between \u001b[91mtap\u001b[0m for example , a verb\n",
      "\u001b[92m<unk>\u001b[0m \t\t for example , a verb \u001b[91mprospekt\u001b[0m s syntax and its semantics\n",
      "\u001b[92m,\u001b[0m \t\t s syntax and its semantics \u001b[91mdemonstrates\u001b[0m as motivated rather than arbitrary\n",
      "\u001b[92mas\u001b[0m \t\t syntax and its semantics , \u001b[91munseemly\u001b[0m motivated rather than arbitrary .\n",
      "\u001b[92merror\u001b[0m \t\t the average value of the \u001b[91mtsinghua\u001b[0m term , language is never\n",
      "\u001b[92mterm\u001b[0m \t\t average value of the error \u001b[91mcostuming\u001b[0m , language is never ,\n",
      "\u001b[92m,\u001b[0m \t\t value of the error term \u001b[91mbrucke\u001b[0m language is never , ever\n",
      "\u001b[92mlanguage\u001b[0m \t of the error term , \u001b[91mindex.jun\u001b[0m is never , ever ,\n",
      "\u001b[92mis\u001b[0m \t\t the error term , language \u001b[91mkeynsham\u001b[0m never , ever , ever\n",
      "\u001b[92mnever\u001b[0m \t\t error term , language is \u001b[91mabiomed\u001b[0m , ever , ever ,\n",
      "\u001b[92m,\u001b[0m \t\t term , language is never \u001b[91mkeynsham\u001b[0m ever , ever , random\n",
      "\u001b[92m,\u001b[0m \t\t the hypothesis can , therefore \u001b[91mcoterie\u001b[0m be couched as : are\n",
      "\u001b[92mbe\u001b[0m \t\t hypothesis can , therefore , \u001b[91mncec\u001b[0m couched as : are the\n",
      "\u001b[92mcouched\u001b[0m \t can , therefore , be \u001b[91maargau\u001b[0m as : are the error\n",
      "\u001b[92mas\u001b[0m \t\t , therefore , be couched \u001b[91mfrepaso\u001b[0m : are the error terms\n",
      "\u001b[92m:\u001b[0m \t\t therefore , be couched as \u001b[91mgrafting\u001b[0m are the error terms systematically\n",
      "\u001b[92mare\u001b[0m \t\t , be couched as : \u001b[91madelson\u001b[0m the error terms systematically greater\n",
      "\u001b[92mthe\u001b[0m \t\t be couched as : are \u001b[91mjohn.sanders@reuters.com\u001b[0m error terms systematically greater than\n",
      "\u001b[92mbecomes\u001b[0m \t % of them , devastate \u001b[91mdall\u001b[0m one of the verbs for\n",
      "\u001b[92mone\u001b[0m \t\t of them , devastate becomes \u001b[91mabiomed\u001b[0m of the verbs for which\n",
      "\u001b[92mof\u001b[0m \t\t them , devastate becomes one \u001b[91mdaimler-benz\u001b[0m the verbs for which we\n",
      "\u001b[92mthe\u001b[0m \t\t , devastate becomes one of \u001b[91myell\u001b[0m verbs for which we have\n",
      "\u001b[92mverbs\u001b[0m \t\t devastate becomes one of the \u001b[91mormond\u001b[0m for which we have plenty\n",
      "\u001b[92mfor\u001b[0m \t\t becomes one of the verbs \u001b[91mmathur\u001b[0m which we have plenty of\n",
      "\u001b[92mwhich\u001b[0m \t\t one of the verbs for \u001b[91mstabs\u001b[0m we have plenty of data\n",
      "\u001b[92mwe\u001b[0m \t\t of the verbs for which \u001b[91mvlasov\u001b[0m have plenty of data ,\n",
      "\u001b[92mhave\u001b[0m \t\t the verbs for which we \u001b[91msunni-shi'ite\u001b[0m plenty of data , and\n",
      "\u001b[92mplenty\u001b[0m \t\t verbs for which we have \u001b[91mthat\u001b[0m of data , and crude\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_dataset._iterator(w2v_dataset.vectorize(sent)):\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x = tensor(w2v_io['x']).to(device)\n",
    "        y = tensor(w2v_io['y']).to(device)\n",
    "        \n",
    "        if -1 in x: # Skip unknown words.\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            _, prediction =  torch.max(pretrained_cbow_model(x), 1)\n",
    "        true_positive += int(prediction) == int(y)\n",
    "        visualize_predictions(x, y, prediction, w2v_dataset.vocab, window_size=window_size)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRmLeM9-HAPk",
    "outputId": "2a727ef6-0d7a-42d2-81c3-258493823af3"
   },
   "outputs": [],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPYRyVP4HAPl"
   },
   "source": [
    "<a id=\"section-3-1-6-unfreeze-finetune\"></a>\n",
    "## Unfreeze the Embedddings and Tune it on the CBOW Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4cUE4nTHAPl",
    "outputId": "ec962a3c-d9c8-4abe-b7fd-2849e17e150d"
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, pretrained_npy, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        vocab_size, embd_size = list(pretrained_npy.shape)\n",
    "        # See https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding.from_pretrained\n",
    "        # Note the `freeze=False`, by default if you use `nn.Embedding.from_pretrained(),\n",
    "        # `freeze` is set to True\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_npy, freeze=False)\n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embeddings(inputs).float().view((1, -1))\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfwppYi8HAPm",
    "outputId": "c31a71a9-9f22-4391-f102-cc3ef672ce45"
   },
   "outputs": [],
   "source": [
    "window_size = 2 \n",
    "w2v_dataset = Word2VecText(tokenized_text_train, window_size=window_size, variant='cbow')\n",
    "hidden_size = 300\n",
    "pretrained_cbow_model = CBOW(pretrained_npy, window_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpQbKw8iHAPm",
    "outputId": "7eb62122-8c66-4444-be79-831edb3fbd97"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(pretrained_cbow_model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "model = nn.DataParallel(pretrained_cbow_model)\n",
    "\n",
    "num_epochs = 100\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    epoch_loss = []\n",
    "    for sent_idx in range(w2v_dataset._len):\n",
    "        for w2v_io in w2v_dataset[sent_idx]:\n",
    "            # Retrieve the inputs and outputs.\n",
    "            x = tensor(w2v_io['x']).to(device)\n",
    "            y = autograd.Variable(tensor(w2v_io['y'], dtype=torch.long)).to(device)\n",
    "            \n",
    "            if -1 in x or int(y) == -1:\n",
    "                continue\n",
    "            # Zero gradient.\n",
    "            model.zero_grad()\n",
    "            # Calculate the log probability of the context embeddings.\n",
    "            logprobs = pretrained_cbow_model(x)\n",
    "            # This unsqueeze thing is really a feature/bug... -_-\n",
    "            loss = criterion(logprobs, y.unsqueeze(0)) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "    # Save model after every epoch.\n",
    "    torch.save(model.state_dict(), 'cbow_finetuning_checkpoint_{}.pt'.format(_e))\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTKWhnDXHAPn"
   },
   "source": [
    "<a id=\"section-3-1-6-reval-cbow\"></a>\n",
    "\n",
    "## Re-Test Pretrained Embeddings on the CBOW Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKmkIvpeHAPn"
   },
   "outputs": [],
   "source": [
    "\n",
    "true_positive = 0\n",
    "all_data = 0\n",
    "# Iterate through the test sentences. \n",
    "for sent in tokenized_text_test:\n",
    "    # Extract all the CBOW contexts (X) and targets (Y)\n",
    "    for w2v_io in w2v_dataset._iterator(w2v_dataset.vectorize(sent)):\n",
    "        # Retrieve the inputs and outputs.\n",
    "        x = tensor(w2v_io['x']).to(device)\n",
    "        y = tensor(w2v_io['y']).to(device)\n",
    "        \n",
    "        if -1 in x: # Skip unknown words.\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            _, prediction =  torch.max(pretrained_cbow_model(x), 1)\n",
    "        true_positive += int(prediction) == int(y)\n",
    "        visualize_predictions(x, y, prediction, w2v_dataset.vocab, window_size=window_size)\n",
    "        all_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtTOg58JHAPo",
    "outputId": "17789194-c928-4e7f-88d6-892e0af1b30c"
   },
   "outputs": [],
   "source": [
    "print('Accuracy:', true_positive/all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ang2rfTtHAPp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRGV62gLHAPq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7wLms84nHlmc",
    "4euuHE2ZHlmg",
    "dNiCSpQjHlmu",
    "xFyT-2C7Hlmx",
    "NfiJsVXfHlne",
    "JljjG8wPHlnq",
    "g5FFlCOxHloZ",
    "eJZPBd_eHloc",
    "SjnIlUDeHlpH",
    "_Lcv5kLPHlpW",
    "YwizIFgnHlpf",
    "UD-HOa8AHlpo",
    "opZKKtIKHlpu",
    "v3oQzqhoHlpv",
    "mabiO5n1Hlpx",
    "TouRhGbDHlp5",
    "40WxV7F6HlqD",
    "G02TvHoqHlqD",
    "QQbNKqJBHlqG",
    "5Ps4hXZPHlqK",
    "wkMi05XVHlqR",
    "bxSp00OXHlqc",
    "E6QkNPykHlqm"
   ],
   "name": "Session3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
